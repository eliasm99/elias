{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02535db3-4a7c-4bbe-b79e-e7468dde16aa",
   "metadata": {},
   "source": [
    "# Import libraries and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eff10042-551e-4d32-bccc-bc68b6dbc356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed640387-8aab-4a10-aa26-ee3bfa01a802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset and flatten it for MLP use\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bf8c60-e639-4a20-8727-21537ec74e53",
   "metadata": {},
   "source": [
    "## Explore the distribution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b17b7f4-e36a-4322-baba-4a7616c5b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_dataset.targets  # Extract labels from the dataset\n",
    "label_counts = torch.bincount(labels)  # Count occurrences of each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63261984-3048-4e7a-b141-898f06645de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Seaborn style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d71b262-0023-43d7-8522-8c677f327eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1wAAAIlCAYAAADBv/l5AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAnGZJREFUeJzs3Xd4FFXbx/HvpkEaJZTQAgQQUEAICbGEonQREFQwoFQFJZQXpYiiWJAiKBYCSu9d2oMgSC+KdBDpLUSQmgghCSVl3z/yZJ6sSdawyYYk/D7XxUUyc/bMOfduZvaeM3PGZDabzYiIiIiIiEiWc3jQDRAREREREcmrlHCJiIiIiIjYiRIuERERERERO1HCJSIiIiIiYidKuEREREREROxECZeIiIiIiIidKOESERERERGxEyVcIiIiIiIidqKES0TuW3x8/INuQpbIK/0QEXnYaX8uOZnTg26AiKRv2bJlvPfee6mWm0wmXF1dKVy4MNWrVyc4OJinn346Vbldu3bRuXNnAEqXLs2mTZsy1Z6EhAQWLlzIrl27+Pbbb+/rtSn7EhgYyJw5c+zSxoy4evUqX375JU899RRt2rQxlo8fP57Q0FAA2rZty+jRo+3eluxw8uRJvvrqK/bv309MTAxeXl40btyYYcOGpfuahg0bcvHiRQBGjRrFiy++mOXtys73vkqVKsbPGzdupEyZMlla/4ULF2jUqJHx+4kTJ7K0/vS2A0l9+89//pOqbI8ePdi2bZvFstmzZ/PEE08Alp93b29vfvrpJ9zd3VPVk/KzkDJ2Q4YMYfny5UDafy9Xrlxh9uzZ7Nixg0uXLhETE4OHhwcVKlTg2WefpWPHjnh4eBjlU7Yno6y9l506dWL37t0Zrsten8Gs/pynty/NSRISEli2bBlr167lxIkT3LhxA2dnZ0qUKEFAQACvvvoqVatWzbJt2XpcEskuSrhEciGz2UxsbCyxsbFcvHiRdevW0aFDB4YNG4aDg30Grs+cOUP//v05efIkgYGBdtlGdliwYAFjxowhNjbW+OKZl927d49u3bpx/fp1Y9mVK1e4dOnSA2yVZKWTJ08SERFBkSJFjGXx8fHs3bs3w3VcuXKF0NBQ3n333Sxp086dOwkJCSE2NtZi+Y0bN9i/fz/79+9n/vz5zJw5k/Lly2fJNiVniI6Opnv37hw6dMhieVxcHGfPnuXs2bMsXbqUoUOH8uqrr2ZqW3nluCR5nxIukVzCw8ODDh06YDabSUhI4ObNm/z222/89ddfQFIiUbx4cUJCQozXlCpVih49egBQoECBTG3/0KFDnDx50ubXV65c2WiLj49PptqSGWvWrEn1JTCZv7+/0cZq1aplZ7Ps5vTp0xbJVqtWrShcuDB+fn4PsFV5j6enp/HZyW5ms5mdO3fSsmVLY9mhQ4fS/ZynZ/bs2bRt25bKlStnqj3R0dH83//9n7F9b29vgoKC8PDwICwsjB07dpCYmMilS5fo378/y5cvx2QyWfz9Jfvxxx+NkwO1a9fG39/fYr2np2e67WjZsiU1a9a0WDZlyhSL9SVLljR+z+w+Mj1ZuR+GnLMvTc/IkSONZMvZ2Zl69epRpkwZbt26xebNm7lx4wYJCQl89tln1KxZk+rVq9u8rcwel0SyixIukVyiYMGCDBw40GJZfHw8H374IcuWLQNg4sSJvPzyyxQvXhxIOhj/8zUPSvXq1TN1YM0OTz/9dJqXZuZm0dHRxs/e3t588cUXD7A1eVdaf5/25urqyu3btwH49ddfLRKunTt3Gj+7ubllKPmKj4/nk08+Yd68eZlq14YNG7h58yYAVatWZcmSJbi4uBjrf/zxRwYMGADAsWPH+OOPP6hRo0aaf3+HDh0yEq6nn36avn37Zrgdr7zySqplKROu9u3bZ8sod1bvh3PyvjQ+Pt7i8tb58+fz+OOPG79HRkbSpk0brly5QmJiIsuWLcuxfRHJSpo0QyQXc3Jy4pNPPjEuJYqLi2Pp0qXG+l27dlGlShWqVKlCw4YNLV578+ZNvvjiC1q2bEmtWrWoVq0aTz/9NG+88QZbtmyxKNupUyeLe8l2795NlSpV6NSpU6rtvP3222zcuJEmTZpQvXp1mjRpwp9//smyZcuMMsmvS8utW7cYPnw4QUFB1KxZk5deeokVK1akKjdkyBCjvvHjx1usS6vfFy5coEqVKhb3dLz33ntUqVLFSFjHjx9vvG7IkCGpthkZGUloaCitWrXCz88PPz8/XnzxRaZMmWJ88f1n3JLrO3PmDLt376ZLly74+fkREBBAr1697vten/j4eBYvXkzHjh158sknqVGjBs2aNWPEiBFcvnzZomzDhg0tYn3lyhWjPRcuXLiv7WbU1atX+eSTT2jSpAk1atTgscceIygoiLfeeosDBw5YfW1G33tIum9jwYIFvPTSS9SqVYvatWvTrl075s2bd183zyckJDBv3jyCg4MJCAjgscceIyAggFdeeYU5c+aQkJCQoXqSP1/J/1Jq2LChsfzu3busX7+eV155hVq1avHEE08wcOBA4x6p++Hl5UW5cuUAywQL4LfffgOSkq1/tseavXv3phvzjLp69arxs6urK87Ozhbrn3/+eZo1a0bdunWpW7cud+7cydT2slLK/dQXX3zB4sWLqV+/Po8//jgtW7Y0Etdz584xePBgnn32WSMBql+/Pm+//TZnzpyxqNPafjh5eVBQEABLlizhhRde4PHHH6du3bp8/PHHREZGptvGlH/fKT+D7du3Jz4+nilTptC8eXNq1KhBw4YN+fLLL9PcV927d4/JkydblA0NDSUuLo4mTZqk+blOy99//01cXJzx+z/vCfTy8qJXr17Ge5/WiF9ybOvWrWvEdfDgwani+m/HJZGcRCNcIrmci4sLDRo0MJKGPXv20KtXL6uviY6Opn379oSFhVksj4iIYPv27ezYsYPPPvuMl19++b7bc/z4cdavX28cdOPj4ylTpgx79uz519fevn2bV1991SIJ+eOPP3j33Xc5ceJElt1fYos//viDkJAQrly5YrH8yJEjHDlyhBUrVjBlyhRKlSqV5utXrVrFpEmTSExMNJZt2rSJXbt2sXLlygxdGvT3338TEhLC/v37LZaHhYURFhbG8uXLGT9+PE899ZQNPcy8yMhIXnvtNc6fP2+x/Pr162zevJlt27YxderUNEcR7+e9j4+Pp0+fPmzevNmijt9//53ff/+djRs38v3331uMqqRn4MCBrFmzxmLZrVu3OHjwIAcPHuSPP/7g888/z1D/M2Ly5MkWE0Pcvn2bVatWsWfPHn788Uerl8ilJTAwkPPnz/PXX38RFhZG+fLluX37NgcPHgSSLsO7d+/ev9bj4eFhjIaOGTOGhg0b2nz5W4UKFYyfDxw4QIcOHXjllVeoV68eRYsWxWQy5YrJDbZu3WpxuVrBggVxc3Pj3LlzdOzYMVUidOXKFdasWcPmzZtZsmQJjzzyyH1tb9iwYSxatMj4/dq1ayxYsIBDhw6xZMkSnJwy/pUtPj6e3r17W5w8u3jxIpMnT+bUqVN8//33xvK4uDh69uxpkbRfvHiR8ePHc/DgwQyfdICkhKpQoULcuHEDSEqKOnToYCRtJpOJDh060KFDhzRfn9a9f1euXGHlypWsXbuW8ePH06BBgwy3RySn0AiXSB5QqVIl4+fTp0//a/kFCxYYyVbJkiV55ZVX6NKli3Hph9lsZsSIEcYXsJYtW1oc5EqWLEmPHj0sLmFKdvbsWUwmEy+++CLNmzendevWmEymDPUjMjKSEydOEBgYSIcOHfD19TXWTZ8+PdVZ/PuRfI9Nyns2GjRoQI8ePf71npWoqCj69u1rJFuFCxfmxRdfpGXLlri5uQFJce/Vq5fF2d2UvvvuO4oUKULHjh2pX7++sTwmJoYlS5ZkqA/vvfeekWw5OTnRtGlT2rdvb/Tp1q1b9O7dm/DwcACCg4Mt3iMPDw969OhBjx497vuLfUZMmjTJSLZ8fHzo1KkTr7zyCsWKFQOSRpNmz56d5mvv573/7rvvjGTL2dmZli1b0r59ewoWLAjAL7/8kqHZ7n7//Xcj2XJzc6NVq1Z07dqVhg0bGp/ZFStWZOpz90+hoaGUK1eO1157jdq1axvLL1++nCrxy4iUEwUkt3Pfvn3G5zCjEwmk/BxFRETw1Vdf3XdbkjVo0MDib+rAgQMMGTKEoKAgWrRowWeffcauXbswm802byM7nDx5Eg8PD1555RUaNGhAq1atAPjyyy+NZKtKlSp06dKFl156yUhQb9++zcKFC+9rW9evX2fRokU8+uijxsh4sqNHjxojlhl15MgRtmzZgr+/P506dbKYyXHz5s2cO3fO+P2ff1/+/v506NCBSpUqsX379vsafXV0dKR79+7G7xEREYSGhvLCCy/w5JNP0rdvX5YuXWpxqXOyv//+m/79+xvJVuXKlXn11VepU6cOAHfv3mXgwIHGPan3c1wSedA0wiWSB6ScWjkqKupfy//555/GzyNGjDAuZzGbzQwbNoz4+HgqVqxoTOP8yiuv4OzszNatW4F/vydh4MCBdOnSxaa+dO/e3RjNuHv3Lm+88YZxGeDChQttHr1Jvscm5T0hzZs3z9B05/PnzzcmJyldujQLFizA29sbSJolq3379kRHR3P8+HFWrlyZ5shgyZIlWbZsGV5eXgC8/vrr7NixA4BTp079axv2799vJBmOjo7MmjWLgIAAIGnEsmvXrhw+fJiYmBhCQ0MZM2YMPXv2ZNeuXfz4448WMbCX8uXL07JlS86dO8fUqVONvrZu3dqYjSzlZ++fMvLe37t3zyJpmzJlivGZ6NmzJ61btyY2NpZ58+bRq1cvXF1d091ecmIK0LlzZ95++23j9zlz5rBv3z4qVaqUpclptWrVmD9/Pvnz5+fevXu89NJLxihKRj4H/5TyHqSdO3fSoUMHiy/PgYGBxufMGjc3Nz744AN69+4NJMX7pZdesun+GmdnZyZNmsSbb76ZakKDM2fOcObMGebMmUO1atUYM2aMxQmjnObzzz+ncePGFstq1KiBg4MDkZGRTJs2jXz58gFJsU7+/Fr7nKfnmWeeYeLEiTg6OnLz5k1atGhhJBenT5+mbt2691VfcHAwn3zyCQBdunTh+eef5+7du0Z9ySc15s+fb7ymU6dOfPDBB0DSZYZvvfUWv/zyy31tt2fPnly/fj3VyZUbN27w888/8/PPPzNy5EgGDx5scZ/dDz/8YIyMPfHEE0yfPt0Y1fvkk0+YP38+UVFRLF68mJCQkPs+Lok8SBrhEskDUp4pzsj9K4899pjxc9++fRkwYABLlizh7NmzDB8+nFGjRvHGG28YScX9Sj4TbIuUl0Pmy5fPInH75zTD2eWnn34yfu7Vq5dFXCpWrGhxz8CGDRvSrOOFF14wEhDAYpQrIxMapGzD888/byRbkJRwJ09CAEmXKqa8dDG7dOjQgS+//NJILG/cuMHWrVst7gmydr9ORt77I0eOGCcVypYta5GA+/j4GCM60dHR/P7771bb++ijjxojWVOmTOH1119n2rRpHDx4kODgYL7++mv69OmTpTf1BwcHkz9/fiDpcuCU7b/fWQUhaSKU5Pu4du3aRWJiopFwubm5UaNGjQzX1bhxY5555hkAEhMT+eSTT2z+HJUqVYrly5fz5ZdfUr9+faPPKR05coTOnTunuvcwp3B3d091zxXAm2++ybfffsvcuXPJly8f165d4+eff2bjxo1GGVvuS+vcuTOOjo5A0smRWrVqGetiYmLuu75u3boZP/v4+Fhc6plc319//WUR/5Sz3Lq4uBgJ+P0wmUwMHTqUlStX0qFDhzSPI9HR0QwbNozFixcby1KO4r300ksWl1CmPDGWlSPOItlFI1wieUDKg3FG7rt4+eWX2bp1K5s2bSImJoYff/zRGAUpVqwYzZs3p3v37unej2SNq6urRWJxP7y8vFK1P+WlZSmnN7cmq5ONlCMhaU0Xn3JZeme2S5QoYfF7ypvJM9Lef2tDyiT61q1b3Lhxw+b3ITMOHjzIDz/8wO7du1PdywWkexlZRt/7lM8PCw8Pt3oj/5kzZ6zOQlexYkXeeecdxo0bR0JCAjt27DBGg9zc3Khfvz5du3bN0in0M/s5SEvyfVw3btxg586dHDt2DEi6f+t+7vsB+OCDD/jtt9+4c+cOv//+u8UX4vvl5OREy5YtadmyJffu3ePgwYPs3LmTNWvWGJc0R0REMH36dN5//32bt2MvJUuWTPe5hjt27GD58uXs27cvzWfa2XK5ZFZ/NlJePp1efSknOClUqFCqfcb93oeWUtWqVfn444/5+OOPOXfuHL/99hubNm0yHgsA8PXXX9OmTRtcXFws4jh48GAGDx6cZr3/nDxDJDdQwiWSB6S8Hj/ll9T0ODk58d1337Fz505Wr17N9u3bjbOc165dY86cOaxYsYIlS5ZkqL6UUl7eeL/Suv8p5Q3b6X15/OeXkfTuo7LVv31pTfnlKr371ZIvO0p2vw+ovp82PCgzZ85k9OjRmM1m3NzcaNiwIX5+fpQpU8bicr20ZPS9T/leOzs7G/dtpSUjN/v37NmTRo0asWLFCmOShOQHi69du5Z169bx5Zdf8vzzz/9rXRmR2c9BWurUqWPcB/jNN98YMbJlynMfHx969epl3MNly71cmzdv5tq1a1y7do327dtTrFgxXFxcCAwMJDAwkD59+vD222+zbt06gFSTwOQU6e3LRo0axcyZM4GkkajmzZvj5+eHk5MTw4cPt3l7Wf3ZyEh9Kfcbae1DMnr/bbITJ05w4sQJrl27RqVKlYx7rHx9ffH19aVDhw5s2LDBGDmLiIggPDycSpUqWfy9FixYMNXslskyMhmOSE6jhEsklzObzfz666/G7/fzJaty5co8+eSTmEwm/vzzT/bt28e0adM4efIkt27dYsaMGXz66af31Z70DpIZcevWLS5fvmxxpjflKEny88XA8svDPy/f+fvvv21uQ1pKlSplXMZ29OhRi9Gk5GXJki/vymopRxtTbi9Z8qgGJJ2pLly4sF3akZ6bN28ybtw4zGYzzs7O/Pjjj5QuXRrI2EQuGX3vU16eVKZMGdauXWtRT0JCgnFZVkZ5e3vTq1cvBgwYwI0bNzhw4ABLlixh48aNmM1mvv322yxLuOzhySefNH5OedltRifM+Kfu3buzcuVKzp49a9xTcz8+/vhj4wROgQIFUk3T7ejoSO3atY2EK/m+opwmrX3ZmTNnjGSrWLFirF692kj6k+8lyk1S7lNv3rxJRESE8ZgR4L4fW/HTTz/x3XffAUkj8WnNKPjPz2Xy++/t7W2MfH700UcWf3OJiYlZcnJC5EHRp1ckl5s8ebIxi5Szs3OaD/tMyWw289Zbb/HEE0/w9NNPG/cG+fj40KZNG4sZnlJe4pHyYGdtBOl+z4j+04QJE4yf7927x/Tp043f/f39jZ9Tjmz88ccfFnUkf5FLS8p+ZPR5TSnv4/juu++4du2a8fu5c+eYO3eu8XuTJk0yVOf9StmG1atXs2/fPuP36Ohoxo0bZ/zeqFGjTL8P9+vcuXPGFydHR0eLiSZSPgjV2qVRGXnvq1evbswMee7cOYsvuVevXiUwMJDmzZvTt29fi/cpLePHj+eZZ57B39+fMWPGAEnJ6rPPPkuPHj2Mcjn1HqNk3t7elC1b1mKZm5ubzfeeubi48NFHH9ncnpRfskNDQzl79qzF+hs3bljMzHk/zwnLTmn9DR0/ftz42cXFxfgsms3mDH/Oc5LSpUtbnMxJTpYgKRH65ptv7qu+5HsAIekevZR/w5AUp6lTpxq/58uXzzhJlTIRmz9/vsXjDD7//HMCAwPp2LGjxSQfGT0uiTxoGuESySWSH1QMSQfzmJgYDh06ZDGyERIS8q8TXZhMJnx9fY0Z7wYPHszatWspWbIkly5dsni20T8nZkh2+PBhhg0bhqurq8WDJ7PC4sWLOXXqFNWrV+e3334zZm5Lfn5LsqpVqxo/7969mw8//JDq1auzceNGq2eaU/Zj2rRp/PHHH9SvXz/VTGQpdejQgQULFvD3339z4cIFWrduzTPPPENcXBwbN240JjuoXr16piYMseaJJ54gICCAvXv3Eh8fT5cuXWjYsCGFChVi+/btxiyKBQoUsOlGd2umTZtm8WXyn/r162fxubtz5w6vvPIKQUFBHD161CI5tDaZQEbee1dXV9q3b2+MMvTq1YtGjRrh7e3Nxo0biY6OJjo6moIFCxrT0aenevXqxvTxCxYs4MyZMzz66KPcunUr3b+DnCowMNDiPj9b7t9K6cknn6RVq1asWrXqvl/bo0cPVq5cyZ07d7hx4watW7emQYMGlCpVisjISLZu3cqtW7eApC/Mts5o+iCk/ExdvHiR4OBg/Pz82Lt3r8W+OCc9zPnfdOzY0Ti2zJkzh+PHj1OpUiV27tyZ6lmN/6ZWrVrUrVvXuBfy888/58cff+Txxx8nMTGRAwcOWMxc2b59e2Of3K5dO6ZNm0ZsbCx79+6lVatWPP3001y9etWYjGjfvn0Wk+tk13FJJLOUcInkEtHR0UyZMiXd9R06dPjXBx4n69+/P8eOHWPnzp3ExcWlOSLk5+dn8UWoZs2aODs7ExcXR3x8PIsWLaJUqVJZemCrW7culy5d4sCBAxw4cMBiXZ8+fYznhAE0bdqUCRMmGJedLV682LjB/59nQVPy9/c3Dt7JDwwuWrSo1YSrePHihIaG0q9fPyIiIoiMjDQeNJ2sSpUqxpTO9uDg4MC4cePo1asXR44cSfN9K1iwIBMmTDAu5csqp0+ftnpZYPIzpZo3b25c4nf27FljZMPZ2RknJydu377NjRs3iI6OTnV/zP289/379+fo0aPs3r2bhIQEfv75Z4vyJUqUYOzYsf/ar2effZa33nrLeAjs7t27jWnokxUtWtSYJjsnCwwM5IcffjB+t+X+rX8aMmQIW7duzdCjJlLy8fHh66+/5p133iE2Npa4uLg0Z+90dnbmo48+uq+ZFB+0gIAAatWqZTxY+o8//jBG2N3c3Lhz5w6JiYlcvHgRs9mc7SPNtujatSs7duwwZgncs2eP8aD6tm3bsnz5ciDjVy+MHTuWHj16GHFJfjj8P9WrV89iYgxvb2/Gjh1L//79iYuLM/bPKb355pvUq1fP+D07jksiWUGXFIrkUq6urvj4+NC6dWvmzZvHxx9/nOEDYr58+ZgyZYpxmUaJEiVwdnbG09MTPz8/3nvvPWbPnm0xlXOxYsUYN24cjzzyCM7OzhQuXDjN2fIyo0CBAixatIjOnTtTrFgx8uXLR40aNfjqq6/o06dPqv7PnTuX1q1bU7hwYVxdXalZsyZffvklQ4YMSXcbr732Gp06dcLLywsXFxfKli2bodkYAwICWLVqFb1796ZKlSq4ubnh5uZGtWrVePfdd1m8eLHN0+hnlLe3N4sWLeLjjz+mTp06FCpUCBcXF8qXL0+XLl1YtWqV8ZDQB2Hs2LG8/fbbVKhQgXz58lGqVCmeffZZ5s2bZ1xqaTab2bRpU6rX3u97P2PGDIYNG4afnx+enp7kz5+fChUq8Prrr7N06dJUl9il5+2332b27Nk0adKEsmXLki9fPlxdXXnkkUfo3r07//nPf+574pgH4Z8Jlq33b6VUtGhR+vfvb9Nrn332WX766SfefPNNqlWrhqenJ46OjhQsWJDKlSvTuXNn/vOf/9CuXbtMtzM7OTg4MG3aNLp37258XsqWLUuLFi344YcfjBkt//777xw7Gcg/OTs7M2XKFHr37o2Pjw8uLi74+voybNgwhg4dapSz9ky7lLy8vFi0aBEjR46kXr16FCtWDGdnZ1xdXSldujTNmjXjm2++YerUqakmwGjcuDErV66kbdu2lCpVCmdnZ4oVK8bTTz/Nd999xzvvvGNRPjuOSyJZwWTOCVNbiYiIiEi2mzNnDgCFCxembNmyFqPJu3fvNiY9qVy5sk2XmIqILikUEREReWitX7+eXbt2AUmjXa1ataJQoUJcu3bN4l7GlBNiiMj90QiXiIiIyENq165dvPHGGxazAv5T+fLlWbRoEYUKFcq+honkIUq4RERERB5iJ06cYObMmRw4cIDLly9z9+5dXF1dKV++PA0bNqRLly4Wj3oQkfujhEtERERERMRONEuhiIiIiIiInSjhEhERERERsRMlXCIiIiIiInaSY6aF37VrF507d053fd++fenTpw9nz55l9OjR7Nu3DycnJxo1asSQIUMoUKCAUTY6OpoxY8awceNGYmJi8PPzY+jQoVSqVMmizhkzZjBv3jyuXLlChQoV6Nu3L40bN063Ddeu3cp8R3MxLy93IiNjHnQzcizFxzrFxzrFxzrFxzrFxzrFxzrFxzrFJ30Pe2yKFcvYZDI5JuGqVq0aixYtSrX866+/5vDhwzz//PNERUXRtWtXihcvzpgxY4iIiGDs2LFcvnyZ6dOnG68ZMGAAv//+O4MGDcLDw4PQ0FC6dOnC6tWrjSlNp06dyrhx4+jduzfVq1dn6dKl9OvXj1mzZlGnTp3s6nauYTKBo6MDJhNompXUFB/rFB/rFB/rFB/rFB/rFB/rFB/rFJ/0KTYZl2MSLg8PD2rVqmWxbMOGDezcuZNvvvkGX19fJk2aRFRUFCtWrMDLywsAb29vevbsyd69ewkICODAgQNs2bKFyZMn06BBAwACAgJo1KgR8+fPJyQkhDt37jBp0iS6du1K7969Aahfvz7BwcFMmDCBmTNnZmfXRUREREQkj8qx93DduXOHzz77jGeeeYbmzZsDsGPHDvz9/Y1kC6BevXq4u7uzbds2o4ybmxtBQUFGGS8vL+rUqWOUOXToEFFRUTRt2tQoYzKZaNKkCbt37+bOnTvZ0UUREREREcnjcswI1z/NnDmTq1evMmvWLGPZmTNnaNGihUU5BwcHypQpQ1hYmFGmTJkyODlZdq1s2bKsWrXKKANJT05PqVy5ciQkJBAeHk7lypXTbJfJlJle5V7J/X5Y+/9vFB/rFB/rFB/rFB/rFB/rFB/rFB/rFJ/0KTYZlyMTrnv37jFnzhxatGhBuXLljOVRUVG4u7unKu/u7k50dDQAt27dwsPDI80yMTExRhkgVbnkupPr+icvL3ccHXPsoGC2KFJET5q3RvGxTvGxTvGxTvGxTvGxTvGxTvGxTvFJn2Lz73JkwrV27VquX7/OG2+8kWqdKY002mw2G8sTExPTLJPytYmJiWmuN//3jj8Hh7STqsjImIc2izeZkv6gIiJu6cbINCg+1ik+1ik+1ik+1ik+1ik+1ik+1ik+6VNsoGjRXDZLYUrr1q3jkUceoWrVqhbLPTw80hx9io2NpUSJEgB4enoSERGRqkxMTAyenklBSZ5CPiYmhoIFC1rUk1xHeh7WD1Qyszlvx+DcubOMGPEJ27ZtJjHRTEBAHT75ZCRVqlSlePEC6b7Ox6cs4eHnU8Vn1qzpDBrUHx+fsuzb94exPDIygq++GstPP63h+vWrlC1bjg4dOtGzZy8cHR3t2cUHKq9/fjJL8bFO8bFO8bFO8bFO8bFO8UmfYvPvclzCFRcXxy+//JLm6Javry/h4eEWyxITE7lw4YIxAYavry87duwgMTHRYqQqPDycihUrGmUAzp8/z+OPP26UOX/+PC4uLvj4+GR5vyTnCw8/T4sWjYiIiCB//vyYzWY2bdrA0aNH2LbtN0qWLJXqNdeuXSU+Pp5SpUqnWnfp0l8MH/5RquX37t2jbdvnOXbsKA4ODnh6FuD48WN89NH7nDp1gnHjxtulfyIiIiKS/XLcDUknT57k9u3b+Pv7p1oXFBTEnj17iIyMNJZt376dmJgYY1bCunXrEhMTw/bt240ykZGR7Nmzh7p16wLg5+eHm5sb69atM8qYzWbWr19PYGAgLi4u9uqe5GAjR35CREQEjRs35cSJ8/z++wlKlizFjRt/s23bFg4dOm7xb/r0OSQmJlK4cGG++25KqvreffcdoqJuplq+bt0ajh07Sv78+dm69TdOnQrn/feHATBv3myuXbtm976KiIiISPbIcSNcJ0+eBDBGo1Lq2LEjc+fOpVu3bvTp04cbN24wduxY6tevj5+fHwB16tQhMDCQQYMGMWjQIAoVKsT48ePx9PQkODgYAFdXV7p3786ECRNwdnbGz8+PpUuXcuTIEYtZEeXhkZCQwNq1awB4883euLq64urqys6d+3Fzc0tVPi4ujnfe6UtiYiIffzwCH5+yFuuXL/+BtWvXkC9fPu7evWuxzsnJmebNn6dw4cJUqZJ02exzz7Vk5MhPMZvNXL78F8WKFbNTT0VEREQkO+W4Ea7r168DWNxblczLy4vZs2dTuHBhBg4cyFdffUXz5s356quvLMqFhobSqFEjxowZw5AhQ/D29mbmzJkWdfbp04d+/fqxYsUK+vbty4ULF5g4cWKaI2uS94WFnTXu4Tt16gRPPFGLsmWL06lTMCdPnkhVfvbs6Rw7dpTatf0JDn7VYl1kZARDh75L/vz5CQnpm+q1zz33PLNnL+CbbyYay3bu/AUAR0fHVMmbiIiIiOReJrNZt7ll1LVrtx50Ex4YkylpJpbr1/PmTDR79uzi+eebAEmzWbq6unH37h0SEhIoWrQomzfvxNvbG0i6b/Cpp2pz7txZZs9eSPPmLSzi06tXD374YRFDh36Et3cJ+vXrlWrSjJT++OMwbdq0ICrqJm3avMjkyTOzq9vZJq9/fjJL8bFO8bFO8bFO8bFO8bFO8UmfYgPFimVslsIcN8Il8iCk3FE0a/YcJ0+eZ//+I5QsWYrr168zY8ZkY/369es4d+4s5cqVp1mz5yzq2bhxPT/8sIhHH61GSEi/f93u778f5OWXWxEVdZNixYozfPjnWdYnEREREXnwlHCJ8L9HBQC89loXXFxcKFmyFC1btgbg0KGDxvrVq/8DQKtWbSye+RYdHc2gQW/j4ODAuHHf4uzsbHWbe/bs4sUXWxEZGUnhwoVZuHCpMYomIiIiInlDjps0Q+RB8PWtgLOzM3FxccTExBjLHR2d/vv//56NtXXrZgCaNm1uUcfevXv588+kxxY891wji3V//hlO8eIF+Pbb7wgOfpWjR4/QocPLxsjWkiUreeyxanbpm4iIiIg8OBrhEgHy5cvHM880BGDSpAlERd3k778jWbt2NQC1awcAcP58GJcu/YWDgwM1atRMVUfJkqUs/hUqVAhISthKliyFm5sbsbGxdO3akaiom3h6FmDFijVKtkRERETyKI1wifzX0KEf88svO9i/fx/VqlUC4O7du5QqVZquXV8Hkh5mDODjUxZ3d3eL1z/11FP8/vtxi/vBFi6cR79+vShVqrQxaca0aZMJCzsHQHx8HC+/3NqinrlzF6VK5kREREQkd9IIl8h/PfZYNVatWkuDBs/i6OiIi0s+WrVqw6pV6/DyKgLAtWtXAShSpIjN2/n555+Mn2/fvs2lS39Z/Pvnc7tEREREJPfStPD3QdPCP9xTf1qj+Fin+Fin+Fin+Fin+Fin+Fin+Fin+KRPsdG08CIiIiIiIg+c7uGSPKlTp1eM+6Syi6OjAwkJidm6zfLlfZkzZ1G2blNEREREMk4Jl+RJYWHnOH3mLIWKVczGrZoB07+Wyio3rp3Jtm2JiIiIiG2UcEmeVahYRboP2/egm2E30z/1JynJExEREZGcSvdwiYiIiIiI2IkSLhERERERETtRwiUiIiIiImInSrhERERERETsRAmXiIiIiIiInSjhEhERERERsRMlXCIiIiIiInaihEtERERERMROlHCJiIiIiIjYiRIuERERERERO1HCJSIiIiIiYidKuEREREREROxECZeIiIiIiIidKOESERERERGxEyVcIiIiIiIidqKES0RERCQXO3fuLG+80YXKlctSqZIPwcEvcuLEcWP9+vVradWqGZUq+VCtWiU6dXqFkydPpKpn2rTJ1KsXiI9PMerUeZzx47/GbDYb6w8f/p3ixQuk+lepkk+29FMkt3J60A0QEREREduEh5+nRYtGREREkD9/fsxmM5s2beDo0SNs2/YbmzZt4K23XgfAw8OTv/+OZN26n9ixYzvr12/lkUceAeCjj4YyceJ4AAoWLMT582EMHz4MgL59+wNw9OgfALi5uVGwYCGjDQUKFMim3orkThrhEhEREcmlRo78hIiICBo3bsqJE+f5/fcTlCxZihs3/mbbti18/fUXAAQHv8rp039y8OBxSpUqTUxMNFOnfg/A8ePH+e67UBwdHVm6dBWnToXz4YefYjKZWLlymbGto0ePANC5c3cOHTpu/Nu+fXf2d1wkF9EIl4iIiEgulJCQwNq1awB4883euLq64urqys6d+3FzcyMxMZGff15LsWLF6dixEw4ODhQvXpyAgED+85/l/PXXRQCWL1+O2WzG378O9eo1AKBXrz68+WYILi4uxvaOHEka4apQoWI291Qkd9MIl4iIiEguFBZ2ltjYWABOnTrBE0/UomzZ4nTqFMzJkydwcHAgNHQSS5eu4sknnwbg3r177Nu3B4Dy5SsAcPjwYQCKFClKnz5vUr58Cfz9q/Pdd+Mt7uFKvqRwxowplC9fksceq8B77w002iAiaVPCJSIiIpILRUZGGj8PHfouV65cIS4uju3bt9CmzXNcuXLForzZbGbw4Le5ePECjo6OdOzYCYCIiAgA1q5dzeLFC3B0dOLSpb8YMeITPv/8MwCuXLnC9evXADh27CiOjo5cv36dadMm07VrR/t3ViQXU8IlIiIikgulGHyiWbPnOHnyPPv3H6FkyVJcv36dGTMmG+sTExN5552+zJ8/B4C33x5E1aqP/reepIocHBxYtepnzpy5wKBB7wEwceJ4oqOjSUxM4M03Q+jQ4TX27j3MmTMX+OqrUAC2bNnEb7/tzI4ui+RKSrhEREREcqGUswO+9loXXFxcKFmyFC1btgbg0KGDQNK9XiEhbzBv3mwAXn21s5FQARQsWBCA6tUf54knngSgR4+3ALhz5w4nTx6nZMlSDB8+mm++mUjZsuWMepJnK/z99wP266hILqeES0QkC/zbc3CSrVy5jOLFC/D00/6p1u3du5t27V7A17cUVauWp337Nhw+fCjN7SUmJtKgwVMUL16A5ct/yPL+iEjO5+tbAWdnZwBiYmKM5Y6OTv/93xGAAQP6sWxZ0n6ie/cejBs3HpPJZJR/7LHH/ltHtLHMyel/86o5OjoSHn6eVatW8p//LLdoQ3x8PAAFChTMsn6J5DVKuEREMin5OTj/+c9y7ty5w927d9i0aQPt2r3AjRt/G+WOHz/Ge+8NTLOOY8eO0bZtS7Zu3YzZbCY2NpYtWzbx/PNNOH78mEVZs9nM++8P4tixI3btl4jkbPny5eOZZxoCMGnSBKKibvL335GsXbsagNq1A5g9e4ZxGWGnTl0ZPfpLi2QLoFWrVgCcPn2KZcuWALBgwVwA3N09qFLlUQ4dOsjrr3eiV683+O23XwGYPn0KMTHRODk58dRTQfbvsEgupYRLRCST/u05OHfv3mXq1O957rlGXL9+Pc06fvjhB+Lj43nmmYacOBHGkSOn8fEpy507d4wvQJB0s/rLL7/A9OlTsqt7IpKDDR36MW5u7uzfv49q1Srx+ONVCAs7R6lSpXntta588cVoo+zatWuoWbOq8S8kpAcAAQEBtG/fAYC33nqdihXLMHTouwC8885g8ufPT9OmzalVy4+4uDhat25OpUo+DBky4L+v6UO5cuWzt+MiuYgSLhGRTEjrOTiFC3uxc+d+wsOv0rp1W2bNmsb77w/GbDYTEBCYZj0ffvghf/55lRkz5pEvXz6uX79ObGzSJUIlS5YyyrVu3Zzt27fQoMGz9u6aiOQCjz1WjVWr1tKgwbM4Ojri4pKPVq3asGrVOsLDw7h8+ZJR9tq1q1y69JfxLyLifyeAvvlmAoMHv//fEz23qVTpEcaO/Zq+ffsDSaNpCxYs4/XXe+LjU5a7d+9QqdIjjBjxOR9++El2d1skV9GDj0VEMuGfz8EZPPhtLl36izp1nmTUqLFUrlwFBwcHnnuuJR988DHLl//A3r2706zLyckJd3cn3nyzGytWLMNsNvPqq53p1KmrUaZUqVIMGjSEN954ixIlCmVDD0Ukp6tRoyZLlqxMtdzHpyxXr0ZlqA4nJycGDhzCwIFD0i1TpEgRRo36glGjvrC5rSIPIyVcIiKZ8M/n4Li6ulk8B2fz5p1069aDN954K8N1Hj9+DLPZjIODA3///Te3bkVRuLAXAJs2/WLcCC8ieUunTq8QFnYu27fr6OhAQkJitm2vfHlf5sxZlG3bE3nQlHCJiGTCP5+DM3XqbCIirtO8eUMuXfqLGTMmM2TIh/dV5+LFKwEzXbt2ZM2aVcTHxzF37mIAJVsieVhY2DnOnTlFRW+vbN2umey7x+TMlch/LySSxyjhEhHJBGvPwZky5XvjOTj3w9vbG4CQkP/j9dc7sWHDz9y9e5d8+fJlVbNFJIeq6O3FvlH9HnQz7Mb/vW/JvrE0kZxBk2aIiGRCRp+D82++//57QkJ6sHLlslTrEhMTiYuLy4LWioiISHZTwiUikgkZeQ5ORhw9epQlSxbxxRejiYyMIDY2lunTJwNQq5YfHh4e9umAiIiI2JUuKRQRyaShQz/ml192GM/BAbh79y6lSpWma9fXM1THu+++y4IFCzhx4jiPP540s+GdO3dwcXHh009H/3sFIiIikiNphEtEJJOsPQfHy6tIhuooXbo0a9ZsoFWrNhQsWAiTyUS9eg1YufInnnzyKTv3QEREROxFCZeIZMgjj5SlePECqf4dPvw7ALNmTScoKIAyZYri71+dL7/8nPj4eIs6vv9+Qpp1dO7cwShz/fp1Bgzoh5/fY5Qr503dunX4/vtQzCmnA8yBkp+DExZ2mTNnLjBt2mx8fMqmKjd48PtcvRrFr7/uS7XO17cC06bN5siR05w/f4WlS1fh718n3W1evRrF1atRtG37cpb2RUREHh5ZcXxPadas6RQvXgB//+oWy8PDz/P6652pVMmH8uVL0K7dC8Y28jpdUigi/+rChT+5efMGjo6OFC/ubbHOxcWFr7/+gpEjPwXA07MAf/4ZzuefjyAs7Bzjx39vlD169AgAhQoVwtXVzVhepEjSKJDZbKZLlw7s2bMLR0dHChQowMmTJxg27H3u3r3L//3fAHt39aF5Dg7oWTgiIg+7zBzfQ0O/T1XfpUt/MXz4R6mWX79+nZYtm3L58iVjxt2tWzfTunVzVq9ez2OPVbND73IOjXA9ZLLiLMbx48fo3r0T1as/QsWKZWjRojEbNqyzKHPp0l/06fMmjz1WgfLlS9KkSQP+85/l2dZPyVpHj/4BQLVqNTh06LjFPx+fsnz99RcAjBnzFWfOXGDSpOkALFo0n0OHDqSoJynhGj9+kkUdX30VCsCZM6fZs2cX+fPn59df93HixHk++OATAP7znxXZ0tewsHOcOXuW23GmbP0Xfcecrds7c/bsA0ksRWyRlWfgL168QNmyxSlevABXrlyxWJdbR9hFbJVVx/dk7777DlFRN1Mtnz59MpcvX+KRRyrzxx+nOHLkNP7+AcTERDNy5Cd27GHOoBGuh0hWnMU4c+Y0zz3XiJiYaFxcXHBycmbv3t107NiOiROn8PLLr3D37l3atn2es2fP4OzsjKurG4cOHeCNN7rw9dfRdOzYKdv7Lplz5EjSDrlChQqp1p04cYzY2FgA2rULBqBt25f58svPOXnyBGvXrqFWLT8SEhI4ceLYf+upmOZ2kqc+N5lMKaZTT/qiU6JEiSzrz78p5VOR75YcyrbtPQi92tUkObYiOVlWjbAD3LoVxRtvdOHOnTuptpMTRthFsltmj++NGtU3yi9f/gNr164hX7583L1716Kugwf3A9CkSXMKFiwEwFtv9aFHj65s3ryRe/fu4eLikuX9yyk0wvUQyYqzGJMnf0dMTDSPPvoYx46d5eTJ8zRp0gyAb78dB8Du3b9x6dJfFC/uzf79Rzh58jwtW74AwLx5s7O1z5I1kkem9u/fb4xadu4czPnzYRZnfu/e/d+XGGfnpB3nqVMnATh58qTxJeett17Hx6cYdeo8zrRpk4zXPProY9Sr14Dbt2/z5JN+VKlSjs8++5hHH32Mzz773O79FJGcJ6vOwK9fv45Gjeqxb9+eNLeTE0bYRbJbZo7vJ0+eNJZFRkYwdOi75M+fn5CQvqm2k1xXWvXExcVx7tzZLOxVzqOE6yFiy1mMypWrALB27RoASpYsRcOGjXnttS54ehbAxcWFRo2aAnDx4kUA6tVrQFjYZXbu3Ie3dwliYqKJiLgOQKlSpe3YQ7GXI0cOAxAeHsbdu/eIjY1h7do1tGrVjOLFvXFzcwfgyy8/Jzo6mlWrVhhfkm7evAHAoUP/GzE6duwIjo5OnD8fxnvvDeKbb7401oWGTqJUqdLEx8fz999/A3rwr8jDLCuOXYcOHaJjx3aEhZ2jfv1n09xOThlhF8lOmTm+R0XdMOr54IMhXL9+jQED3sXXN/VVLMkTQK1cuYw//jjMtWvXmDx5orH+5s3UlyHmJTku4Tp48CCdOnWiVq1aPP3007z77rtEREQY68+ePUvPnj3x9/fniSee4P333ycqKsqijujoaIYNG0ZQUBC1atWiW7dunD59OtW2ZsyYQePGjalRowYvvPACGzZssHv/HqSsOIvRv/8AFi5cRo8evYwyv/32C5A0w1oyk8mEp2cBpk2bTNWqvuzc+Qv+/nX47DM9Tyg3at26LS++2I4VK9Zw5swFNm36BTc3Ny5fvsTixQsYMOBdAKZM+Z4KFUrx+uudcXZ2BjC+uPj4+NC16+v06dOfkyfDOX36T4KDXwXgq6++4M6dO9y8eYM2bVpw7dpVFi1azunTf/Laa104ceI43bq9qvsoRB5CWTHCbjabqVXLjwULfuDttwemuR2NsMvDKDPHdweHpOP7xo3r+eGHRTz6aDVCQvqluZ3u3XtQunQZrl+/TsOGQVSrVpG9e3cb6x0dc1xKkqVyVO/++OMPOnfujJubG6GhoQwcOJBffvmF3r17AxAVFUXXrl2JjIxkzJgxDBgwgPXr19O/f3+LepKXDxgwgDFjxhAREUGXLl24ceOGUWbq1KmMHTuWtm3bEhoaSrly5ejXrx979qR9qUFekFVnMVJauHAeK1YsA+C117qkWn/69EnjrGFcXBxXr15JVUZyviFDPuD776fx9NN1AahevQYNGjQE4NChg/Tt259vvpmIn19tKlasxNtvD6RZsxYAFCpUGICgoCDGjv2KYcM+xcPDAycnJ3r2DAEgNjaG06dPMW/eHM6dO8szzzTk2WcbUaBAQYYO/RhI+uJ0/PixbO65ZJV/m/Rg9epVNG3aAF/fUlSrVokuXTpy4sTxdOtLb9rhyMgIPvxwCAEBj1O+fAnq13+C774LJSEhwa79E/vJihH2GjVqsH79VuOKjPRohD1vyor9T0Yea5IsMTGRBg2eonjxAixf/kO29NFWmTm+Fy5cmOjoaAYNehsHBwfGjfvWSMb+ycurCD/++DPt2gVTvrwvdevW5+uvJxjrCxcubOeePlg5atKMMWPG8OijjzJx4kTjrLiHhwcjRozgzz//ZM2aNURFRbFixQq8vLwA8Pb2pmfPnuzdu5eAgAAOHDjAli1bmDx5Mg0aNAAgICCARo0aMX/+fEJCQrhz5w6TJk2ia9euRjJXv359goODmTBhAjNnznwg/be31q3bEhZ2js6du/H003X544/DtGzZxOIsxvDhw5gy5XumTEm60djFxYV79+4ZZzFSmj9/Du+8k3Sdbt269encuVuqMgMGDOH994fx6acfMWvWNIKDX2LPnt9xc3NLVVZypqiom/z2269cunSJjh07GTvT+PikLyAFCxYEoEWLlrz4YjtjutfmzZMu20me6nX//v3s3XuQkiXLGA/yTa4juZ4zZ5JGok0mk7E85Vmv27dj7dJHsa9/m/Rg06b1dOuWNNpZoEBBbt68wU8//ci+fXvYvn2Xsb9Plt60w/fu3aNt2+c5duwoDg4OeHoW4PjxY3z00fucOnWCcePG26+TYjeZOXYlf5f43yWC6fvnCLu/fwAff/wBc+fOolu3V9mxY4/Fvklyh6za//zbY02Smc1m3n9/EMeOHbFnt7JEZo/vjz5ajb179/Lnn+EAPPdcI4v6//wznOLFC/Dtt98RHPwqxYt789lnoylcOCmmGzf+DICbmxvlyvnaubcPVo4Z4fr777/ZvXs3HTp0sNgxNm3alK1bt+Lj48OOHTvw9/e3OPjWq1cPd3d3tm3bBsCOHTtwc3MjKCjIKOPl5UWdOnWMMocOHSIqKoqmTf93pstkMtGkSRN2796d5uxFeUFmz2KkNH36FN5+uw+JiYk8/ngtpk+fg4ND6o9T0aJF8fQswHvvfQDAtWtX2bNnlz27KVns7t17dO7cgUGD+vP990lno37//SDbtm0BkpLtp5/255FHyvLdd0lfaDdv3sjBgwcwmUw8/3wrIOkS3jfffJ2+fd/k8uVLxMfH8/33SdPB+/pWoEwZH2P2wm3btvD77weBpIlaAFxdXalS5dHs6rZkIWuTHlSpUpVFi+YD0Llzd06dCufw4ZOULFmKq1evsGvXb6nqS2/a4XXr1nDs2FHy58/P1q2/cepUOO+/PwxImrDn2rVrduyl2EtWjLBnhEbY86as2v/822NNAI4dO8rLL7/A9OlTsrGHtsvs8b1ly1bky5ePkiVLWfwrVKgQkHSio2TJUri5ubFs2RJ8fIpRv/6TREREcPv2bWObzz3XMkMnRXKzHDPCdeLECcxmM0WKFGHAgAFs2rQJgEaNGvHhhx/+9+z3GVq0aGHxOgcHB8qUKUNYWBgAZ86coUyZMjg5WXatbNmyrFq1yigDUL58eYsy5cqVIyEhgfDwcCpXrpxmO3Prya2MnMUwmeD551vy0kv/O4vRrJnlKIXJlHQZ4XvvDcRsNlOnTiALFvxgTPEJsGXLJlauXI63tzdDhnxgvC7ZvXt3c20ccyJ7x7J48WJ0796DqVMnMXz4ML7++guio28Z7//LL7fnr78uMnLkp4wc+SkTJnxrXMbTu3c/KlV6BJMJ+vfvz5w5czl/Pozatavh4pKP2NgYHBwc+OyzUTg4mHjttU5MmzaJCxf+pHHj+nh6FuDWraR7NPv1exsPD3f7dvYhlB1/iyknPUhre3FxSc9LcnR0+O96s3FvTokS3sZrTKa0px1OXu/s7Mxzzz1PoUKFqVq1KpB0ZnbkyE8xm81cvvwXxYsXs1s/H5SU8clrsuLY9c/4pIyTyfS/38+e/d8Ie/IyJ6f/nUi8cyc2T8b4QcmuWGbF/iflY00qVqyYbttbt27OzZs3eOaZZ9myZTNg+RnLabLi+F6kiCeHDx8n5S3WCxbMo1+/XpQqVZr9+5Pi//ffkRQpUpQrVy5Tq1ZVTCYTd+7coUiRIgwdOizHxiir5JiEKzIyEoD333+f+vXrM3HiRMLCwhg3bhx//vknCxYsICoqCnf31F+43N3diY6OBuDWrVt4eHikWSYmJsYoA6Qql1x3cl3/5OXlnmtv6ktMvE2nTh1ITEwkIeEugwcPZv/+/cZZjBYtmlG3bh1OnDjBiBEjeP/99/n555+NsxivvZZ0jfJff4UxYMD/YTab8fPzY9Omjani6OCQwNy5s3B1daVjx1eoXbs2Y8d+BkD+/Plp1qwhRYp42rW/Se9T3p9gwdHRgaJF7RtLgO++C+XRRyszbdo0zp49S4kSJWjXrh3Dhw+nQIECDB/+ES4uDsyYMYPLly/z6KOP0rt3b+OSXYAiRTzZsWM7H374Ib/++iu3bt3iqaee4uOPPzZGm4sW9WTPnt188sknrFmzhsuXL1O5cmX69u1Lnz597N5P+O9nJy7vf3Yg+z4/Z86cAODQoQM89lhFYmNjadSoEV9//TW+vr68/XY/fvrpR2bMmMry5T8QGxuL2Wzm008/pUmTZ1LUdI8PPhhC/vz5GTBgACNGjMDBwWT0oVOnYDp1CrbY9g8/7PtvXx3x86tG4cL27++DYu/96oOQ2WNXp04djLgk/1+wYMrLwTyMz0+NGo8BSSPs4eGnqF27NqGhSTOourq6EhQUmOZ3kKzk6OjwEBy5sm/fA1mz/zl27Jhx9VPv3j04evQopUuX5u2337Y4Nvn4lOGTTz6mb9++xoiNp6drtvXVFll1fE/J0zM/gMX+uWhRT37+eR0DBgxgz549ODo60qpVK0aNGkXFimk/mzMvyTEJV/INqdWqVWPEiBEAPPXUUxQoUIB33nmHX35JmgkvreunzWazsTwxMTHda6xTlklL8hmNtC6NA4iMjMm1GbiDg6txFuPdd9/ls89GWJzFaNq0FcePn2bkyE8ZOnQoY8aMtTiLUaRISQA++GAY9+7dA+Ds2XPG1LsA+fLlY8+eQwQFNeTJJ5/mt99+JSAgAHd3D6Kjk5Lcd98ditnswvXrt+za34SERCCXvln3ISEh0e6xTNa5cw86d+5hsezePYzt9+79Dr17v2OxPnmdyZS0Qy5ZshxTpqR+FlvKPjg5uTN8+BiGDx+Tbhl7elg+O5B9n5/9+5OehXTu3Dk8PQsQExPDf/7zH3bv3sOWLb/y+ON1GDBgMGPGjDImN3JycuLGjVtcv37L+Pz06tWbq1evMnToR3h7J03TnZhoTrcPf/xxmHffHQJAq1YvkJDglG2fo+yUHJ+IiFvktYk8M3vs8vIqSUTELYv43Lz5v3tBIyKicXJK+ky0adOeb775lgsX/sTf3z/VCPvt24ncvm3/Y1fuPK17f7Lz2JUV+5+UjzU5fPgwLi75OHv2LH379uXy5ev075/0UOwNG7bj6OhIZGSMUf7Wrds5fr9j6/E9vX1Py5Yvce3aS0a5ZGXKVGTRohWptp/T42NNRpPpHJNwJZ81evZZy+dj1KtXD0g6u+Dh4ZHm6FNsbKzxjAxPT0+LaeSTxcTE4OmZFJQCBQoYy5JvCEyuJ7mO9OTmg9mnn47Cx6cc8+fP5vz5MIoX96Z16zYMGfIBDg6O9Ov3DnFxcSxcOI+rV69QuXIVunXrweuv98RsThpS37BhvVHfzZs3jAMbJCVcZnPSNKHz5i1m7NjRrFnzI5cv/8Wjjz5G797/R/v2HXJ1DHOi+41np06vEBZ2zj6NscLR0eG/yUz2KV/elzlzFmXrNnOb7Ph7tDbpwcyZ0yhYsBBjxoyiefMWfPPNRM6ePUNw8EuMGzeWypWr8tJL7Vi7di1Llvxv2uGlSxdb7cPvvx+kffs2REXdpFix4gwf/nme3/eYzbn7GJWezB67kiXHJ61lAAULFuannzbxxRej2bjxZ65evULFipV44403ef31N/NkbB+k7IpnVux/kh9r4uHhyTvvDCZ//vy8805fFi6cx1dffcGbb/Ymf/78ODg4pupXdv5dPojju47tGZNjEq7k+6mSR0+SxccnXVubP39+fH19CQ8Pt1ifmJjIhQsXjEuSfH192bFjB4mJiRYjVeHh4caQpa9v0kwo58+f5/HHHzfKnD9/HhcXF3x8fLK2czmEk5MTvXr1oVevtC/NcnBwYNCg9xg06L001zs6OnL+/KUM7Tg8PQvw6acj+fTTkZlpsthBWNg5zpw5S9FSlR7A1rPv3O31v1I/e08ejOR7OZMlT3rw008/cujQQX79dQcA77wzmMKFvfD39+Kll9oxffoUfvzxPzRr9hxvvfXWv047nGzPnl106PAyUVE3KVy4MAsXLsXb29vqayTnyuyx65+Cgupx9WpUmuu8vb0ZO/Yrm9sqOU9m9z8vvdSOoKAgqlR53OL7T8+eISxcOM94rEn16jWys1tpCgs7x9lTJyjr7ppt24zPti0lCY+5nc1bzBo5JuGqWLEipUuXZvXq1XTq1MlYvnHjRiBpaveoqCimTZtGZGSkMVPh9u3biYmJMWYlrFu3Lt9//z3bt283poWPjIxkz549vPXWWwD4+fnh5ubGunXrjITLbDazfv16AgMDcXFxybZ+20pnMSQzipaqxAff5/wpazPjs7eqAdn7eZXUMjLpQfJIueXjAJLuf7h9O5ZDhw5w/vx54N+nHT569IiRbBUrVpwlS1Yak/7Ig6cRdslOWbH/gYw91iSnKOvuyspnn3jQzbCbFzbnzpmuc0zCZTKZGDx4MP3796d///60a9eOs2fPMm7cOJo1a8Zjjz1GiRIlmDt3Lt26daNPnz7cuHGDsWPHUr9+ffz8/ACoU6cOgYGBDBo0iEGDBlGoUCHGjx+Pp6cnwcFJN1O7urrSvXt3JkyYgLOzM35+fixdupQjR44wa9asBxmGDAsLO8ep02fxKFQuG7eavQ8Ojb5xPlu3JyJZL3na4cTERKKioujbt3+qaYfXrPmRqKibfPddKKGhk7h27SqrVq0EoGZNP1xcXChdujSJif87vXz7diw3bvzv2Tpubm7ExsbStWtHoqJu4ulZgBUr1vDII2nPOCsPRljYOc6dPU3F0iWydbtmsvc5OGcuXs7GrUl6smL/A0mPNQkNDaVcufKsWrWOokWLpXqsiYg1OSbhAmjevDnfffcdEyZM4K233qJgwYIEBwfz9ttvA0nP05o9ezYjR45k4MCBuLu707x5cwYPHmxRT2hoKKNHj2bMmDEkJiZSu3Ztvv76a4szEH369MHR0ZHFixczffp0KlWqxMSJE/H398/WPmeGR6FyNO+6/t8L5lJrZzZ50E0QkUwqViz9aYcDAgJ56aX2RERE8NFH77Ns2RLWrl3D3bt3SEhIoHhxb15//U2KFy/GhQsXuH79fzdmL1z4v2mH9+1LmnZ42rTJxuhJfHwcL7/c2qItc+cuokaNmtnaf0mtYukS7J315YNuhl0FdBmg8fUcICv2P2D9sSbDh4/SA7HlX+WohAuSJs3458QZKVWuXJmZM2daraNgwYKMGjWKUaNGpVvGZDIREhJCSEiIrU0VEZEMsDbpgaOjI7169aFMmTJMnDieEyeO4+bmTr16Dfjoo+EUK5bx52b9/PNPxs+3b9/m9m3La/2Tn9slIg+PrNj/VKxYkVWr1jJq1Gfs2bOLmJhoAgICGTToPZ59ttG/tEAkByZcIiKSt/zbpAcArVq1oVWrNhmuMzj4VYKDX7VYtmjRclubKCJ5VFbtfx599DFmzZqf4e2mNzGLPJyUcImISIZp0gMReVAelv2P9j15jxIuERHJsLCwc5w9exafcr7Zut24hOydtOfP89n/pU5ErAsLO8e50yfxLVwgW7ebnXufc39rZCwvUsIlIiL3xaecL8vXbHvQzbCrti3qP+gmiEgafAsXYPubbR50M+ym3qQVD7oJYgfZOUuqiIiIiIjIQ0UJl4iIiIiIiJ0o4RIREREREbETJVwiIiIiIiJ2ooRLRERERETETpRwiYiIiIiI2IkSLhERERERETtRwiUiIiIiImInSrhERERERETsRAmXiIiIiIiInSjhEhERERERsRMlXCIiIiIiInaihEtEROQBe+SRshQvXiDVv8OHf09V9s03u1G8eAH69n3LYvnx48fo3r0T1as/QsWKZWjRojEbNqxLc3uJiYk0aPAUxYsXYPnyH+zSJxERSeL0oBsgIiLyMLtw4U9u3ryBo6MjxYt7W6xzcXGx+P3nn39i+fKlqeo4deoUzZs3IiYmGhcXF5ycnNm7dzcdO7Zj4sQpvPzyK0ZZs9nM++8P4tixI/bpkIiIWNAIl4iIyAN09OgfAFSrVoNDh45b/KtSpapR7tatKAYPfifNOr755htiYqJ59NHHOHbsLCdPnqdJk2YAfPvtOKPcsWNHefnlF5g+fYodeyQiIikp4RIREXmAjhxJSrgqVKhgtdwnnwzjr78uki9fvlTrSpcuTcOGjXnttS54ehbAxcWFRo2aAnDx4kWjXOvWzdm+fQsNGjybZe0XERHrlHCJiIg8QEePJl3at3//fh57rALly5ekc+dgzp8PM8rs3PkLc+bMoEqVqjz/fKtUdbz33nssWrSMHj16Gct+++0XAHx9/5fIlSpVis8+G82iRcvt1BsREfknJVwiIiIP0JEjhwEIDw/j7t17xMbGsHbtGlq1akZERAR37tzhnXf6AvDFF9/i7OxirToAFi6cx4oVywB47bUuxvJNm36hZ88QHBx0+BcRyS7a44qIiDxArVu35cUX27FixRrOnLnApk2/4ObmxuXLl5g1axpjx47izJnTdO7cnSeeePJf65s/fw79+/cGoG7d+nTu3M1Y5+joaLd+iIhI2jRLoYiIyAM0ZMgHFr9Xr16DBg0a8tNPP7J9+1Z27dpJiRIl+fDDj/+1runTp/DeewMxm808/ngtpk+fo9EsEZEHTHthERGRByQq6iY///wTs2ZNJy4uzlgeH5/0s49PWeLj47l8+RKVKvlQvHgBFi2aD8CiRfMpXrwA4eHngaTLCJOTrYCAQJYu/Q+FChXO/k6JiIgFjXCJiIg8IHfv3qNz5w4kJiYSFRVF3779+f33g2zbtgVISrhKlixl8ZqbN28QGxuLm5sbBQsWwsnJicOHDzNgwP9hNpupUaMmixevwMPD4wH0SERE/kkjXCIiIg9IsWLF6N69BwDDhw+jYsUyNGnSgLt37xIQEMg77wxO9WyuVq3aANCqVRsOHTpOqVKl+fTTT7l37x4A4eHnCQoKoGbNqtSsWZXAwJoPqnsiIoJGuERERB6oTz8dhY9POebPn83582EUL+5N69ZtGDLkgwxNcpGQkMBPP/1k/H7z5g1u3rxh/J7Wc7tERCT7KOESERF5gJycnOjVqw+9evXJUPnx479n/Pjvjd8dHR2Jjo7m+vVbmM0Z3+7Vq1H321QREbGBEi4REZEs0qnTK4SFncv27To6OpCQkJit2yxf3pc5cxZl6zZFRHIjJVwiIiJZJCzsHOfOnqF8WZ9s3W58fLZujrDwP7N3gyIiuZgSLhERkSxUvqwP21YtftDNsKv6rdo/6CaIiOQamqVQRERERETETpRwiYiIiIiI2IkSLhERERERETtRwiUiIiIiImInSrhERERERETsRAmXiIiIiIiInSjhEhERERERsRMlXCIiIiIiInaihEtERERERMROlHCJiIiIiIjYiRIuERERERERO1HCJSIiIiIiYidKuEREREREROxECZeIiIiIiIidKOESERERERGxEyVcIiIiIiIidqKES0RERERExE6UcImIiIiIiNiJEi4RERERERE7UcIlIiIiIiJiJ04PugEp3b59m9q1a5OYmGix3MXFhcOHDwNw9uxZRo8ezb59+3BycqJRo0YMGTKEAgUKGOWjo6MZM2YMGzduJCYmBj8/P4YOHUqlSpUs6p0xYwbz5s3jypUrVKhQgb59+9K4cWP7d1RERERERB4KOSrhOnHiBImJiYwbN47SpUsbyx0ckgbioqKi6Nq1K8WLF2fMmDFEREQwduxYLl++zPTp043yAwYM4Pfff2fQoEF4eHgQGhpKly5dWL16NYUKFQJg6tSpjBs3jt69e1O9enWWLl1Kv379mDVrFnXq1MnWfouIiIiISN6UoxKuY8eO4ezsTNOmTXF2dk61fsGCBURFRbFixQq8vLwA8Pb2pmfPnuzdu5eAgAAOHDjAli1bmDx5Mg0aNAAgICCARo0aMX/+fEJCQrhz5w6TJk2ia9eu9O7dG4D69esTHBzMhAkTmDlzZrb1WURERERE8q4cdQ/XsWPHqFSpUprJFsCOHTvw9/c3ki2AevXq4e7uzrZt24wybm5uBAUFGWW8vLyoU6eOUebQoUNERUXRtGlTo4zJZKJJkybs3r2bO3fu2KN7IiIiIiLykMlRCdfx48dxcHCgW7du1KpVi8DAQIYNG0Z0dDQAZ86cwdfX1+I1Dg4OlClThrCwMKNMmTJlcHKyHLwrW7Ys586dM8oAlC9f3qJMuXLlSEhIIDw8PN02mkw549/DRPGxTrGxTvGxTvGxTvGxTvGxTvFJn47t1ik+1mXFd+ms+JdROeaSwsTERE6ePImDgwMDBw4kJCSEw4cPExoayunTp5k7dy5RUVG4u7uneq27u7uRlN26dQsPD480y8TExBhlgFTlkutOruufvLzccXTMGTlqUjsSHnQz7M7R0YGiRT1teh2Ys75BOYwt8ckpn+HsYHN84vL+Zwdsj09cQt7f94Dt8YmPt1ODchhb4/Nw/HUpPtZk5tj+MOx9MhOfh2H3Y2t8HqQck3CZzWYmTZpE0aJFqVixIgB16tShaNGiDBo0iO3btwNgSiOdNJvNxvLExMQ0y6R87T9nQUxZD/xvko5/ioyMyTFnEBIS0u5DXpOQkMj167dseh3kkDfLjmyJT1JsHo6ky/b45P3PDmQmPg8Hxcc6W+PzcOx9FB9rMndsz/sUH+tsjY89ZDTxyzEJl6OjI0888USq5c888wyQNIOhh4dHmqNPsbGxlChRAgBPT08iIiJSlYmJicHTMykoyVPIx8TEULBgQYt6kutIj/lhOPWUwyjm1ik+1ik+1ik+1ik+1ik+1ik+6VNsrFN8rMtt8ckxJ1KuXLnC4sWLuXz5ssXy5AksChcujK+vb6r7qxITE7lw4YLxjC1fX18uXLiQahQrPDzcGDlLvg/s/PnzFmXOnz+Pi4sLPj4+WdcxERERERF5aOWYhOvevXt8+OGHLFq0yGL5mjVrcHBwwN/fn6CgIPbs2UNkZKSxfvv27cTExBizEtatW5eYmBjjEkSAyMhI9uzZQ926dQHw8/PDzc2NdevWGWXMZjPr168nMDAQFxcXe3ZVREREREQeEjnmkkIfHx9eeOEFpkyZgouLC7Vq1WLfvn18//33dOzYkQoVKtCxY0fmzp1Lt27d6NOnDzdu3GDs2LHUr18fPz8/IOm+r8DAQAYNGsSgQYMoVKgQ48ePx9PTk+DgYABcXV3p3r07EyZMwNnZGT8/P5YuXcqRI0eYNWvWgwyDiIiIiIjkITkm4QIYPnw45cqVY8WKFUycOBFvb2/69evH66+/DiQ9T2v27NmMHDmSgQMH4u7uTvPmzRk8eLBFPaGhoYwePZoxY8aQmJhI7dq1+frrry3u1+rTpw+Ojo4sXryY6dOnU6lSJSZOnIi/v3+29llERERERPKuHJVw5cuXj969e9O7d+90y1SuXJmZM2daradgwYKMGjWKUaNGpVvGZDIREhJCSEiIrc0VERERERGxKsfcwyUiIiIiIpLXKOESERERERGxEyVcIiIiIiIidqKES0RERERExE6ybNKMhIQEduzYgaOjI08//TQODsrlRERERETk4WZTwmU2mxk3bhynT5/mu+++IyEhgVdffZVDhw4B8OijjzJ79mw8PDyytLEiIiIiIiK5iU3DUDNnzmTKlCnExMQAsG7dOg4ePEijRo3o1asXp06d4vvvv8/ShoqIiIiIiOQ2No1wrVy5kqeeeorp06cDsGHDBlxcXPj8889xd3fn5s2brF+/noEDB2ZpY0VERERERHITm0a4zp8/T/PmzTGZTAD89ttv1KxZE3d3dwCqVq3KpUuXsq6VIiIiIiIiuZBNCZeLiwuJiYkAHDt2jMjISJ588kljfVRUFJ6enlnTQhERERERkVzKpoSrQoUKbN68GYBFixZhMpl45plnAIiOjmbZsmVUrFgxyxopIiIiIiKSG9mUcHXq1Int27fj7+/PwoULqVmzJtWqVePw4cM0b96cs2fP0q1bt6xuq4iIiIiISK5i06QZLVq0wMnJiWXLllGiRAn69u0LQP78+fHw8OC9997j2WefzdKGioiIiIiI5DY2P/i4adOmNG3a1GLZI488wtq1azPdKBERERERkbzA5oQL4MqVK2zZsoWLFy/y0ksv4ebmxpUrV6hevXpWtU9ERERERCTXsjnhmj17Nl988QX37t3DZDLx1FNPcffuXXr16sWrr77KBx98kJXtFBERERERyXVsmjRj8+bNjBw5Ej8/Pz755BPMZjOQNHuhn58f8+bNY9myZVnaUBERERERkdzGpoRr2rRpPPbYY0yfPt3iPq6yZcsye/ZsqlevzoIFC7KskSIiIiIiIrmRTQnXkSNHeP7553F0dEy1zsnJiRdeeIGwsLDMtk1ERERERCRXsynhAsiXL1+66+7du0d8fLytVYuIiIiIiOQJNiVclStXZvPmzWmuS0xMZM2aNTzyyCOZapiIiIiIiEhuZ1PC9dprr/HLL7/w2WefcebMGQDu3r3LkSNHCAkJ4ciRI7Rv3z5LGyoiIiIiIpLb2DQtfKtWrTh+/DjTpk1j3rx5APTq1QsAs9nMyy+/zMsvv5x1rRQREREREcmFbH4O16BBg2jWrBmrV68mLCyMhIQEypQpQ7NmzXjqqaeyso0iIiIiIiK5ks0JF8Djjz/O448/nlVtERERERERyVMylHD99ddfNlVeqlQpm14nIiIiIiKSF2Qo4WrYsCEmk+m+KjaZTBw9etSmRomIiIiIiOQFGUq42rRpc98Jl4iIiIiIyMMuQwnX6NGj7d0OERERERGRPCdTk2YAHDt2jPDwcBwdHfH19aVixYpZ0S4REREREZFcz+aEa9u2bQwfPpwLFy5YLK9cuTLDhw/X7IUiIiIiIvLQsynh2rNnDyEhIbi4uBAcHEyFChVISEjgzJkzrFq1ii5durB48WIeeeSRrG6viIiIiIhIrmFTwjV+/Hi8vLxYsmQJ3t7eFuvefPNN2rdvz/jx4/n222+zpJEiIiIiIiK5kYMtLzpy5AivvfZaqmQLoEyZMnTs2JFdu3ZlunEiIiIiIiK5mU0Jl7OzMw4O6b/Uw8MDs9lsc6NERERERETyApsSrmbNmrFw4UKioqJSrbt37x7Lly+nWbNmmW6ciIiIiIhIbmbTPVyNGzdm+/btPP/883Tp0oVHHnkEFxcXzp8/z9y5c7lw4QKvvPIKK1assHhdmzZtsqDJIiIiIiIiuYNNCVePHj2Mn7/44gtMJhOAxWWEw4cPN342m82YTCYlXCIiIiIi8lCxKeEaNWpUVrdDREREREQkz7Ep4Wrbtm1Wt0NERERERCTPsSnhShYfH8/169dJTExMc32pUqUyU72IiIiIiEiuZlPCde3aNYYOHcovv/ySbrJlMpk4evRophonIiIiIiKSm9mUcI0cOZJt27ZRs2ZNypYti5NTpgbKRERERERE8iSbMqXffvuNl19+mc8++yyr2yMiIiIiIpJn2PTg47i4OGrWrJnVbREREREREclTbEq4nn76aXbt2pXVbREREREREclTbLqkcMiQIXTo0IGRI0fSokULihUrZjz8OCXNUigiIiIiIg8zmxIuR0dHihYtypw5c5gzZ06aZTRLoYiIiIiIPOxsSrg++eQTjhw5wqOPPkrFihVxdnbO6naJiIiIiIjkejYlXLt27eLFF19k5MiRWd0eERERERGRPMOmSTNMJhN+fn5Z3RYREREREZE8xaaE68knn+S3337L6raIiIiIiIjkKTYlXO+++y67du1i+PDh7Nu3j/DwcP76669U/zKrT58+NGzY0GLZ2bNn6dmzJ/7+/jzxxBO8//77REVFWZSJjo5m2LBhBAUFUatWLbp168bp06dT1T9jxgwaN25MjRo1eOGFF9iwYUOm2ywiIiIiIpLMpnu4WrduTVxcHPPnz2f+/PlplsnsLIUrV65k/fr1lC5d2lgWFRVF165dKV68OGPGjCEiIoKxY8dy+fJlpk+fbpQbMGAAv//+O4MGDcLDw4PQ0FC6dOnC6tWrKVSoEABTp05l3Lhx9O7dm+rVq7N06VL69evHrFmzqFOnjs3tFhERERERSWZTwtWsWbM0n7uVVa5cucKIESMoUaKExfIFCxYQFRXFihUr8PLyAsDb25uePXuyd+9eAgICOHDgAFu2bGHy5Mk0aNAAgICAABo1asT8+fMJCQnhzp07TJo0ia5du9K7d28A6tevT3BwMBMmTGDmzJl265uIiIiIiDw8bEq4Ro8endXtsPDBBx8QFBREvnz52L17t7F8x44d+Pv7G8kWQL169XB3d2fbtm0EBASwY8cO3NzcCAoKMsp4eXlRp04dtm3bRkhICIcOHSIqKoqmTZsaZUwmE02aNGHcuHHcuXOH/Pnz27WPIiIiIiKS99l0D1dGXL582abXLVmyhCNHjvDhhx+mWnfmzBl8fX0tljk4OFCmTBnCwsKMMmXKlMHJyTKXLFu2LOfOnTPKAJQvX96iTLly5UhISCA8PNymtouIiIiIiKRk0wgXwOrVq1m9ejWxsbEkJiYayxMSEoiKiuLs2bMcOXLkvuq8ePEio0aNYtSoURajWMmioqJwd3dPtdzd3Z3o6GgAbt26hYeHR5plYmJijDJAqnLJdSfXlRY7Xkkp6VDMrVN8rFN8rFN8rFN8rFN8rFN80qfYWKf4WJfb4mNTwjVv3jw+++wzzGYzkHQ5XvLPAPny5eO55567rzrNZjPvv/8+DRo0oFmzZumWS+veMbPZbCxPTExM9/6ylGXSawMkjZqlxcvLHUdHuw0K3pekdiQ86GbYnaOjA0WLetr0OjD/a7nczpb45JTPcHawOT5xef+zA7bHJy4h7+97wPb4xMfbqUE5jK3xeTj+uhQfazJzbH8Y9j6Zic/DsPuxNT4Pkk0J1w8//EDJkiWZMmUKcXFxtG3blm3btmE2m5kyZQrz588nODj4vuqcN28eJ06cYNWqVcT/92iVnADFx8fj4OCAh4dHmqNPsbGxxgQbnp6eREREpCoTExODp2fSm1OgQAFjWcGCBS3qSa4jLZGRMTkmo05ISDtpzGsSEhK5fv2WTa+DHPJm2ZEt8UmKzcORdNken7z/2YHMxOfhoPhYZ2t8Ho69j+JjTeaO7Xmf4mOdrfGxh4wmfjYlXGFhYfTs2ZOKFStiNpvJnz8/Bw4coFmzZnzwwQccO3aMqVOnEhAQkOE6161bx99//03dunVTratWrRp9+vTB19c31f1ViYmJXLhwwZgAw9fXlx07dpCYmGgxUhUeHk7FihWNMgDnz5/n8ccfN8qcP38eFxcXfHx80m2n+WE49ZTDKObWKT7WKT7WKT7WKT7WKT7WKT7pU2ysU3ysy23xselESnx8PMWLFweSLtMrW7YsJ0+eNNY3bdqUEydO3Fedn3zyCT/88IPFv2effZZixYrxww8/0L59e4KCgtizZw+RkZHG67Zv305MTIwxK2HdunWJiYlh+/btRpnIyEj27NljJHN+fn64ubmxbt06o4zZbGb9+vUEBgbi4uJy/0ERERERERH5B5tGuIoXL24xC2GZMmU4deqU8burq6tFUpQRFSpUSLWsUKFCuLi4UKNGDQA6duzI3Llz6datG3369OHGjRuMHTuW+vXr4+fnB0CdOnUIDAxk0KBBDBo0iEKFCjF+/Hg8PT2NyxxdXV3p3r07EyZMwNnZGT8/P5YuXcqRI0eYNWvWfcdDREREREQkLTaNcD311FMsXLiQ48ePA1C1alV27dplJFlbt26lSJEiWdfK//Ly8mL27NkULlyYgQMH8tVXX9G8eXO++uori3KhoaE0atSIMWPGMGTIELy9vZk5c6bF/Vp9+vShX79+rFixgr59+3LhwgUmTpyIv79/lrdbREREREQeTjaNcL355pv8/PPPtG3bll9++YX27dszdepUnnvuOYoUKcK5c+fo2rVrphuX1gOWK1euzMyZM62+rmDBgsb08ukxmUyEhIQQEhKS2WaKiIiIiIikyaYRLh8fH5YtW0aXLl3w8vLC29ub77//ngIFCnDt2jVeeOEF+vXrl9VtFRERERERyVVsfvBxmTJlGDJkiPH7U089xfr167OkUSIiIiIiInlBljzuIS4ujuPHjxMWFpYV1YmIiIiIiOQJGU647t69y+TJk+nZs6fF8m3btvHss8/Stm1bnnvuOdq0aWMxY6GIiIiIiMjDKkOXFMbHx9OtWzf279+Po6MjcXFxODs7c/78efr06cO9e/cICgqicuXKrFu3jk6dOrF69Wq7zFQoIiIiIiKSW2RohGvRokXs37+fnj17snPnTpydnQH4/vvvuXfvHo0bN2batGm8++67LFmyBICpU6far9UiIiIiIiK5QIYSrp9++omgoCDeeecdChQoAIDZbGbTpk2YTCa6d+9ulC1SpAgvvPACW7dutU+LRUREREREcokMJVynTp0iKCjIYtmxY8e4efMmBQoUoHbt2hbrKlWqxKVLl7KulSIiIiIiIrlQhhKu2NhYY2Qr2d69ewFSJVuQdM+XyWTKguaJiIiIiIjkXhlKuIoUKcKVK1cslv3666+YTCaefPLJVOWPHTtGsWLFsqaFIiIiIiIiuVSGEi5/f39WrVpFXFwcAFeuXOGXX34BoFGjRhZlr127xpo1awgICMjipoqIiIiIiOQuGZoWvnv37rRr14727dvz5JNPsmHDBuLi4nj++ecpU6YMkPTw47179zJy5EhiY2Pp2LGjXRsuIiIiIiKS02VohKtatWp88cUXXLp0iRkzZvDnn38SFBTEJ598YpQZPXo03bp149SpUwwePJhq1arZrdEiIiIiIiK5QYZGuABatGhBo0aNOH36NJ6enpQtW9Zifc2aNYmLi+Oll16iZs2aWd5QERERERGR3CbDCRdAvnz50h25at26Na1bt86SRomIiIiIiOQFGbqkUERERERERO6fEi4RERERERE7UcIlIiIiIiJiJ0q4RERERERE7CRDCdeMGTM4c+aMvdsiIiIiIiKSp2Qo4fr22285ePCg8XujRo3YuHGjvdokIiIiIiKSJ2Qo4XJwcGDnzp3ExMQAcPHiRW7fvm3XhomIiIiIiOR2GXoOV7169fjxxx9ZvXo1ACaTiUGDBjFo0KB0X2MymTh69GjWtFJERERERCQXylDC9dlnn1GyZElOnjzJvXv32Lt3L76+vhQpUsTe7RMREREREcm1MpRweXh48O677xq/V61alV69etGqVSu7NUxERERERCS3y1DC9U+zZ8+mYsWKWd0WERERERGRPMWmhCswMBCAFStW8NNPP3HhwgVcXFwoWbIkzZs3p3Xr1lnaSBERERERkdzIpoTLbDbTr18/NmzYgNlsxtPTk8TERI4dO8bmzZtZu3YtEydOzOq2ioiIiIiI5CoZmhb+n+bOncv69etp1aoVW7duZc+ePezbt4/NmzfTunVrNm/ezIIFC7K6rSIiIiIiIrmKTQnX0qVLCQwMZMyYMXh7exvLS5Ysyeeff05gYCBLly7NskaKiIiIiIjkRjYlXOfOnaNJkybprm/cuDFnz561uVEiIiIiIiJ5gU0Jl5OTE7Gxsemuj42NxWQy2dwoERERERGRvMCmhKt69eosW7aMu3fvplp3+/Ztli1bxmOPPZbpxomIiIiIiORmNiVc3bt35/z587z88sv8+OOPHD9+nOPHj7Nq1SratWtHeHg43bp1y+q2ioiIiIiI5Co2TQvfoEEDBg8ezLhx4xg0aJDFOgcHB95++20aNmyYJQ0UERERERHJrWxKuCBplKtJkyZs2LCB8PBwzGYzZcuWpUmTJvj4+GRlG0VERERERHIlmxMuAB8fH106KCIiIiIikg6b7uESERERERGRf6eES0RERERExE6UcImIiIiIiNiJEi4RERERERE7sSnhWrBgAWFhYVncFBERERERkbzFpoTriy++YNWqVVndFhERERERkTzFpoTLwcGBwoULZ3VbRERERERE8hSbEq7XX3+dyZMns337dhITE7O6TSIiIiIiInmCTQ8+PnjwINHR0fTs2RMXFxcKFy6Mo6OjRRmTycSGDRuypJEiIiIiIiK5kU0J18mTJylUqBCFChUylpnNZosy//xdRERERETkYWNTwrVp06asboeIiIiIiEiekyXP4bp3757u5RIREREREfkHmxOuGzdu8Omnn1K3bl1q1arFrl272Lt3L2+99Rbnzp3LyjaKiIiIiIjkSjYlXDdu3OCVV15h/vz5uLq6Gvdr3bx5ky1btvDqq6/y559/ZmlDRUREREREchubEq7Q0FAuXrzIjBkzWLRokZFwNWrUiMmTJxMbG8vEiROztKEiIiIiIiK5jU0J16ZNm2jfvj1PPfUUJpPJYl39+vV55ZVX2LVrV5Y0UEREREREJLeyKeG6evUqVatWTXd9xYoVuXbt2n3Xm5CQwOTJk2nSpAmPP/44rVu3ZuXKlRZlzp49S8+ePfH39+eJJ57g/fffJyoqyqJMdHQ0w4YNIygoiFq1atGtWzdOnz6danszZsygcePG1KhRgxdeeEHPDRMRERERkSxlU8JVpEgRLl68mO76kydPUrhw4fuud9y4cXz77be0a9eOSZMm8fTTTzN48GBWrVoFQFRUFF27diUyMpIxY8YwYMAA1q9fT//+/S3qSV4+YMAAxowZQ0REBF26dOHGjRtGmalTpzJ27Fjatm1LaGgo5cqVo1+/fuzZs+e+2y0iIiIiIpIWm57DVb9+fRYuXEi7du1wd3e3WLd//34WL15My5Yt76vOmJgY5s6dS5cuXejZsycATz31FEeOHGHu3Lm0atWKBQsWEBUVxYoVK/Dy8gLA29ubnj17snfvXgICAjhw4ABbtmxh8uTJNGjQAICAgAAaNWrE/PnzCQkJ4c6dO0yaNImuXbvSu3dvo0/BwcFMmDCBmTNn2hIWERERERERCzaNcPXp0wdnZ2fatm3Le++9h8lkYuHChbz11lt06tQJV1dXQkJC7qvOfPnysWjRIrp162ax3NnZmXv37gGwY8cO/P39jWQLoF69eri7u7Nt2zajjJubG0FBQUYZLy8v6tSpY5Q5dOgQUVFRNG3a1ChjMplo0qQJu3fv5s6dO/cXEBERERERkTTYlHB5e3uzcOFC/Pz82LZtG2azmXXr1rFlyxZq1arFnDlzKFOmzH3V6eTkRNWqVSlatChms5lr164xadIkfv31Vzp27AjAmTNn8PX1teyAgwNlypQhLCzMKFOmTBmcnCwH78qWLWs8H+zMmTMAlC9f3qJMuXLlSEhIIDw8PN12mkw549/DRPGxTrGxTvGxTvGxTvGxTvGxTvFJn47t1ik+1mXFd+ms+JdRNl1SCFCmTBkmT57MrVu3CAsLIzExkTJlylCkSBFbqzSsWrWKQYMGAdCgQQNatGgBJN3D9c9LGAHc3d2Jjo4G4NatW3h4eKRZJiYmxigDpCqXXHdyXf/k5eWOo6PNz4rOUkntSHjQzbA7R0cHihb1tOl1YM76BuUwtsQnp3yGs4PN8YnL+58dsD0+cQl5f98DtscnPt5ODcphbI3Pw/HXpfhYk5lj+8Ow98lMfB6G3Y+t8XmQbE64ksXHx2M2m3FyciJfvnxZ0SZq1qzJ3LlzOXfuHN9++y3BwcH88MMPAPxzGnoAs9lsLE9MTEyzTMrXJiYmprk++XliDg5pfyGNjIzJMWcQEhLS7kNek5CQyPXrt2x6HeSQN8uObIlPUmwejqTL9vjk/c8OZCY+DwfFxzpb4/Nw7H0UH2syd2zP+xQf62yNjz1kNPGzOeE6fPgwY8aMYd++fRaJSlBQEEOHDqVcuXK2Vk25cuUoV64cderUwcfHh65du7Ju3To8PDzSHH2KjY2lRIkSAHh6ehIREZGqTExMDJ6eSUEpUKCAsaxgwYIW9STXkR7zw3DqKYdRzK1TfKxTfKxTfKxTfKxTfKxTfNKn2Fin+FiX2+Jj04mUI0eO0KlTJ/bt20e9evXo3Lkzr732Gk8++STbt28nODiYP//8877qjIiIYPny5amSpRo1agBw+fJlfH19U91flZiYyIULF6hUqRIAvr6+XLhwIdUoVnh4OBUrVjTKAJw/f96izPnz53FxccHHx+e+2i4iIiIiIpIWmxKub7/9FhcXF5YtW8akSZN47733GDp0KNOmTWPBggXcuXOHcePG3VedsbGxDBkyhCVLllgs3759OwBVqlQhKCiIPXv2EBkZabE+JibGmJWwbt26xMTEGK8DiIyMZM+ePdStWxcAPz8/3NzcWLdunVHGbDazfv16AgMDcXFxub+AiIiIiIiIpMGmSwr37t1L165dqVq1aqp1tWrV4rXXXmPRokX3VaePjw9t2rRhwoQJODg4UKNGDf744w++++476tatS/369alRowZz586lW7du9OnThxs3bjB27Fjq16+Pn58fAHXq1CEwMJBBgwYxaNAgChUqxPjx4/H09CQ4OBgAV1dXunfvzoQJE3B2dsbPz4+lS5dy5MgRZs2aZUtIREREREREUrEp4TKZTMZ9UGkpU6YM8TZM0zR8+HDKly/P0qVLGT9+PMWKFaNz586EhIRgMpnw8vJi9uzZjBw5koEDB+Lu7k7z5s0ZPHiwRT2hoaGMHj2aMWPGkJiYSO3atfn6668t7tfq06cPjo6OLF68mOnTp1OpUiUmTpyIv7//fbdbREREREQkLTYlXA0aNGDlypV06NAhzcvvfvrpJ+Pyvfvh4uJCr1696NWrV7plKleuzMyZM63WU7BgQUaNGsWoUaPSLWMymQgJCbnvBzSLiIiIiIhkVIYSrj179lj83qhRIz744ANeffVVevbsSYUKFXBwcCA8PJy5c+dy6tQpvv76a3u0V0REREREJNfIUMLVqVOnVM+2MpvNHD58mH79+qVaDtC5c2eOHTuWRc0UERERERHJfTKUcPXu3TvdhwmLiIiIiIhI2jKUcPXt29fe7RAREREREclzbHoOl4iIiIiIiPw7m2YpjI6O5ssvv2TLli1cuXLFuG8rJZPJxNGjRzPdQBERERERkdzKpoRrzJgxLF68mOLFi1OrVi0cHR2zul0iIiIiIiK5nk0J1+bNm2ncuDHffvstDg66KlFERERERCQtNmVL0dHRNGjQQMmWiIiIiIiIFTZlTLVr1+bIkSNZ3RYREREREZE8xaaEa9CgQfz000/MmjWLa9euZXWbRERERERE8gSb7uEqXbo0VapUYfTo0YwePTrNMpqlUEREREREHnY2JVwjRoxg9+7deHl5Ua5cOZycbKpGREREREQkT7N5lsJGjRrxzTffKNkSERERERFJh033cN27d49nnnlGyZaIiIiIiIgVNiVcfn5+mqVQRERERETkX9iUcA0YMIDVq1czffp0rly5QkJCQla3S0REREREJNez6ZrAIUOG4ODgwNixYxk7dmyaZTRLoYiIiIiIPOxsSrgKFSpEoUKFsrgpIiIiIiIieYtNCdecOXOyuh0iIiIiIiJ5jk33cImIiIiIiMi/s2mE67333vvXMiaTiZEjR9pSvYiIiIiISJ5gU8K1fPnydNeZTCZcXFzIly+fEi4REREREXmo2ZRwbdy4MdWyhIQErl27xvLly/ntt9+YP39+phsnIiIiIiKSm9mUcJUuXTrN5WXLlsXf35+33nqLL7/8ks8//zxTjRMREREREcnN7DJpRsOGDdm6das9qhYREREREck17JJwXbt2jTt37tijahERERERkVzDpksK//rrrzSX37lzhz/++INZs2ZRrVq1TDVMREREREQkt7Mp4WrYsCEmkynd9Q4ODvTp08fmRomIiIiIiOQFNiVcbdq0STPhcnR0pHjx4rRt2xYfH59MN05ERERERCQ3synhGj16dFa3Q0REREREJM+xy6QZIiIiIiIiksERrtDQUJsq131cIiIiIiLyMMvyhCvlvV1KuERERERE5GGWoYRr9uzZ/1rGbDYzb948fv75ZwAaNGiQuZaJiIiIiIjkchlKuAIDA62u/+uvv3j//ffZtWsXnp6eDBkyhJdeeilLGigiIiIiIpJb2TRLYUoLFy5k7NixxMTEULduXUaMGIG3t3dWtE1ERERERCRXsznhunz5MkOHDuXXX3/F3d2d4cOH065du6xsm4iIiIiISK5mU8K1ZMkSPv/8c6Kjo3n66acZMWIEJUuWzOq2iYiIiIiI5Gr3lXBduXKFDz74gB07duDq6srHH39McHCwvdomIiIiIiKSq2U44Vq+fDmjRo0iKiqKJ598khEjRlC6dGl7tk1ERERERCRXy1DC9dZbb7F161YAmjdvTseOHfnrr7/466+/rL6uTp06mW+hiIiIiIhILpWhhGvLli3Gz+vWrWPdunUZqvzYsWM2NUpERERERCQvyFDC1adPH3u3Q0REREREJM9RwiUiIiIiImInDg+6ASIiIiIiInmVEi4RERERERE7UcIlIiIiIiJiJ0q4RERERERE7EQJl4iIiIiIiJ0o4RIREREREbETJVwiIiIiIiJ2kqMSLrPZzKJFi2jVqhV+fn40atSIESNGEB0dbZQ5e/YsPXv2xN/fnyeeeIL333+fqKgoi3qio6MZNmwYQUFB1KpVi27dunH69OlU25sxYwaNGzemRo0avPDCC2zYsMHufRQRERERkYdHjkq4pk6dyieffMIzzzzDhAkTeOONN1i1ahV9+vTBbDYTFRVF165diYyMZMyYMQwYMID169fTv39/i3qSlw8YMIAxY8YQERFBly5duHHjhsW2xo4dS9u2bQkNDaVcuXL069ePPXv2ZG+nRUREREQkz3J60A1IlpiYyOTJk3nllVcYMGAAAE8//TSFChWif//+/PHHH/z6669ERUWxYsUKvLy8APD29qZnz57s3buXgIAADhw4wJYtW5g8eTINGjQAICAggEaNGjF//nxCQkK4c+cOkyZNomvXrvTu3RuA+vXrExwczIQJE5g5c+YDiYGIiIiIiOQtOWaEKzo6mtatW9OyZUuL5b6+vgD8+eef7NixA39/fyPZAqhXrx7u7u5s27YNgB07duDm5kZQUJBRxsvLizp16hhlDh06RFRUFE2bNjXKmEwmmjRpwu7du7lz547d+ikiIiIiIg+PHDPCVaBAAT788MNUy3/++WcAHnnkEc6cOUOLFi0s1js4OFCmTBnCwsIAOHPmDGXKlMHJybJrZcuWZdWqVUYZgPLly1uUKVeuHAkJCYSHh1O5cuU022ky3XfXJJMUc+sUH+sUH+sUH+sUH+sUH+sUn/QpNtYpPtbltvjkmIQrLfv372fKlCk0btyYRx55hKioKNzd3VOVc3d3NybWuHXrFh4eHmmWiYmJMcoAqcol151yko6UvLzccXTMGYOCSe1IeNDNsDtHRweKFvW06XVgzvoG5TC2xCenfIazg83xicv7nx2wPT5xCXl/3wO2xyc+3k4NymFsjc/D8del+FiTmWP7w7D3yUx8Hobdj63xeZBybMK1d+9e3nrrLcqWLcuIESOM5aY0Ulqz2WwsT0xMTLNMytcmJiamud5sTtrNOTik/YU0MjImx2TUCQlp9yGvSUhI5Pr1Wza9DnLIm2VHtsQnKTYPR9Jle3zy/mcHMhOfh4PiY52t8Xk49j6KjzWZO7bnfYqPdbbGxx4ymvjlyIRr9erVDBkyBF9fX6ZNm0ahQoWApBGptEafYmNjKVGiBACenp5ERESkKhMTE4OnZ1JQChQoYCwrWLCgRT3JdaTH/DCcesphFHPrFB/rFB/rFB/rFB/rFB/rFJ/0KTbWKT7W5bb45LgTKVOnTmXAgAHUqlWLefPmUaxYMWOdr68v4eHhFuUTExO5cOEClSpVMspcuHAh1ShWeHg4FStWNMoAnD9/3qLM+fPncXFxwcfHJ8v7JSIiIiIiD58clXAtXLiQsWPH0rx5c6ZNm5ZqpCkoKIg9e/YQGRlpLNu+fTsxMTHGrIR169YlJiaG7du3G2UiIyPZs2cPdevWBcDPzw83NzfWrVtnlDGbzaxfv57AwEBcXFzs2U0REREREXlI5JhLCq9du8aoUaMoXbo0r732GkePHrVYX7ZsWTp27MjcuXPp1q0bffr04caNG4wdO5b69evj5+cHQJ06dQgMDGTQoEEMGjSIQoUKMX78eDw9PQkODgbA1dWV7t27M2HCBJydnfHz82Pp0qUcOXKEWbNmZXvfRUREREQkb8oxCdfWrVu5c+cOFy9e5NVXX021ftSoUbz44ovMnj2bkSNHMnDgQNzd3WnevDmDBw+2KBsaGsro0aMZM2YMiYmJ1K5dm6+//trifq0+ffrg6OjI4sWLmT59OpUqVWLixIn4+/vbva8iIiIiIvJwyDEJ18svv8zLL7/8r+UqV67MzJkzrZYpWLAgo0aNYtSoUemWMZlMhISEEBIScr9NFRERERERyZAcdQ+XiIiIiIhIXqKES0RERERExE6UcImIiIiIiNiJEi4RERERERE7UcIlIiIiIiJiJ0q4RERERERE7EQJl4iIiIiIiJ0o4RIREREREbETJVwiIiIiIiJ2ooRLRERERETETpRwiYiIiIiI2IkSLhERERERETtRwiUiIiIiImInSrhERERERETsRAmXiIiIiIiInSjhEhERERERsRMlXCIiIiIiInaihEtERERERMROlHCJiIiIiIjYiRIuERERERERO1HCJSIiIiIiYidKuEREREREROxECZeIiIiIiIidKOESERERERGxEyVcIiIiIiIidqKES0RERERExE6UcImIiIiIiNiJEi4RERERERE7UcIlIiIiIiJiJ0q4RERERERE7EQJl4iIiIiIiJ0o4RIREREREbETJVwiIiIiIiJ2ooRLRERERETETpRwiYiIiIiI2IkSLhERERERETtRwiUiIiIiImInSrhERERERETsRAmXiIiIiIiInSjhEhERERERsRMlXCIiIiIiInaihEtERERERMROlHCJiIiIiIjYiRIuERERERERO1HCJSIiIiIiYidKuEREREREROxECZeIiIiIiIidKOESERERERGxEyVcIiIiIiIidqKES0RERERExE6UcImIiIiIiNiJEi4RERERERE7ybEJ16VLlwgICGDXrl0Wy8+ePUvPnj3x9/fniSee4P333ycqKsqiTHR0NMOGDSMoKIhatWrRrVs3Tp8+nWobM2bMoHHjxtSoUYMXXniBDRs22LVPIiIiIiLycMmRCdfFixfp1q0bt27dslgeFRVF165diYyMZMyYMQwYMID169fTv39/i3LJywcMGMCYMWOIiIigS5cu3LhxwygzdepUxo4dS9u2bQkNDaVcuXL069ePPXv2ZEMPRURERETkYeD0oBuQUmJiIsuXL2fMmDFprl+wYAFRUVGsWLECLy8vALy9venZsyd79+4lICCAAwcOsGXLFiZPnkyDBg0ACAgIoFGjRsyfP5+QkBDu3LnDpEmT6Nq1K7179wagfv36BAcHM2HCBGbOnJkt/RURERERkbwtR41wnThxgo8//pg2bdqkmXTt2LEDf39/I9kCqFevHu7u7mzbts0o4+bmRlBQkFHGy8uLOnXqGGUOHTpEVFQUTZs2NcqYTCaaNGnC7t27uXPnjr26KCIiIiIiD5EcNcJVsmRJ1q9fT4kSJVLduwVw5swZWrRoYbHMwcGBMmXKEBYWZpQpU6YMTk6WXStbtiyrVq0yygCUL1/eoky5cuVISEggPDycypUrp9lGk8mWnklmKObWKT7WKT7WKT7WKT7WKT7WKT7pU2ysU3ysy23xyVEJV6FChayuj4qKwt3dPdVyd3d3oqOjAbh16xYeHh5plomJiTHKAKnKJdedXNc/eXm54+iYMwYFk9qR8KCbYXeOjg4ULepp0+vAnPUNymFsiU9O+QxnB5vjE5f3Pztge3ziEvL+vgdsj098vJ0alMPYGp+H469L8bEmM8f2h2Hvk5n4PAy7H1vj8yDlqIQrI0xppLRms9lYnpiYmGaZlK9NTExMc73ZnLSbc3BI+wtpZGRMjsmoExLS7kNek5CQyPXrt/69YBqvgxzyZtmRLfFJis3DkXTZHp+8/9mBzMTn4aD4WGdrfB6OvY/iY03mju15n+Jjna3xsYeMJn65KuHy8PBIc/QpNjaWEiVKAODp6UlERESqMjExMXh6JgWlQIECxrKCBQta1JNcR3rMD8OppxxGMbdO8bFO8bFO8bFO8bFO8bFO8UmfYmOd4mNdbotPrjqR4uvrS3h4uMWyxMRELly4QKVKlYwyFy5cSDWKFR4eTsWKFY0yAOfPn7coc/78eVxcXPDx8bFXF0RERERE5CGSqxKuoKAg9uzZQ2RkpLFs+/btxMTEGLMS1q1bl5iYGLZv326UiYyMZM+ePdStWxcAPz8/3NzcWLdunVHGbDazfv16AgMDcXFxyaYeiYiIiIhIXparLins2LEjc+fOpVu3bvTp04cbN24wduxY6tevj5+fHwB16tQhMDCQQYMGMWjQIAoVKsT48ePx9PQkODgYAFdXV7p3786ECRNwdnbGz8+PpUuXcuTIEWbNmvUguygiIiIiInlIrkq4vLy8mD17NiNHjmTgwIG4u7vTvHlzBg8ebFEuNDSU0aNHM2bMGBITE6lduzZff/21xf1affr0wdHRkcWLFzN9+nQqVarExIkT8ff3z+5uiYiIiIhIHpVjE64nnniCEydOpFpeuXJlZs6cafW1BQsWZNSoUYwaNSrdMiaTiZCQEEJCQjLbVBERERERkTTlqnu4REREREREchMlXCIiIiIiInaihEtERERERMROlHCJiIiIiIjYiRIuERERERERO1HCJSIiIiIiYidKuEREREREROxECZeIiIiIiIidKOESERERERGxEyVcIiIiIiIidqKES0RERERExE6UcImIiIiIiNiJEi4RERERERE7UcIlIiIiIiJiJ0q4RERERERE7EQJl4iIiIiIiJ0o4RIREREREbETJVwiIiIiIiJ2ooRLRERERETETpRwiYiIiIiI2IkSLhERERERETtRwiUiIiIiImInSrhERERERETsRAmXiIiIiIiInSjhEhERERERsRMlXCIiIiIiInaihEtERERERMROlHCJiIiIiIjYiRIuERERERERO1HCJSIiIiIiYidKuEREREREROxECZeIiPx/e/ceVmO69wH8a0U55jA1mFSoUaSEMhOJJJVDvGw5Rg17RrhGgxyn2e132Ezs0EGKtWkmW9Sg3RSJIQ27SLMxNDmlVgwZSg6lw3reP5rWa6mYMS3Ps2d9P9e1rmv81nqevuueqN+6n/t+iIiISEPYcBEREREREWkIGy4iIiIiIiINYcNFRERERESkIWy4iIiIiIiINIQNFxERERERkYaw4SIiIiIiItIQNlxEREREREQawoaLiIiIiIhIQ9hwERERERERaQgbLiIiIiIiIg1hw0VERERERKQhbLiIiIiIiIg0hA0XERERERGRhrDhIiIiIiIi0hA2XERERERERBrChouIiIiIiEhD2HARERERERFpCBsuIiIiIiIiDWHDRUREREREpCFsuIiIiIiIiDRE6xuukydPYuLEiejXrx+cnZ0RFRUFQRDEjkVERERERH8AWt1w5eTkYP78+TAzM0NYWBg8PT2xadMmbNu2TexoRERERET0B9Bc7ABiioiIgKWlJTZs2AAAcHJyQnV1NaKjo+Hr64uWLVuKnJCIiIiIiP6bae0MV2VlJbKysjBq1Ci1upubG54+fYrs7GyRkhERERER0R+F1jZcCoUCVVVV6N69u1rd1NQUAHDz5s03H4qIiIiIiP5QtPaSwrKyMgBA27Zt1ept2rQBADx+/LjB45o102yu3+JxaQEO73IVO4bGPC4tAAx6vvaYl967jn/878CmDSUhpfeuw0D/9cbn59vXsGaeVdOHkpCfb19De7PXG5/biuvwm9yv6UNJyG3FdZj1fL3xURTk439GOzV9KAlRFOSj52uOz81CBZzGeTV9KAm5WahAj55mrzU+12/dgd3sJU0fSkKu37qDHj3NX2987j7AwJWhTR9KIq7ffYAebd967Z/t+SVlGBp1sEkzSUl+SRl6vNXltcen8Ek5xh/PatpQElL4pBw9Ia3fx38NrW24lEolAKBZI//HZLL6k3+Ghu00mum3+PHHXLEjSBrHp3Ecm5fj+Lwcx+flOD4vx/F5OY7Py3F8Xo7jI11ae0mhvr4+gPozWU+ePAFQf+aLiIiIiIjot9LahsvExAQ6OjooKChQq9f92dzcXIxYRERERET0B6K1DZeenh7s7OyQlpamdqPj1NRU6Ovrw8bGRsR0RERERET0R6C1DRcA+Pn54fz581i0aBHS09OxefNmyOVyfPTRR7wHFxERERER/W5a3XA5ODggLCwM+fn5WLBgAZKSkrBs2TLMnTtX7GiSc/LkSUycOBH9+vWDs7MzoqKi1GYGCfjpp59gZ2eHrKw/7u5Av5UgCNi7dy/GjRuH/v37w8XFBWvXrm10F1BtU1NTg+joaLi6usLGxgaenp5ITEwUO5ZkLVy4ECNGjBA7hmSUl5ejd+/esLCwUHtYW1uLHU0y/vOf/8Db2xu2trYYPHgwli9fjvv374sdS3RZWVn1vm+ef4SHh4sdURL27duHMWPGwNbWFh4eHti9ezd/9/mFUqmEXC6Hq6srrK2t4e7ujpiYGI5PI7R2l8I6rq6ucHX9426t3hRycnIwf/58eHh4wN/fH+fOncOmTZugVCrh5+cndjxJuHXrFubMmYNHjx6JHUVSduzYgU2bNmHOnDlwcHBAQUEBtmzZgqtXr2Lnzp2N7hKqLUJCQhATE4OPP/4Y1tbWSE9Px7JlyyCTyTBu3Dix40lKYmIi0tLSYGRkJHYUycjLy4NSqURISIjauDS0y642+uGHHzBr1iw4ODggPDwcxcXFCAkJwYIFCxAXFyd2PFFZWVlh79699eqbN2/GxYsXMWbMGBFSSUt8fDwCAwPh7e0NFxcXnDlzBp9//jkqKiowZ84cseOJbv369YiJicHUqVPh6uoKhUKBLVu24NatW1i1apXY8aRHIHqFDz74QJg0aZJaLTg4WLC1tRXKy8tFSiUNNTU1QkJCgjBo0CBh0KBBQq9evYTMzEyxY0lCTU2NYGdnJwQFBanVU1JShF69egkXLlwQKZk0PH78WLCxsRGCg4PV6jNnzhS8vLxESiVNd+7cEezt7QUnJyfB2dlZ7DiS8c9//lOwsrISKisrxY4iSd7e3oKXl5dQXV2tqqWmpgpOTk5CYWGhiMmkKS0tTejVq5dw6NAhsaNIwpQpU4SpU6eq1fz9/flvkCAI9+/fF3r37i18+umnavUTJ04IlpaWwrVr10RKJl38GIxeqrKyEllZWRg1apRa3c3NDU+fPkV2drZIyaQhLy8PQUFBmDBhAoKDg8WOIymPHz+Gp6cnxo4dq1bv0aMHAEChUIgRSzL09PSwd+9e+Pr6qtVbtGiByspKkVJJ06effoohQ4bAwcFB7CiSkpubC3Nzc7Ro0ULsKJJTUlKCM2fOYNq0adDR0VHVR40ahfT0dBgbG4uYTnoqKiqwZs0aDB8+HO7u7mLHkYTKykq0a6d+/9WOHTuitLRUnEAScvPmTdTU1MDZ2Vmtbm9vD6VSiYyMDJGSSRcbLnophUKBqqoqdO/eXa1uamoKoPYvnTbr2rUr0tLSsHLlSm608gJ9fX0EBgZi4MCBavUjR44AAN59910xYklG8+bNYWlpCQMDAwiCgHv37iEqKgqnT5/G9OnTxY4nGfHx8bh06RICAwPFjiI5P/74I2QyGXx9fWFra4tBgwbhs88+4xpJ1H4YJggC3nrrLSxZsgT9+/dH//79sXTpUjx8+FDseJKza9cuFBcX81Kw58yePRunTp1CYmIiHj16hIyMDBw4cADjx48XO5roOnXqBKB2OcXzCgsLAQBFRUVvPJPUaf0aLnq5srIyAPVvBN2mTRsA9W8crW06dOggdoT/Kjk5Odi+fTtGjhyp9Q3X85KSkhAQEAAAGDZsGEaPHi1yImm4desW1q1bh3Xr1ql+wFMtpVKJK1euQCaTYenSpZg/fz4uXryI8PBwXLt2DbGxsVq9luvBgwcAgFWrVsHJyQlbt27FzZs3ERISAoVCgT179mj1+DyvsrISX331FUaPHq36MJUADw8PZGZmYtmyZaqao6Mjm1IA3bt3x4ABAxAeHo4uXbrg/fffh0KhQGBgIHR1dfH06VOxI0oOGy56KaVSCQCNbm7AH1j0a2VnZ2PevHkwMTHB2rVrxY4jKf369UNsbCzy8/MRGhqKqVOnIiEhAXp6emJHE40gCFi1ahWGDRsGNzc3seNIjiAIiIqKgoGBAczMzADUXs5jYGCAgIAAZGRkYNiwYSKnFE9VVRWA2s0h6v69cXBwgL6+PhYvXoxTp05h6NChYkaUjMOHD+Pnn3/mDs0v8PPzQ05ODgICAmBjY4O8vDyEh4dj0aJFiIiI0PpNn8LCwvDZZ59h4cKFAGqvagkICMDWrVvRunVrkdNJDxsueil9fX0A9Weynjx5AqD+zBdRQ5KTk7FixQr06NEDcrmcM4MvMDU1hampKezt7WFsbAwfHx+kpqbC09NT7Gii2b17N/Ly8pCUlITq6moAUG03XF1dDZlMptUf+Ojo6OC9996rVx8+fDiA2kvqtLnhqrsK48U1JnVNVm5uLhuuX6SmpuLdd9+FpaWl2FEkIycnB9999x3WrFmDyZMnAwAGDRoEY2NjfPTRRzhx4kS97y1tY2BggK1bt6KsrAzFxcUwMTGBTCZDUFAQ2rdvL3Y8ydHen1b0q5iYmEBHRwcFBQVq9bo/m5ubixGL/ovs2LEDS5Ysga2tLXbv3g1DQ0OxI0nC/fv3ceDAgXr3BKq7h9KdO3fEiCUZqampKCkpgaOjI6ysrGBlZYWDBw/i1q1bsLKyQkREhNgRRXX37l3s27ev3vdJRUUFgNrF/dqsbt3xixvQ1DXvXHNbq6qqCqdOneJGGS+4ffs2AGDAgAFqdXt7ewDA1atX33gmqUlOTsaPP/4IfX19mJubQ1dXF7m5uaipqUGfPn3Ejic5bLjopfT09GBnZ4e0tDS1m9mlpqZCX18fNjY2IqYjqYuLi8OGDRvg7u4OuVxeb8cnbfb06VOsWLEC8fHxavW63Z0sLCzEiCUZf/3rX5GQkKD2cHZ2hqGhIRISEuDl5SV2RFFVVlYiMDCw3r2UUlJSIJPJ6m1Wo23MzMxgZGSE5ORktfqxY8cAAHZ2dmLEkpwrV66gvLxc679fXtSzZ08AqLcTc05ODgCgW7dubzyT1ERGRiI6OlqttmvXLujr6zc4+67teEkhvZKfnx98fX2xaNEiTJo0Cd9//z3kcjmWLl3KTwmpUffu3cO6detgZGSEmTNn4vLly2rPm5iYaPVGCMbGxpgwYQIiIiIgk8lgbW2NH374AZGRkXB0dISTk5PYEUVV9wvP8zp06ABdXV3VLKA2MzY2xvjx47F9+3bo6urC1tYW586dw7Zt2zB9+vQGx0+bNGvWDMuWLYO/vz/8/f0xefJk3LhxAyEhIXBzc+Mn8L+4cuUKAKjWAVKtPn36wM3NDevXr8fDhw/Rr18/XLt2DWFhYbCysoKrq6vYEUXn7e2Nv/zlLzA3N8eAAQOQkpKCb775BkFBQVxu0oBmwvPTFkSNSEtLQ2hoKPLz89G5c2fMmDEDH3zwgdixJCUrKwuzZs3Cl19+yU93ACQkJGD16tWNPr9u3TpMnDjxDSaSnsrKSsjlchw8eBC3b9+GoaEhPD09MX/+fOjq6oodT3JWrFiBM2fO4NtvvxU7iiQ8e/YMO3bswL/+9S/cvn0bnTt3hpeXF+bMmaN27yltdvz4cURERCAvLw/t27fHuHHj8Mknn/Dv1y+2b9+OjRs34sKFC1q9SU9DKisrERkZicTERBQXF+Odd97ByJEjsWDBAtUaQW0XExOD2NhY3Lt3Dz169MCcOXPq3XuTarHhIiIiIiIi0hCu4SIiIiIiItIQNlxEREREREQawoaLiIiIiIhIQ9hwERERERERaQgbLiIiIiIiIg1hw0VERERERKQhbLiIiIiIiIg0hA0XERERERGRhrDhIiKiN2LFihWwsLBAVlZWk52zqKgIFhYWWLFiRZOdEwDCwsKaPCtQm3fgwIHIzc1V1crLy7Flyxa4urrCxsYGbm5ukMvlqKmp+dXnrampgVwuh7u7O6ytrTFixAh88cUXKC0tVXtdbm4uBg4cCIVC0VRviYiIXoENFxER0RsSGBgId3d39O7dGwCgVCrx8ccfIzIyEoMGDcLq1athYWGB4OBgBAUF/erzBgQEIDg4GK1bt8aSJUswfvx4xMfHY+rUqXjw4IHqdb1798bo0aOxevVqCILQ1G+PiIgawIaLiIjoDUhKSsLZs2excOFCVe3w4cM4efIkFi9ejLVr12LKlCkIDQ3FlClTsG/fPpw/f/6V5z1x4gSSk5Nhb2+PuLg4+Pj4YNGiRYiNjYVCocCGDRvUXr9w4ULk5OQgMTGxyd8jERHVx4aLiIhIwwRBQHR0NAYPHoyuXbuq6gcOHECLFi0wc+ZMtdf/+c9/BgDs37//lec+cuQIAMDf3x+6urqquqWlJYYPH46kpCQ8efJEVe/cuTOGDBmC6OhoznIREb0BbLiIiEhyBEFAfHw8pk+fDjs7O1hZWcHR0RGLFy9GQUFBg8fs2rULLi4usLa2xtixYxEbG1uvoVAqlfjqq68wfvx42NjYwM7ODnPnzsW5c+demeny5cuYN28ehg4dir59+8LFxQVr1qypt06qIRkZGbhy5Qo8PDzU6hcuXECvXr3QunVrtbqxsTE6deqECxcuvPLcd+7cAVDbYL3I1NQUVVVVyMvLU6t7eHjg+vXrSE9Pf+X5iYjo92kudgAiIqIXrVu3DjExMRg5ciQ++eQTAEB2djZSUlJw+fJlpKSkQCb7/88MU1NTkZqaipkzZ8LQ0BDffPMNPv/8cxQVFaltqLF06VIkJyfDzc0NXl5eePjwIfbv3w9vb2+EhITA3d29wTwKhQKzZ8+GoaEhfHx8oK+vj/PnzyM2NhYXLlzA3r170axZs0bfz9GjR9GsWTO4uLioauXl5SgtLYWdnV2Dx3Tp0gVFRUWvHKu6Zu3Jkydo27at2nMlJSUAgOLiYrW6i4sLZDIZjh49iuHDh7/yaxAR0etjw0VERJJSUlKC3bt3w9nZGREREar6jBkzoFQqcfjwYeTm5sLKykr1XEVFBeLi4tCvXz8AwLRp0zBjxgzs2rUL06ZNg6mpKQ4dOoTk5GQEBARg7ty5qmNnz56NP/3pTwgKCsKwYcPQqlWrepmOHDmCsrIyyOVy2NjYAAAmT56Mtm3b4syZMyguLkbnzp0bfU+ZmZkwNjaGvr6+qvbo0SMAqDe7Vadly5YoLy9/5XgNGDAAaWlpSEpKUntfT548QUZGhmp8nteuXTsYGxs3+S6MRERUHy8pJCIiSenYsSOys7OxceNGtXpZWZmqGXr69Knac05OTqpmCwBatGgBX19fCIKAo0ePAgCSk5MBAG5ubnjw4IHq8ezZM4waNQolJSU4e/Zsg5nq1l1t2LAB//73v1FZWQmgdqv7/fv3v7TZUiqVUCgUMDU1VavXXe7Y2DoqQRDUZvEaM3nyZHTt2hVbtmyBXC5HQUEBvv/+e8ybNw9VVVWq8XiRiYkJioqKoFQqX/k1iIjo9XGGi4iIJEdPTw/Hjh3D8ePHUVhYiKKiIvz000+qy/ZebBLMzMzqnaNHjx4AoFrzlZ+fDwAYOXJko1/31q1bDdbd3NwwadIk7N+/Hz4+PmjZsiUGDhyIYcOGYcKECWjfvn2j5ywtLYVSqVSb3QKANm3aAKg/+1SnoqIC7dq1U/133YxYHR0dHXTq1Ant2rXDrl27sGTJEgQHByM4OBgymQxjx47F6NGjERQU1GA+fX19KJVKlJaWolOnTo3mJyKi34cNFxERSUpVVRUWLlyIEydOoG/fvujbty/c3NzQp08fpKenIyoqqt4xDc0E1TVlzZvX/qirqalBmzZtEB4e3ujXrmvSXqSjo4O//e1vmD9/Po4fP47Tp08jOzsbp06dQlRUFOLi4mBiYtLgsY01iW3btkXHjh1Vm1686M6dOzAyMgIApKSkYOXKlWrPGxkZ4dtvvwUAdO/eHV9//TVu3LiBBw8eoHv37jAwMEBoaCgA1JtdA4Dq6moADY8dERE1HTZcREQkKSkpKThx4gQ+/PBDLFmyRO25AwcONHhMYWFhvdqNGzcA1DYjANCtWzfk5+fD0tKy3oxObm4uiouLG1y/BdTOfBUWFsLBwQHe3t7w9vZGdXU15HI5QkJCsGfPHixfvrzBYzt27IgWLVqoNrB4no2NDTIzM1FRUYGWLVuq6gqFAiUlJRg7diwAwNHRETt37lQ7Vk9PD0DtzN3Zs2cxfPhw9OzZEz179lS95uTJk+jatSuMjY3rfe2SkhLo6uqiQ4cODeYmIqKmwY+1iIhIUuoaEwsLC7V6QUEBUlNTAdTOVj0vPT1dremqrKzEjh070Lx5c7i6ugKovSwQADZv3qx27OPHj+Hv748FCxbg2bNnDWbatm0bfHx81G5E3Lx5c9W6MR0dnZe+JyMjowYvV/T09MSzZ8/w5ZdfqtW3b98OAJg4cSIA4O2338bgwYPVHgMHDgQA3L17F4GBgdizZ4/aORITE3Hx4kX4+vo2mOn27duqGTQiItIcznAREdEbtXPnTtUGFi9atWoVhg4dir///e9Yu3YtCgsLYWhoiKtXr+Lrr79WXQZXVlamdlzr1q0xffp0zJo1C7q6ujh48CByc3OxfPly1YYXEydOxOHDh7F3714UFhZixIgRqK6uRnx8PG7evImAgIBGN7/w8fHBoUOH8OGHH2Lq1Kno1q0b7t69iz179qBdu3bw8vJ66Xt2dHREbGwsiouL8fbbb6vqY8aMQXx8PEJCQlBUVARra2t89913OHz4MGbMmIE+ffq8cjzt7e3x3nvvITo6GmVlZbC0tMTly5cRFxeHIUOGYNq0afWOKS4uRlFREWbPnv3K8xMR0e/DhouIiN6o48ePN/rc0qVLYWZmhujoaISGhkIulwOo3SVw5syZcHd3x4QJE5CRkaF2zywvLy+0atUKu3fvxoMHD2Bubo5NmzZh9OjRqtfo6Ohg27ZtiImJQWJiIjZu3IhWrVrBzMwMYWFhGDVqVKO5zMzMEBsbi8jISBw8eBD3799Hhw4d8P7772PBggWNrt+q4+LigtjYWGRlZWHcuHGqerNmzRAZGYmwsDCkpKTgwIED6NatG1auXIlZs2a9cizr3ldERAS2bt2KI0eOICEhAe+88w78/f3h4+MDXV3desdkZmaqchERkWY1Exrbj5aIiIiahFKpxNixY9GlSxf84x//EDsOfHx88PPPPyMpKemlN2wmIqLfj2u4iIiINEwmk8HPzw+nT5+GQqEQNUthYSEyMzPh5+fHZouI6A1gw0VERPQGjBkzBv3791dt1S6W0NBQ2NrawsPDQ9QcRETagg0XERHRGyCTyfDFF1/g2LFjuHTpkigZLl26hGPHjmH9+vW8/xYR0RvCNVxEREREREQawo+3iIiIiIiINIQNFxERERERkYaw4SIiIiIiItIQNlxEREREREQawoaLiIiIiIhIQ9hwERERERERaQgbLiIiIiIiIg1hw0VERERERKQh/wf3BLh5NoEgmwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define color map\n",
    "colors = sns.color_palette(\"coolwarm\", 10)  \n",
    "\n",
    "# Create the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(range(10), label_counts.numpy(), color=colors, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "# Add exact counts on top of each bar\n",
    "for bar, count in zip(bars, label_counts.numpy()):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), str(count),\n",
    "             ha='center', va='bottom', fontsize=12, color='black', fontweight='bold')\n",
    "\n",
    "# Labels and Title\n",
    "plt.xlabel('Labels (0-9)', fontsize=14)\n",
    "plt.ylabel('Number of Samples', fontsize=14)\n",
    "plt.title('Distribution of Labels in MNIST Training Set', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Adjust ticks\n",
    "plt.xticks(range(10), fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50326e0-76d2-4e29-8c7f-f440a2d60033",
   "metadata": {},
   "source": [
    "## Plot a small sample for visual exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd7cb212-3858-4091-abc3-4caacbea85da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of examples to display\n",
    "num_examples = 6\n",
    "\n",
    "# Plot the first few images\n",
    "plt.figure(figsize=(9, 4))\n",
    "\n",
    "for i in range(num_examples):\n",
    "    plt.subplot(1, num_examples, i+1)  \n",
    "    plt.imshow(train_dataset.data[i], cmap='gray') \n",
    "    plt.title(f\"Label: {train_dataset.targets[i].item()}\", fontsize=12)\n",
    "    plt.axis('off') \n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea27ac4-0346-4155-8b3b-850b3794dd87",
   "metadata": {},
   "source": [
    "# Defining the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee0da3-a1a9-45b2-abb1-26cf69b2a12f",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6766ef64-8c2e-40a3-aaab-4fc750467a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MLP Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        # Create a list to hold the layers of the network\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        # Dynamically add hidden layers based on provided hidden_sizes list\n",
    "        for hidden_size in hidden_sizes:\n",
    "            # Add a fully connected (Linear) layer\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            # Add a ReLU activation function for non-linearity\n",
    "            layers.append(nn.ReLU())\n",
    "            # Update the size for the next layer's input\n",
    "            prev_size = hidden_size\n",
    "        # Add the final output layer\n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        # Use nn.Sequential to stack all layers into a single model\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Define the forward pass using the sequential model\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c4f3f6-f6c7-4560-a899-df9cc41e4a78",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "226430eb-a611-430a-8926-b7fc12476671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_filters, kernel_size, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # First convolutional layer:\n",
    "        # - 1 input channel (grayscale image)\n",
    "        # - num_filters output channels\n",
    "        # - kernel_size is the size of the filter\n",
    "        # - padding=1 keeps spatial dimensions nearly the same after convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=kernel_size, padding=1)\n",
    "\n",
    "        # Max pooling layer with 2x2 window and stride of 2 (downsamples by a factor of 2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Second convolutional layer:\n",
    "        # - input channels = num_filters from previous layer\n",
    "        # - output channels = num_filters * 2 (doubling for more feature complexity)\n",
    "        self.conv2 = nn.Conv2d(in_channels=num_filters, out_channels=num_filters * 2, kernel_size=kernel_size, padding=1)\n",
    "\n",
    "        # Calculate the flattened output size after conv and pooling layers to define the first fully connected layer\n",
    "        conv_output_size = self._get_conv_output((1, 28, 28), num_filters, kernel_size)\n",
    "\n",
    "        # First fully connected layer after flattening convolution output\n",
    "        self.fc1 = nn.Linear(conv_output_size, 128)\n",
    "\n",
    "        # Final fully connected layer producing the output classes\n",
    "        self.fc2 = nn.Linear(128, output_size)\n",
    "\n",
    "        # ReLU activation function used after each layer\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def _get_conv_output(self, shape, num_filters, kernel_size):\n",
    "        # Utility function to dynamically compute the flattened output size\n",
    "        # from the conv and pooling layers given the input shape\n",
    "        x = torch.zeros(1, *shape)  # Create a dummy input tensor\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        return int(np.prod(x.shape[1:]))  # Flatten the output and compute total features\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass logic:\n",
    "        # - Reshape flat input into 2D image format with single channel\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "\n",
    "        # Apply first convolution + ReLU activation + pooling\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Apply second convolution + ReLU activation + pooling\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Flatten the 2D feature maps into a 1D vector\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Apply first fully connected layer + ReLU\n",
    "        x = self.relu(self.fc1(x))\n",
    "\n",
    "        # Output layer (produces raw class scores)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b3693-7534-4c05-894d-2eff058393f1",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ac0a64-7ff8-4c84-bbf5-af9a9ab9ca19",
   "metadata": {},
   "source": [
    "## MLP Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03121dd6-fae2-4232-99de-7bb625e6716b",
   "metadata": {},
   "source": [
    "### Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "737b2736-ad2f-4391-b278-8c4777be9cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "mlp_param_grid = {\n",
    "    'hidden_sizes': [[128, 64], [256, 128], [512, 256]],\n",
    "    'learning_rate': [0.01, 0.001, 0.0001],\n",
    "    'batch_size': [64, 128],\n",
    "    'epochs': [10]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a5b418-c710-4901-a4c0-84a7fd354e50",
   "metadata": {},
   "source": [
    "### Train and Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "871da38c-ad0f-4d11-94b5-4b4370234bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_train_and_evaluate(hidden_sizes, learning_rate, batch_size, epochs):\n",
    "    # Print the configuration of the model being trained\n",
    "    print(f\"Training model with hidden_sizes={hidden_sizes}, learning_rate={learning_rate}, batch_size={batch_size}, epochs={epochs}\")\n",
    "\n",
    "    # Lists to store the validation loss and training accuracy for each fold\n",
    "    fold_losses = []\n",
    "    fold_train_accuracies = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset, targets)):\n",
    "        print(f\"Fold {fold+1}\")\n",
    "\n",
    "        # Create training and validation subsets for this fold\n",
    "        train_subset = Subset(train_dataset, train_idx)\n",
    "        val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "        # Wrap the subsets in DataLoaders for batch processing\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize the MLP model with specified hidden layer sizes\n",
    "        model = MLP(28*28, hidden_sizes, 10).to(device)\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Training loop over epochs\n",
    "        for epoch in range(epochs):\n",
    "            model.train()  # Set model to training mode\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            # Iterate over training batches\n",
    "            for i, (images, labels) in enumerate(train_loader):\n",
    "                # Move data to the specified device (CPU/GPU)\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # Zero out gradients before each update\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass and parameter update\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Accumulate loss and correct predictions for accuracy\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "            # Calculate average loss and accuracy for the epoch\n",
    "            epoch_loss = running_loss / len(train_loader)\n",
    "            epoch_accuracy = correct / total\n",
    "\n",
    "            # Print epoch performance\n",
    "            print(f\"Model {hidden_sizes}, LR {learning_rate}, Batch {batch_size}, Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "        # Evaluation on the validation set after training\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Calculate average validation loss (error)\n",
    "        fold_loss = val_loss / len(val_loader)\n",
    "        fold_losses.append(fold_loss)\n",
    "        fold_train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "        print(f\"Validation Error for Fold {fold+1}: {fold_loss:.4f}\")\n",
    "\n",
    "    # Compute and report average metrics across all folds\n",
    "    cv_error = np.mean(fold_losses)\n",
    "    avg_train_accuracy = np.mean(fold_train_accuracies)\n",
    "    print(f\"Model {hidden_sizes}, LR {learning_rate}, Batch {batch_size}, Cross-Validation Error: {cv_error:.4f}, Training Accuracy: {avg_train_accuracy:.4f}\")\n",
    "\n",
    "    # Return cross-validation error for use in model selection\n",
    "    return cv_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcfae2f9-54f5-4b3c-a0cc-90ba6a7649bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels for stratification\n",
    "targets = np.array(train_dataset.targets)\n",
    "\n",
    "# Stratified K-Fold\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initializing values \n",
    "mlp_best_model = None\n",
    "mlp_best_val_loss = float('inf')\n",
    "mlp_best_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3953ef5-81ca-4a5a-b159-0c2f7c50c714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hidden_sizes=[128, 64], learning_rate=0.01, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2612, Accuracy: 0.9197\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1498, Accuracy: 0.9560\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1244, Accuracy: 0.9645\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1115, Accuracy: 0.9680\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1077, Accuracy: 0.9703\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [6/10], Loss: 0.1002, Accuracy: 0.9720\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0960, Accuracy: 0.9745\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0880, Accuracy: 0.9759\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0830, Accuracy: 0.9777\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0785, Accuracy: 0.9797\n",
      "Validation Error for Fold 1: 0.1616\n",
      "Fold 2\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2682, Accuracy: 0.9179\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1428, Accuracy: 0.9585\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1219, Accuracy: 0.9644\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1063, Accuracy: 0.9702\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1038, Accuracy: 0.9708\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [6/10], Loss: 0.1030, Accuracy: 0.9721\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0853, Accuracy: 0.9762\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0879, Accuracy: 0.9765\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0759, Accuracy: 0.9791\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0771, Accuracy: 0.9790\n",
      "Validation Error for Fold 2: 0.1946\n",
      "Fold 3\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2552, Accuracy: 0.9214\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1481, Accuracy: 0.9573\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1290, Accuracy: 0.9636\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1097, Accuracy: 0.9696\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1045, Accuracy: 0.9706\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0976, Accuracy: 0.9740\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0939, Accuracy: 0.9752\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0873, Accuracy: 0.9770\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0783, Accuracy: 0.9803\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0685, Accuracy: 0.9811\n",
      "Validation Error for Fold 3: 0.1847\n",
      "Fold 4\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2599, Accuracy: 0.9212\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1433, Accuracy: 0.9584\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1250, Accuracy: 0.9648\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1079, Accuracy: 0.9692\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1021, Accuracy: 0.9714\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0994, Accuracy: 0.9724\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0890, Accuracy: 0.9751\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0865, Accuracy: 0.9769\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0783, Accuracy: 0.9792\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0730, Accuracy: 0.9802\n",
      "Validation Error for Fold 4: 0.1621\n",
      "Fold 5\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2614, Accuracy: 0.9214\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1470, Accuracy: 0.9589\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1269, Accuracy: 0.9639\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1038, Accuracy: 0.9710\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1104, Accuracy: 0.9685\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0946, Accuracy: 0.9740\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0987, Accuracy: 0.9733\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0840, Accuracy: 0.9771\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0745, Accuracy: 0.9803\n",
      "Model [128, 64], LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0732, Accuracy: 0.9802\n",
      "Validation Error for Fold 5: 0.1876\n",
      "Model [128, 64], LR 0.01, Batch 64, Cross-Validation Error: 0.1781, Training Accuracy: 0.9800\n",
      "Training model with hidden_sizes=[128, 64], learning_rate=0.01, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2695, Accuracy: 0.9157\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1267, Accuracy: 0.9617\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [3/10], Loss: 0.1041, Accuracy: 0.9684\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0830, Accuracy: 0.9742\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0816, Accuracy: 0.9755\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0689, Accuracy: 0.9790\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0763, Accuracy: 0.9780\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0655, Accuracy: 0.9815\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0583, Accuracy: 0.9832\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0604, Accuracy: 0.9832\n",
      "Validation Error for Fold 1: 0.1537\n",
      "Fold 2\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2815, Accuracy: 0.9114\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1231, Accuracy: 0.9614\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0994, Accuracy: 0.9690\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0856, Accuracy: 0.9737\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0790, Accuracy: 0.9757\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0747, Accuracy: 0.9772\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0652, Accuracy: 0.9799\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0592, Accuracy: 0.9820\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0632, Accuracy: 0.9814\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0556, Accuracy: 0.9840\n",
      "Validation Error for Fold 2: 0.1650\n",
      "Fold 3\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2718, Accuracy: 0.9170\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1276, Accuracy: 0.9612\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0995, Accuracy: 0.9697\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0869, Accuracy: 0.9726\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0833, Accuracy: 0.9742\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0710, Accuracy: 0.9789\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0648, Accuracy: 0.9808\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0639, Accuracy: 0.9812\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0641, Accuracy: 0.9812\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0598, Accuracy: 0.9829\n",
      "Validation Error for Fold 3: 0.1498\n",
      "Fold 4\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2589, Accuracy: 0.9206\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1212, Accuracy: 0.9625\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0930, Accuracy: 0.9723\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0821, Accuracy: 0.9749\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0755, Accuracy: 0.9775\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0676, Accuracy: 0.9792\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0749, Accuracy: 0.9783\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0552, Accuracy: 0.9830\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0679, Accuracy: 0.9810\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0602, Accuracy: 0.9830\n",
      "Validation Error for Fold 4: 0.1830\n",
      "Fold 5\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2723, Accuracy: 0.9170\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1296, Accuracy: 0.9609\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [3/10], Loss: 0.1037, Accuracy: 0.9689\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0883, Accuracy: 0.9734\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0781, Accuracy: 0.9761\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0767, Accuracy: 0.9766\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0678, Accuracy: 0.9794\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0732, Accuracy: 0.9791\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0622, Accuracy: 0.9814\n",
      "Model [128, 64], LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0582, Accuracy: 0.9835\n",
      "Validation Error for Fold 5: 0.1571\n",
      "Model [128, 64], LR 0.01, Batch 128, Cross-Validation Error: 0.1617, Training Accuracy: 0.9833\n",
      "Training model with hidden_sizes=[128, 64], learning_rate=0.001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [1/10], Loss: 0.3766, Accuracy: 0.8955\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [2/10], Loss: 0.1600, Accuracy: 0.9521\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [3/10], Loss: 0.1142, Accuracy: 0.9661\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0847, Accuracy: 0.9741\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0671, Accuracy: 0.9793\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0515, Accuracy: 0.9835\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0415, Accuracy: 0.9868\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0342, Accuracy: 0.9892\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0280, Accuracy: 0.9918\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0235, Accuracy: 0.9922\n",
      "Validation Error for Fold 1: 0.1010\n",
      "Fold 2\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [1/10], Loss: 0.3805, Accuracy: 0.8929\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [2/10], Loss: 0.1617, Accuracy: 0.9525\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [3/10], Loss: 0.1125, Accuracy: 0.9657\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0864, Accuracy: 0.9734\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0680, Accuracy: 0.9795\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0552, Accuracy: 0.9830\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0434, Accuracy: 0.9858\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0353, Accuracy: 0.9884\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0299, Accuracy: 0.9902\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0258, Accuracy: 0.9916\n",
      "Validation Error for Fold 2: 0.0964\n",
      "Fold 3\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [1/10], Loss: 0.3614, Accuracy: 0.8986\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [2/10], Loss: 0.1467, Accuracy: 0.9563\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [3/10], Loss: 0.1023, Accuracy: 0.9694\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0776, Accuracy: 0.9762\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0601, Accuracy: 0.9822\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0468, Accuracy: 0.9858\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0377, Accuracy: 0.9887\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0318, Accuracy: 0.9898\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0251, Accuracy: 0.9919\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0230, Accuracy: 0.9926\n",
      "Validation Error for Fold 3: 0.1016\n",
      "Fold 4\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [1/10], Loss: 0.3730, Accuracy: 0.8943\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [2/10], Loss: 0.1546, Accuracy: 0.9540\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [3/10], Loss: 0.1050, Accuracy: 0.9682\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0799, Accuracy: 0.9757\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0628, Accuracy: 0.9808\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0493, Accuracy: 0.9846\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0407, Accuracy: 0.9876\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0317, Accuracy: 0.9902\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0293, Accuracy: 0.9909\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0219, Accuracy: 0.9935\n",
      "Validation Error for Fold 4: 0.1001\n",
      "Fold 5\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [1/10], Loss: 0.3794, Accuracy: 0.8918\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [2/10], Loss: 0.1561, Accuracy: 0.9537\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [3/10], Loss: 0.1058, Accuracy: 0.9688\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0795, Accuracy: 0.9758\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0618, Accuracy: 0.9805\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0488, Accuracy: 0.9841\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0386, Accuracy: 0.9876\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0312, Accuracy: 0.9904\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0263, Accuracy: 0.9912\n",
      "Model [128, 64], LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0207, Accuracy: 0.9937\n",
      "Validation Error for Fold 5: 0.1110\n",
      "Model [128, 64], LR 0.001, Batch 64, Cross-Validation Error: 0.1020, Training Accuracy: 0.9927\n",
      "Training model with hidden_sizes=[128, 64], learning_rate=0.001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [1/10], Loss: 0.4655, Accuracy: 0.8727\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [2/10], Loss: 0.2026, Accuracy: 0.9415\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [3/10], Loss: 0.1425, Accuracy: 0.9576\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [4/10], Loss: 0.1107, Accuracy: 0.9661\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0871, Accuracy: 0.9738\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0713, Accuracy: 0.9779\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0586, Accuracy: 0.9820\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0491, Accuracy: 0.9851\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0403, Accuracy: 0.9874\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0357, Accuracy: 0.9886\n",
      "Validation Error for Fold 1: 0.0960\n",
      "Fold 2\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [1/10], Loss: 0.4659, Accuracy: 0.8728\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [2/10], Loss: 0.1901, Accuracy: 0.9459\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [3/10], Loss: 0.1383, Accuracy: 0.9592\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [4/10], Loss: 0.1084, Accuracy: 0.9677\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0882, Accuracy: 0.9732\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0702, Accuracy: 0.9789\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0568, Accuracy: 0.9824\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0479, Accuracy: 0.9855\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0385, Accuracy: 0.9884\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0307, Accuracy: 0.9909\n",
      "Validation Error for Fold 2: 0.0984\n",
      "Fold 3\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [1/10], Loss: 0.4673, Accuracy: 0.8709\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [2/10], Loss: 0.1940, Accuracy: 0.9439\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [3/10], Loss: 0.1377, Accuracy: 0.9595\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [4/10], Loss: 0.1070, Accuracy: 0.9683\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0855, Accuracy: 0.9746\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0690, Accuracy: 0.9794\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0589, Accuracy: 0.9819\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0481, Accuracy: 0.9861\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0401, Accuracy: 0.9882\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0340, Accuracy: 0.9897\n",
      "Validation Error for Fold 3: 0.0996\n",
      "Fold 4\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [1/10], Loss: 0.4587, Accuracy: 0.8759\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [2/10], Loss: 0.1929, Accuracy: 0.9433\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [3/10], Loss: 0.1429, Accuracy: 0.9579\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [4/10], Loss: 0.1105, Accuracy: 0.9673\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0859, Accuracy: 0.9745\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0708, Accuracy: 0.9788\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0593, Accuracy: 0.9815\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0480, Accuracy: 0.9849\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0386, Accuracy: 0.9885\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0343, Accuracy: 0.9900\n",
      "Validation Error for Fold 4: 0.0948\n",
      "Fold 5\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [1/10], Loss: 0.4773, Accuracy: 0.8735\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [2/10], Loss: 0.2051, Accuracy: 0.9395\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [3/10], Loss: 0.1452, Accuracy: 0.9556\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [4/10], Loss: 0.1105, Accuracy: 0.9670\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0866, Accuracy: 0.9740\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0720, Accuracy: 0.9780\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0575, Accuracy: 0.9826\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0478, Accuracy: 0.9855\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0391, Accuracy: 0.9881\n",
      "Model [128, 64], LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0321, Accuracy: 0.9898\n",
      "Validation Error for Fold 5: 0.0994\n",
      "Model [128, 64], LR 0.001, Batch 128, Cross-Validation Error: 0.0976, Training Accuracy: 0.9898\n",
      "Training model with hidden_sizes=[128, 64], learning_rate=0.0001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [1/10], Loss: 1.0191, Accuracy: 0.7372\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.3750, Accuracy: 0.8971\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.3046, Accuracy: 0.9140\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.2704, Accuracy: 0.9234\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.2459, Accuracy: 0.9304\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.2263, Accuracy: 0.9362\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.2091, Accuracy: 0.9409\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.1941, Accuracy: 0.9452\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.1812, Accuracy: 0.9485\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.1697, Accuracy: 0.9519\n",
      "Validation Error for Fold 1: 0.1837\n",
      "Fold 2\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [1/10], Loss: 1.0235, Accuracy: 0.7499\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.3704, Accuracy: 0.8986\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.3068, Accuracy: 0.9133\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.2763, Accuracy: 0.9208\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.2541, Accuracy: 0.9275\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.2355, Accuracy: 0.9332\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.2195, Accuracy: 0.9383\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.2049, Accuracy: 0.9426\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.1918, Accuracy: 0.9462\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.1801, Accuracy: 0.9494\n",
      "Validation Error for Fold 2: 0.1903\n",
      "Fold 3\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [1/10], Loss: 1.0063, Accuracy: 0.7770\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.3593, Accuracy: 0.9018\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.2982, Accuracy: 0.9158\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.2676, Accuracy: 0.9239\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.2455, Accuracy: 0.9297\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.2276, Accuracy: 0.9351\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.2122, Accuracy: 0.9391\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.1981, Accuracy: 0.9435\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.1855, Accuracy: 0.9476\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.1744, Accuracy: 0.9501\n",
      "Validation Error for Fold 3: 0.1830\n",
      "Fold 4\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [1/10], Loss: 1.0055, Accuracy: 0.7642\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.3728, Accuracy: 0.8985\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.3054, Accuracy: 0.9139\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.2702, Accuracy: 0.9241\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.2446, Accuracy: 0.9309\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.2240, Accuracy: 0.9367\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.2061, Accuracy: 0.9409\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.1908, Accuracy: 0.9450\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.1773, Accuracy: 0.9491\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.1652, Accuracy: 0.9521\n",
      "Validation Error for Fold 4: 0.1841\n",
      "Fold 5\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [1/10], Loss: 1.0113, Accuracy: 0.7565\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.3697, Accuracy: 0.8990\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.3050, Accuracy: 0.9133\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.2718, Accuracy: 0.9222\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.2481, Accuracy: 0.9285\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.2286, Accuracy: 0.9346\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.2115, Accuracy: 0.9390\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.1967, Accuracy: 0.9437\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.1841, Accuracy: 0.9475\n",
      "Model [128, 64], LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.1719, Accuracy: 0.9515\n",
      "Validation Error for Fold 5: 0.1860\n",
      "Model [128, 64], LR 0.0001, Batch 64, Cross-Validation Error: 0.1854, Training Accuracy: 0.9510\n",
      "Training model with hidden_sizes=[128, 64], learning_rate=0.0001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.3541, Accuracy: 0.6884\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.4788, Accuracy: 0.8799\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.3607, Accuracy: 0.9018\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.3195, Accuracy: 0.9102\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.2949, Accuracy: 0.9163\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.2773, Accuracy: 0.9214\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.2629, Accuracy: 0.9250\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.2505, Accuracy: 0.9285\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.2389, Accuracy: 0.9317\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.2277, Accuracy: 0.9344\n",
      "Validation Error for Fold 1: 0.2370\n",
      "Fold 2\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.3991, Accuracy: 0.6784\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.4883, Accuracy: 0.8738\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.3536, Accuracy: 0.9036\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.3050, Accuracy: 0.9138\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.2774, Accuracy: 0.9221\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.2573, Accuracy: 0.9260\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.2416, Accuracy: 0.9308\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.2279, Accuracy: 0.9347\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.2161, Accuracy: 0.9384\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.2054, Accuracy: 0.9410\n",
      "Validation Error for Fold 2: 0.2148\n",
      "Fold 3\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.3276, Accuracy: 0.7080\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.4659, Accuracy: 0.8813\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.3513, Accuracy: 0.9035\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.3101, Accuracy: 0.9128\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.2860, Accuracy: 0.9200\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.2675, Accuracy: 0.9244\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.2522, Accuracy: 0.9286\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.2386, Accuracy: 0.9322\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.2247, Accuracy: 0.9369\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.2134, Accuracy: 0.9396\n",
      "Validation Error for Fold 3: 0.2158\n",
      "Fold 4\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.3794, Accuracy: 0.6877\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.4825, Accuracy: 0.8795\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.3555, Accuracy: 0.9015\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.3058, Accuracy: 0.9132\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.2758, Accuracy: 0.9219\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.2534, Accuracy: 0.9285\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.2361, Accuracy: 0.9326\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.2217, Accuracy: 0.9371\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.2092, Accuracy: 0.9400\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.1982, Accuracy: 0.9435\n",
      "Validation Error for Fold 4: 0.2148\n",
      "Fold 5\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.3954, Accuracy: 0.6606\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.4864, Accuracy: 0.8789\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.3564, Accuracy: 0.9039\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.3118, Accuracy: 0.9134\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.2863, Accuracy: 0.9196\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.2687, Accuracy: 0.9237\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.2538, Accuracy: 0.9277\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.2407, Accuracy: 0.9305\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.2291, Accuracy: 0.9345\n",
      "Model [128, 64], LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.2182, Accuracy: 0.9375\n",
      "Validation Error for Fold 5: 0.2360\n",
      "Model [128, 64], LR 0.0001, Batch 128, Cross-Validation Error: 0.2237, Training Accuracy: 0.9392\n",
      "Training model with hidden_sizes=[256, 128], learning_rate=0.01, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2609, Accuracy: 0.9226\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1580, Accuracy: 0.9555\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1331, Accuracy: 0.9634\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1204, Accuracy: 0.9670\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1055, Accuracy: 0.9711\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [6/10], Loss: 0.1021, Accuracy: 0.9730\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0949, Accuracy: 0.9753\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0913, Accuracy: 0.9771\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0823, Accuracy: 0.9793\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0887, Accuracy: 0.9790\n",
      "Validation Error for Fold 1: 0.1782\n",
      "Fold 2\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2637, Accuracy: 0.9214\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1571, Accuracy: 0.9557\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1328, Accuracy: 0.9639\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1262, Accuracy: 0.9654\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1075, Accuracy: 0.9709\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0957, Accuracy: 0.9735\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [7/10], Loss: 0.1008, Accuracy: 0.9736\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0949, Accuracy: 0.9750\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0844, Accuracy: 0.9790\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0842, Accuracy: 0.9790\n",
      "Validation Error for Fold 2: 0.1924\n",
      "Fold 3\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2620, Accuracy: 0.9214\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1559, Accuracy: 0.9558\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1305, Accuracy: 0.9634\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1162, Accuracy: 0.9689\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1075, Accuracy: 0.9704\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0964, Accuracy: 0.9744\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [7/10], Loss: 0.1081, Accuracy: 0.9726\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0776, Accuracy: 0.9785\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0859, Accuracy: 0.9780\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0846, Accuracy: 0.9790\n",
      "Validation Error for Fold 3: 0.2241\n",
      "Fold 4\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2616, Accuracy: 0.9209\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1546, Accuracy: 0.9562\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1368, Accuracy: 0.9626\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1238, Accuracy: 0.9668\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1011, Accuracy: 0.9728\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0950, Accuracy: 0.9742\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0872, Accuracy: 0.9769\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0840, Accuracy: 0.9778\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0777, Accuracy: 0.9794\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0799, Accuracy: 0.9798\n",
      "Validation Error for Fold 4: 0.1851\n",
      "Fold 5\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2557, Accuracy: 0.9231\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1545, Accuracy: 0.9573\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1291, Accuracy: 0.9639\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1109, Accuracy: 0.9695\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1044, Accuracy: 0.9712\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [6/10], Loss: 0.1004, Accuracy: 0.9730\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0951, Accuracy: 0.9746\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0866, Accuracy: 0.9780\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0804, Accuracy: 0.9792\n",
      "Model [256, 128], LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0801, Accuracy: 0.9805\n",
      "Validation Error for Fold 5: 0.1745\n",
      "Model [256, 128], LR 0.01, Batch 64, Cross-Validation Error: 0.1909, Training Accuracy: 0.9795\n",
      "Training model with hidden_sizes=[256, 128], learning_rate=0.01, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2525, Accuracy: 0.9222\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1240, Accuracy: 0.9633\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [3/10], Loss: 0.1038, Accuracy: 0.9693\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0848, Accuracy: 0.9749\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0793, Accuracy: 0.9778\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0752, Accuracy: 0.9781\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0749, Accuracy: 0.9797\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0573, Accuracy: 0.9838\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0597, Accuracy: 0.9832\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0651, Accuracy: 0.9820\n",
      "Validation Error for Fold 1: 0.1755\n",
      "Fold 2\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2441, Accuracy: 0.9260\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1233, Accuracy: 0.9636\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0998, Accuracy: 0.9705\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0894, Accuracy: 0.9740\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0834, Accuracy: 0.9759\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0715, Accuracy: 0.9792\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0696, Accuracy: 0.9813\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0700, Accuracy: 0.9801\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0664, Accuracy: 0.9821\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0605, Accuracy: 0.9835\n",
      "Validation Error for Fold 2: 0.1535\n",
      "Fold 3\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2488, Accuracy: 0.9230\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1280, Accuracy: 0.9615\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [3/10], Loss: 0.1012, Accuracy: 0.9708\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0864, Accuracy: 0.9751\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0782, Accuracy: 0.9771\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0785, Accuracy: 0.9775\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0793, Accuracy: 0.9784\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0603, Accuracy: 0.9830\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0671, Accuracy: 0.9817\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0528, Accuracy: 0.9851\n",
      "Validation Error for Fold 3: 0.1642\n",
      "Fold 4\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2530, Accuracy: 0.9219\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1302, Accuracy: 0.9616\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [3/10], Loss: 0.1044, Accuracy: 0.9692\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0897, Accuracy: 0.9735\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0832, Accuracy: 0.9758\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0804, Accuracy: 0.9772\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0737, Accuracy: 0.9795\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0649, Accuracy: 0.9826\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0624, Accuracy: 0.9834\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0641, Accuracy: 0.9831\n",
      "Validation Error for Fold 4: 0.1692\n",
      "Fold 5\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2430, Accuracy: 0.9241\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1249, Accuracy: 0.9632\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0994, Accuracy: 0.9710\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0825, Accuracy: 0.9756\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0849, Accuracy: 0.9755\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0816, Accuracy: 0.9774\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0686, Accuracy: 0.9806\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0615, Accuracy: 0.9828\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0688, Accuracy: 0.9821\n",
      "Model [256, 128], LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0605, Accuracy: 0.9837\n",
      "Validation Error for Fold 5: 0.1657\n",
      "Model [256, 128], LR 0.01, Batch 128, Cross-Validation Error: 0.1656, Training Accuracy: 0.9835\n",
      "Training model with hidden_sizes=[256, 128], learning_rate=0.001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [1/10], Loss: 0.3169, Accuracy: 0.9077\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [2/10], Loss: 0.1194, Accuracy: 0.9634\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0772, Accuracy: 0.9758\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0567, Accuracy: 0.9823\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0429, Accuracy: 0.9861\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0318, Accuracy: 0.9892\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0266, Accuracy: 0.9908\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0217, Accuracy: 0.9925\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0179, Accuracy: 0.9940\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0157, Accuracy: 0.9950\n",
      "Validation Error for Fold 1: 0.1191\n",
      "Fold 2\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [1/10], Loss: 0.3151, Accuracy: 0.9124\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [2/10], Loss: 0.1221, Accuracy: 0.9630\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0801, Accuracy: 0.9753\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0585, Accuracy: 0.9821\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0433, Accuracy: 0.9865\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0340, Accuracy: 0.9895\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0258, Accuracy: 0.9914\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0206, Accuracy: 0.9931\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0180, Accuracy: 0.9940\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0143, Accuracy: 0.9954\n",
      "Validation Error for Fold 2: 0.0874\n",
      "Fold 3\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [1/10], Loss: 0.3233, Accuracy: 0.9096\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [2/10], Loss: 0.1266, Accuracy: 0.9621\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0831, Accuracy: 0.9743\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0598, Accuracy: 0.9814\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0442, Accuracy: 0.9861\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0350, Accuracy: 0.9886\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0276, Accuracy: 0.9918\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0198, Accuracy: 0.9940\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0204, Accuracy: 0.9932\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0158, Accuracy: 0.9947\n",
      "Validation Error for Fold 3: 0.0966\n",
      "Fold 4\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [1/10], Loss: 0.3126, Accuracy: 0.9086\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [2/10], Loss: 0.1191, Accuracy: 0.9640\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0804, Accuracy: 0.9756\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0574, Accuracy: 0.9825\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0427, Accuracy: 0.9869\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0312, Accuracy: 0.9900\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0260, Accuracy: 0.9916\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0218, Accuracy: 0.9927\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0169, Accuracy: 0.9946\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0164, Accuracy: 0.9946\n",
      "Validation Error for Fold 4: 0.0986\n",
      "Fold 5\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [1/10], Loss: 0.3188, Accuracy: 0.9082\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [2/10], Loss: 0.1208, Accuracy: 0.9643\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0800, Accuracy: 0.9758\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0553, Accuracy: 0.9826\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0433, Accuracy: 0.9860\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0323, Accuracy: 0.9894\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0248, Accuracy: 0.9922\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0213, Accuracy: 0.9935\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0171, Accuracy: 0.9945\n",
      "Model [256, 128], LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0146, Accuracy: 0.9951\n",
      "Validation Error for Fold 5: 0.0909\n",
      "Model [256, 128], LR 0.001, Batch 64, Cross-Validation Error: 0.0985, Training Accuracy: 0.9949\n",
      "Training model with hidden_sizes=[256, 128], learning_rate=0.001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3978, Accuracy: 0.8885\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [2/10], Loss: 0.1527, Accuracy: 0.9550\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [3/10], Loss: 0.1022, Accuracy: 0.9705\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0742, Accuracy: 0.9771\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0532, Accuracy: 0.9839\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0403, Accuracy: 0.9877\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0328, Accuracy: 0.9897\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0251, Accuracy: 0.9921\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0203, Accuracy: 0.9938\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0150, Accuracy: 0.9953\n",
      "Validation Error for Fold 1: 0.1085\n",
      "Fold 2\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3911, Accuracy: 0.8914\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [2/10], Loss: 0.1514, Accuracy: 0.9553\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [3/10], Loss: 0.1005, Accuracy: 0.9704\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0722, Accuracy: 0.9776\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0548, Accuracy: 0.9831\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0423, Accuracy: 0.9863\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0332, Accuracy: 0.9892\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0257, Accuracy: 0.9919\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0191, Accuracy: 0.9941\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0157, Accuracy: 0.9952\n",
      "Validation Error for Fold 2: 0.0827\n",
      "Fold 3\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3840, Accuracy: 0.8921\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [2/10], Loss: 0.1481, Accuracy: 0.9564\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0998, Accuracy: 0.9702\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0736, Accuracy: 0.9776\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0561, Accuracy: 0.9825\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0415, Accuracy: 0.9873\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0343, Accuracy: 0.9895\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0254, Accuracy: 0.9925\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0200, Accuracy: 0.9937\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0161, Accuracy: 0.9950\n",
      "Validation Error for Fold 3: 0.0908\n",
      "Fold 4\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3905, Accuracy: 0.8916\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [2/10], Loss: 0.1558, Accuracy: 0.9539\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [3/10], Loss: 0.1020, Accuracy: 0.9692\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0709, Accuracy: 0.9789\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0546, Accuracy: 0.9830\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0425, Accuracy: 0.9865\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0342, Accuracy: 0.9891\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0243, Accuracy: 0.9928\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0198, Accuracy: 0.9938\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0165, Accuracy: 0.9948\n",
      "Validation Error for Fold 4: 0.0952\n",
      "Fold 5\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3897, Accuracy: 0.8907\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [2/10], Loss: 0.1476, Accuracy: 0.9566\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [3/10], Loss: 0.1014, Accuracy: 0.9691\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0731, Accuracy: 0.9774\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0542, Accuracy: 0.9836\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0409, Accuracy: 0.9873\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0321, Accuracy: 0.9900\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0260, Accuracy: 0.9920\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0193, Accuracy: 0.9939\n",
      "Model [256, 128], LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0143, Accuracy: 0.9960\n",
      "Validation Error for Fold 5: 0.0931\n",
      "Model [256, 128], LR 0.001, Batch 128, Cross-Validation Error: 0.0941, Training Accuracy: 0.9953\n",
      "Training model with hidden_sizes=[256, 128], learning_rate=0.0001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.7951, Accuracy: 0.8008\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.3147, Accuracy: 0.9103\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.2614, Accuracy: 0.9255\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.2270, Accuracy: 0.9349\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.1990, Accuracy: 0.9429\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.1773, Accuracy: 0.9491\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.1588, Accuracy: 0.9543\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.1442, Accuracy: 0.9582\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.1303, Accuracy: 0.9620\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.1187, Accuracy: 0.9652\n",
      "Validation Error for Fold 1: 0.1374\n",
      "Fold 2\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.7872, Accuracy: 0.8245\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.3120, Accuracy: 0.9124\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.2581, Accuracy: 0.9277\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.2228, Accuracy: 0.9368\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.1953, Accuracy: 0.9446\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.1734, Accuracy: 0.9508\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.1553, Accuracy: 0.9560\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.1399, Accuracy: 0.9599\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.1263, Accuracy: 0.9639\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.1152, Accuracy: 0.9673\n",
      "Validation Error for Fold 2: 0.1310\n",
      "Fold 3\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.7793, Accuracy: 0.8170\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.3146, Accuracy: 0.9111\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.2647, Accuracy: 0.9242\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.2312, Accuracy: 0.9336\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.2040, Accuracy: 0.9421\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.1821, Accuracy: 0.9477\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.1623, Accuracy: 0.9536\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.1458, Accuracy: 0.9582\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.1322, Accuracy: 0.9623\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.1204, Accuracy: 0.9658\n",
      "Validation Error for Fold 3: 0.1392\n",
      "Fold 4\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.7775, Accuracy: 0.8284\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.3105, Accuracy: 0.9122\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.2588, Accuracy: 0.9267\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.2240, Accuracy: 0.9357\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.1973, Accuracy: 0.9436\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.1750, Accuracy: 0.9492\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.1563, Accuracy: 0.9544\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.1404, Accuracy: 0.9598\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.1276, Accuracy: 0.9635\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.1156, Accuracy: 0.9672\n",
      "Validation Error for Fold 4: 0.1380\n",
      "Fold 5\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.7863, Accuracy: 0.8191\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.3083, Accuracy: 0.9142\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.2574, Accuracy: 0.9259\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.2257, Accuracy: 0.9349\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.2004, Accuracy: 0.9420\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.1800, Accuracy: 0.9479\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.1621, Accuracy: 0.9535\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.1474, Accuracy: 0.9574\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.1335, Accuracy: 0.9621\n",
      "Model [256, 128], LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.1222, Accuracy: 0.9647\n",
      "Validation Error for Fold 5: 0.1421\n",
      "Model [256, 128], LR 0.0001, Batch 64, Cross-Validation Error: 0.1375, Training Accuracy: 0.9660\n",
      "Training model with hidden_sizes=[256, 128], learning_rate=0.0001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.0801, Accuracy: 0.7650\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.3662, Accuracy: 0.8993\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2968, Accuracy: 0.9163\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.2597, Accuracy: 0.9258\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.2324, Accuracy: 0.9347\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.2098, Accuracy: 0.9395\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.1917, Accuracy: 0.9460\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.1768, Accuracy: 0.9498\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.1629, Accuracy: 0.9539\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.1516, Accuracy: 0.9572\n",
      "Validation Error for Fold 1: 0.1681\n",
      "Fold 2\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.0573, Accuracy: 0.7878\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.3672, Accuracy: 0.9003\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2957, Accuracy: 0.9163\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.2608, Accuracy: 0.9264\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.2358, Accuracy: 0.9336\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.2158, Accuracy: 0.9390\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.1996, Accuracy: 0.9436\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.1845, Accuracy: 0.9482\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.1716, Accuracy: 0.9512\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.1598, Accuracy: 0.9538\n",
      "Validation Error for Fold 2: 0.1696\n",
      "Fold 3\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.0560, Accuracy: 0.7613\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.3680, Accuracy: 0.8999\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2994, Accuracy: 0.9165\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.2646, Accuracy: 0.9253\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.2397, Accuracy: 0.9325\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.2185, Accuracy: 0.9382\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.2010, Accuracy: 0.9424\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.1864, Accuracy: 0.9474\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.1724, Accuracy: 0.9515\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.1605, Accuracy: 0.9545\n",
      "Validation Error for Fold 3: 0.1713\n",
      "Fold 4\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.0552, Accuracy: 0.7380\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.3679, Accuracy: 0.9004\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.3022, Accuracy: 0.9141\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.2694, Accuracy: 0.9234\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.2452, Accuracy: 0.9300\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.2252, Accuracy: 0.9355\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.2073, Accuracy: 0.9411\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.1921, Accuracy: 0.9450\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.1777, Accuracy: 0.9493\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.1651, Accuracy: 0.9527\n",
      "Validation Error for Fold 4: 0.1824\n",
      "Fold 5\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.0727, Accuracy: 0.7692\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.3703, Accuracy: 0.8996\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2989, Accuracy: 0.9165\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.2621, Accuracy: 0.9258\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.2356, Accuracy: 0.9325\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.2138, Accuracy: 0.9393\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.1960, Accuracy: 0.9438\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.1807, Accuracy: 0.9481\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.1669, Accuracy: 0.9525\n",
      "Model [256, 128], LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.1551, Accuracy: 0.9555\n",
      "Validation Error for Fold 5: 0.1694\n",
      "Model [256, 128], LR 0.0001, Batch 128, Cross-Validation Error: 0.1722, Training Accuracy: 0.9547\n",
      "Training model with hidden_sizes=[512, 256], learning_rate=0.01, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2716, Accuracy: 0.9190\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1635, Accuracy: 0.9539\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1361, Accuracy: 0.9630\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1228, Accuracy: 0.9660\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1091, Accuracy: 0.9703\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0905, Accuracy: 0.9757\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0948, Accuracy: 0.9749\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0834, Accuracy: 0.9779\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0838, Accuracy: 0.9786\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0755, Accuracy: 0.9803\n",
      "Validation Error for Fold 1: 0.1645\n",
      "Fold 2\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2761, Accuracy: 0.9182\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1610, Accuracy: 0.9547\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1403, Accuracy: 0.9615\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1224, Accuracy: 0.9668\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1077, Accuracy: 0.9710\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0934, Accuracy: 0.9750\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0907, Accuracy: 0.9758\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0877, Accuracy: 0.9768\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0846, Accuracy: 0.9779\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0702, Accuracy: 0.9818\n",
      "Validation Error for Fold 2: 0.1742\n",
      "Fold 3\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2642, Accuracy: 0.9232\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1662, Accuracy: 0.9548\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1340, Accuracy: 0.9639\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1342, Accuracy: 0.9635\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1097, Accuracy: 0.9708\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [6/10], Loss: 0.1148, Accuracy: 0.9707\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0957, Accuracy: 0.9744\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0977, Accuracy: 0.9751\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [9/10], Loss: 0.1002, Accuracy: 0.9755\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0820, Accuracy: 0.9794\n",
      "Validation Error for Fold 3: 0.1742\n",
      "Fold 4\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2743, Accuracy: 0.9197\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1654, Accuracy: 0.9547\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1323, Accuracy: 0.9632\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1262, Accuracy: 0.9660\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1132, Accuracy: 0.9702\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0923, Accuracy: 0.9758\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0962, Accuracy: 0.9745\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0937, Accuracy: 0.9760\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0942, Accuracy: 0.9761\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0885, Accuracy: 0.9790\n",
      "Validation Error for Fold 4: 0.2015\n",
      "Fold 5\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2731, Accuracy: 0.9206\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1666, Accuracy: 0.9540\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1404, Accuracy: 0.9624\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1278, Accuracy: 0.9658\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1122, Accuracy: 0.9701\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [6/10], Loss: 0.1102, Accuracy: 0.9723\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0965, Accuracy: 0.9757\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0979, Accuracy: 0.9750\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0852, Accuracy: 0.9785\n",
      "Model [512, 256], LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0815, Accuracy: 0.9791\n",
      "Validation Error for Fold 5: 0.2138\n",
      "Model [512, 256], LR 0.01, Batch 64, Cross-Validation Error: 0.1857, Training Accuracy: 0.9799\n",
      "Training model with hidden_sizes=[512, 256], learning_rate=0.01, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2491, Accuracy: 0.9243\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1404, Accuracy: 0.9592\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [3/10], Loss: 0.1141, Accuracy: 0.9664\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0993, Accuracy: 0.9713\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0845, Accuracy: 0.9762\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0765, Accuracy: 0.9785\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0841, Accuracy: 0.9776\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0707, Accuracy: 0.9810\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0716, Accuracy: 0.9810\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0671, Accuracy: 0.9830\n",
      "Validation Error for Fold 1: 0.1604\n",
      "Fold 2\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2568, Accuracy: 0.9225\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1360, Accuracy: 0.9606\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [3/10], Loss: 0.1072, Accuracy: 0.9687\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0940, Accuracy: 0.9727\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0921, Accuracy: 0.9732\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0833, Accuracy: 0.9769\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0753, Accuracy: 0.9791\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0663, Accuracy: 0.9820\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0712, Accuracy: 0.9814\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0627, Accuracy: 0.9833\n",
      "Validation Error for Fold 2: 0.1627\n",
      "Fold 3\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2485, Accuracy: 0.9244\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1351, Accuracy: 0.9606\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [3/10], Loss: 0.1046, Accuracy: 0.9692\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [4/10], Loss: 0.1039, Accuracy: 0.9706\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0824, Accuracy: 0.9775\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0877, Accuracy: 0.9758\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0693, Accuracy: 0.9810\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0709, Accuracy: 0.9816\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0795, Accuracy: 0.9804\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0583, Accuracy: 0.9845\n",
      "Validation Error for Fold 3: 0.1568\n",
      "Fold 4\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2583, Accuracy: 0.9205\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1306, Accuracy: 0.9617\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [3/10], Loss: 0.1100, Accuracy: 0.9686\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0961, Accuracy: 0.9731\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0856, Accuracy: 0.9755\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0896, Accuracy: 0.9761\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0708, Accuracy: 0.9796\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0785, Accuracy: 0.9786\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0719, Accuracy: 0.9805\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0719, Accuracy: 0.9813\n",
      "Validation Error for Fold 4: 0.1721\n",
      "Fold 5\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2481, Accuracy: 0.9250\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1366, Accuracy: 0.9603\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [3/10], Loss: 0.1119, Accuracy: 0.9686\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0883, Accuracy: 0.9747\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0801, Accuracy: 0.9778\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0838, Accuracy: 0.9768\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0708, Accuracy: 0.9806\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0785, Accuracy: 0.9791\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0672, Accuracy: 0.9824\n",
      "Model [512, 256], LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0568, Accuracy: 0.9850\n",
      "Validation Error for Fold 5: 0.1746\n",
      "Model [512, 256], LR 0.01, Batch 128, Cross-Validation Error: 0.1653, Training Accuracy: 0.9834\n",
      "Training model with hidden_sizes=[512, 256], learning_rate=0.001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2628, Accuracy: 0.9233\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0989, Accuracy: 0.9693\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0606, Accuracy: 0.9813\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0452, Accuracy: 0.9855\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0339, Accuracy: 0.9890\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0274, Accuracy: 0.9912\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0224, Accuracy: 0.9927\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0200, Accuracy: 0.9935\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0169, Accuracy: 0.9944\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0124, Accuracy: 0.9958\n",
      "Validation Error for Fold 1: 0.1175\n",
      "Fold 2\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2676, Accuracy: 0.9209\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [2/10], Loss: 0.1006, Accuracy: 0.9689\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0647, Accuracy: 0.9797\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0454, Accuracy: 0.9851\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0336, Accuracy: 0.9894\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0267, Accuracy: 0.9903\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0199, Accuracy: 0.9930\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0183, Accuracy: 0.9940\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0195, Accuracy: 0.9935\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0138, Accuracy: 0.9956\n",
      "Validation Error for Fold 2: 0.1077\n",
      "Fold 3\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2670, Accuracy: 0.9220\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0982, Accuracy: 0.9697\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0632, Accuracy: 0.9798\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0450, Accuracy: 0.9855\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0342, Accuracy: 0.9895\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0257, Accuracy: 0.9920\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0226, Accuracy: 0.9921\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0204, Accuracy: 0.9928\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0161, Accuracy: 0.9946\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0133, Accuracy: 0.9954\n",
      "Validation Error for Fold 3: 0.1136\n",
      "Fold 4\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2639, Accuracy: 0.9203\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0978, Accuracy: 0.9696\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0652, Accuracy: 0.9797\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0456, Accuracy: 0.9852\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0347, Accuracy: 0.9885\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0277, Accuracy: 0.9913\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0216, Accuracy: 0.9932\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0194, Accuracy: 0.9932\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0183, Accuracy: 0.9939\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0143, Accuracy: 0.9952\n",
      "Validation Error for Fold 4: 0.1013\n",
      "Fold 5\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2662, Accuracy: 0.9217\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [2/10], Loss: 0.1000, Accuracy: 0.9698\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0619, Accuracy: 0.9810\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0433, Accuracy: 0.9865\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0330, Accuracy: 0.9894\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0256, Accuracy: 0.9917\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0240, Accuracy: 0.9918\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0186, Accuracy: 0.9934\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0154, Accuracy: 0.9949\n",
      "Model [512, 256], LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0173, Accuracy: 0.9944\n",
      "Validation Error for Fold 5: 0.1152\n",
      "Model [512, 256], LR 0.001, Batch 64, Cross-Validation Error: 0.1111, Training Accuracy: 0.9953\n",
      "Training model with hidden_sizes=[512, 256], learning_rate=0.001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3209, Accuracy: 0.9090\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [2/10], Loss: 0.1176, Accuracy: 0.9640\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0711, Accuracy: 0.9779\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0509, Accuracy: 0.9836\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0367, Accuracy: 0.9885\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0279, Accuracy: 0.9913\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0195, Accuracy: 0.9937\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0175, Accuracy: 0.9945\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0164, Accuracy: 0.9946\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0118, Accuracy: 0.9960\n",
      "Validation Error for Fold 1: 0.1041\n",
      "Fold 2\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3171, Accuracy: 0.9084\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [2/10], Loss: 0.1220, Accuracy: 0.9631\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0760, Accuracy: 0.9774\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0529, Accuracy: 0.9839\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0378, Accuracy: 0.9880\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0274, Accuracy: 0.9911\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0222, Accuracy: 0.9929\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0191, Accuracy: 0.9938\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0144, Accuracy: 0.9951\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0163, Accuracy: 0.9945\n",
      "Validation Error for Fold 2: 0.0939\n",
      "Fold 3\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3136, Accuracy: 0.9100\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [2/10], Loss: 0.1127, Accuracy: 0.9665\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0739, Accuracy: 0.9767\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0493, Accuracy: 0.9846\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0360, Accuracy: 0.9888\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0273, Accuracy: 0.9910\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0190, Accuracy: 0.9940\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0180, Accuracy: 0.9941\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0150, Accuracy: 0.9949\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0151, Accuracy: 0.9948\n",
      "Validation Error for Fold 3: 0.0966\n",
      "Fold 4\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3193, Accuracy: 0.9099\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [2/10], Loss: 0.1147, Accuracy: 0.9656\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0729, Accuracy: 0.9778\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0527, Accuracy: 0.9835\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0366, Accuracy: 0.9884\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0289, Accuracy: 0.9906\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0240, Accuracy: 0.9923\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0185, Accuracy: 0.9944\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0160, Accuracy: 0.9949\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0120, Accuracy: 0.9964\n",
      "Validation Error for Fold 4: 0.0893\n",
      "Fold 5\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3242, Accuracy: 0.9071\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [2/10], Loss: 0.1180, Accuracy: 0.9647\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0724, Accuracy: 0.9779\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0501, Accuracy: 0.9838\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0363, Accuracy: 0.9889\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0269, Accuracy: 0.9917\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0213, Accuracy: 0.9932\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0170, Accuracy: 0.9945\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0154, Accuracy: 0.9946\n",
      "Model [512, 256], LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0132, Accuracy: 0.9956\n",
      "Validation Error for Fold 5: 0.0921\n",
      "Model [512, 256], LR 0.001, Batch 128, Cross-Validation Error: 0.0952, Training Accuracy: 0.9955\n",
      "Training model with hidden_sizes=[512, 256], learning_rate=0.0001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.6240, Accuracy: 0.8546\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.2643, Accuracy: 0.9244\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.2086, Accuracy: 0.9405\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.1720, Accuracy: 0.9501\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.1449, Accuracy: 0.9584\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.1248, Accuracy: 0.9644\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.1075, Accuracy: 0.9694\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0934, Accuracy: 0.9732\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0819, Accuracy: 0.9759\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0715, Accuracy: 0.9792\n",
      "Validation Error for Fold 1: 0.1085\n",
      "Fold 2\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.6219, Accuracy: 0.8521\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.2566, Accuracy: 0.9274\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.2006, Accuracy: 0.9423\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.1641, Accuracy: 0.9528\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.1379, Accuracy: 0.9602\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.1174, Accuracy: 0.9668\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.1016, Accuracy: 0.9709\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0881, Accuracy: 0.9743\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0775, Accuracy: 0.9776\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0679, Accuracy: 0.9800\n",
      "Validation Error for Fold 2: 0.0949\n",
      "Fold 3\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.6220, Accuracy: 0.8561\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.2708, Accuracy: 0.9226\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.2160, Accuracy: 0.9380\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.1785, Accuracy: 0.9491\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.1490, Accuracy: 0.9564\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.1272, Accuracy: 0.9639\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.1094, Accuracy: 0.9682\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0949, Accuracy: 0.9729\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0823, Accuracy: 0.9769\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0728, Accuracy: 0.9790\n",
      "Validation Error for Fold 3: 0.1011\n",
      "Fold 4\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.6171, Accuracy: 0.8530\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.2575, Accuracy: 0.9264\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.2036, Accuracy: 0.9416\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.1693, Accuracy: 0.9516\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.1430, Accuracy: 0.9585\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.1234, Accuracy: 0.9642\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.1063, Accuracy: 0.9688\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0926, Accuracy: 0.9733\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0810, Accuracy: 0.9770\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0708, Accuracy: 0.9802\n",
      "Validation Error for Fold 4: 0.1027\n",
      "Fold 5\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.6195, Accuracy: 0.8518\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.2616, Accuracy: 0.9253\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.2082, Accuracy: 0.9404\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.1732, Accuracy: 0.9498\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.1465, Accuracy: 0.9576\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.1252, Accuracy: 0.9645\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.1082, Accuracy: 0.9692\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0938, Accuracy: 0.9728\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0819, Accuracy: 0.9762\n",
      "Model [512, 256], LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0707, Accuracy: 0.9799\n",
      "Validation Error for Fold 5: 0.0997\n",
      "Model [512, 256], LR 0.0001, Batch 64, Cross-Validation Error: 0.1014, Training Accuracy: 0.9797\n",
      "Training model with hidden_sizes=[512, 256], learning_rate=0.0001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.8360, Accuracy: 0.8223\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.3054, Accuracy: 0.9132\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2497, Accuracy: 0.9288\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.2133, Accuracy: 0.9385\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1852, Accuracy: 0.9464\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.1640, Accuracy: 0.9527\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.1456, Accuracy: 0.9575\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.1302, Accuracy: 0.9620\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.1172, Accuracy: 0.9658\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.1058, Accuracy: 0.9688\n",
      "Validation Error for Fold 1: 0.1270\n",
      "Fold 2\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.8228, Accuracy: 0.8214\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.3030, Accuracy: 0.9140\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2464, Accuracy: 0.9295\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.2104, Accuracy: 0.9406\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1842, Accuracy: 0.9477\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.1619, Accuracy: 0.9544\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.1439, Accuracy: 0.9589\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.1287, Accuracy: 0.9637\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.1157, Accuracy: 0.9671\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.1043, Accuracy: 0.9699\n",
      "Validation Error for Fold 2: 0.1289\n",
      "Fold 3\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.8320, Accuracy: 0.8113\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.3020, Accuracy: 0.9150\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2454, Accuracy: 0.9305\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.2106, Accuracy: 0.9402\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1828, Accuracy: 0.9477\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.1611, Accuracy: 0.9536\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.1430, Accuracy: 0.9581\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.1276, Accuracy: 0.9633\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.1143, Accuracy: 0.9669\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.1030, Accuracy: 0.9705\n",
      "Validation Error for Fold 3: 0.1224\n",
      "Fold 4\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.8251, Accuracy: 0.8221\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.2999, Accuracy: 0.9154\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2436, Accuracy: 0.9308\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.2071, Accuracy: 0.9410\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1793, Accuracy: 0.9477\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.1578, Accuracy: 0.9544\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.1404, Accuracy: 0.9595\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.1255, Accuracy: 0.9639\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.1135, Accuracy: 0.9675\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.1022, Accuracy: 0.9706\n",
      "Validation Error for Fold 4: 0.1264\n",
      "Fold 5\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.8313, Accuracy: 0.8101\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.3043, Accuracy: 0.9143\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2480, Accuracy: 0.9298\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.2104, Accuracy: 0.9399\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1827, Accuracy: 0.9481\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.1605, Accuracy: 0.9536\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.1428, Accuracy: 0.9589\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.1287, Accuracy: 0.9632\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.1155, Accuracy: 0.9661\n",
      "Model [512, 256], LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.1043, Accuracy: 0.9702\n",
      "Validation Error for Fold 5: 0.1276\n",
      "Model [512, 256], LR 0.0001, Batch 128, Cross-Validation Error: 0.1265, Training Accuracy: 0.9700\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Select GPU if available, otherwise fall back to CPU\n",
    "for hidden_sizes in mlp_param_grid['hidden_sizes']:\n",
    "    for learning_rate in mlp_param_grid['learning_rate']:\n",
    "        for batch_size in mlp_param_grid['batch_size']:\n",
    "            for epochs in mlp_param_grid['epochs']:\n",
    "                val_loss = mlp_train_and_evaluate(hidden_sizes, learning_rate, batch_size, epochs)\n",
    "                if val_loss < mlp_best_val_loss:\n",
    "                    mlp_best_val_loss = val_loss\n",
    "                    mlp_best_params = {'hidden_sizes': hidden_sizes, 'learning_rate': learning_rate, 'batch_size': batch_size, 'epochs': epochs}# Finding the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ae196-0108-45ec-bf90-5f407fbb6fec",
   "metadata": {},
   "source": [
    "## CNN Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f544ca03-fedb-4b0d-b726-bede67526497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset for CNN (Not flattened like MLP)\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee20f2-bc94-4d60-9be8-e2812ef49bd3",
   "metadata": {},
   "source": [
    "### Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27122011-2994-4c84-a366-8f39a841033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'num_filters': [16, 32, 64],\n",
    "    'kernel_size': [3, 5],\n",
    "    'learning_rate': [0.01, 0.001, 0.0001],\n",
    "    'batch_size': [64, 128],\n",
    "    'epochs': [10]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a078a-91e2-4744-ba32-6b92e61b093e",
   "metadata": {},
   "source": [
    "### Train and Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03be3981-44c3-4e40-9722-6443bf3b21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(num_filters, kernel_size, learning_rate, batch_size, epochs):\n",
    "    # Print the configuration of the model being trained\n",
    "    print(f\"Training model with num_filters={num_filters}, kernel_size={kernel_size}, learning_rate={learning_rate}, batch_size={batch_size}, epochs={epochs}\")\n",
    "    \n",
    "    # Lists to track validation loss and final training accuracy for each fold\n",
    "    fold_losses = []\n",
    "    fold_train_accuracies = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset, targets)):\n",
    "        print(f\"Fold {fold+1}\") \n",
    "\n",
    "        # Create training and validation subsets for the current fold\n",
    "        train_subset = Subset(train_dataset, train_idx)\n",
    "        val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "        # Wrap subsets in DataLoaders for batch-wise training/evaluation\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize CNN model with specified number of filters and kernel size\n",
    "        model = CNN(num_filters, kernel_size, 10).to(device)\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Training loop for the current fold\n",
    "        for epoch in range(epochs):\n",
    "            model.train()  # Enable training mode\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            # Iterate through batches in training set\n",
    "            for i, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # Zero gradients before backward pass\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass and update weights\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Accumulate loss and accuracy stats\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "            # Calculate and log average loss and accuracy for the epoch\n",
    "            epoch_loss = running_loss / len(train_loader)\n",
    "            epoch_accuracy = correct / total\n",
    "            print(f\"Model {num_filters}, Kernel {kernel_size}, LR {learning_rate}, Batch {batch_size}, Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
    "        \n",
    "        # Evaluation phase on the validation set\n",
    "        model.eval()  # Switch to evaluation mode\n",
    "        val_loss = 0.0\n",
    "\n",
    "        # Disable gradient computation for inference\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Compute average validation loss for the current fold\n",
    "        fold_loss = val_loss / len(val_loader)\n",
    "        fold_losses.append(fold_loss)\n",
    "        fold_train_accuracies.append(epoch_accuracy)\n",
    "        print(f\"Validation Error for Fold {fold+1}: {fold_loss:.4f}\") \n",
    "    \n",
    "    # Compute average cross-validation error and training accuracy\n",
    "    cv_error = np.mean(fold_losses)\n",
    "    avg_train_accuracy = np.mean(fold_train_accuracies)\n",
    "\n",
    "    # Print summary results\n",
    "    print(f\"Model {num_filters}, Kernel {kernel_size}, LR {learning_rate}, Batch {batch_size}, Cross-Validation Error: {cv_error:.4f}, Training Accuracy: {avg_train_accuracy:.4f}\")\n",
    "    \n",
    "    return cv_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c4e3426-810a-4971-be06-5d4d73b35b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels for stratification\n",
    "targets = np.array(train_dataset.targets)\n",
    "\n",
    "# Stratified K-Fold\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initializing values\n",
    "best_model = None\n",
    "best_val_loss = float('inf')\n",
    "best_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0d92bd0-2ada-4963-aa30-4bf327067090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with num_filters=16, kernel_size=3, learning_rate=0.01, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.1673, Accuracy: 0.9468\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0682, Accuracy: 0.9794\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0582, Accuracy: 0.9822\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0500, Accuracy: 0.9853\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0440, Accuracy: 0.9869\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0449, Accuracy: 0.9867\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0420, Accuracy: 0.9872\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0440, Accuracy: 0.9874\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0420, Accuracy: 0.9880\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0450, Accuracy: 0.9876\n",
      "Validation Error for Fold 1: 0.0860\n",
      "Fold 2\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.1474, Accuracy: 0.9541\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0645, Accuracy: 0.9802\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0544, Accuracy: 0.9839\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0509, Accuracy: 0.9856\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0434, Accuracy: 0.9882\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0495, Accuracy: 0.9864\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0456, Accuracy: 0.9879\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0465, Accuracy: 0.9887\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0320, Accuracy: 0.9920\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0467, Accuracy: 0.9888\n",
      "Validation Error for Fold 2: 0.1155\n",
      "Fold 3\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.1370, Accuracy: 0.9573\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0649, Accuracy: 0.9803\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0551, Accuracy: 0.9837\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0514, Accuracy: 0.9846\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0441, Accuracy: 0.9874\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0430, Accuracy: 0.9875\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0466, Accuracy: 0.9870\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0358, Accuracy: 0.9903\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0339, Accuracy: 0.9907\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0397, Accuracy: 0.9901\n",
      "Validation Error for Fold 3: 0.0768\n",
      "Fold 4\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [1/10], Loss: 2.3032, Accuracy: 0.1094\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [2/10], Loss: 2.3021, Accuracy: 0.1108\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [3/10], Loss: 2.3021, Accuracy: 0.1115\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [4/10], Loss: 2.3021, Accuracy: 0.1113\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [5/10], Loss: 2.3023, Accuracy: 0.1109\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [6/10], Loss: 2.3022, Accuracy: 0.1099\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [7/10], Loss: 2.3020, Accuracy: 0.1113\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [8/10], Loss: 2.3022, Accuracy: 0.1100\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [9/10], Loss: 2.3022, Accuracy: 0.1115\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [10/10], Loss: 2.3023, Accuracy: 0.1104\n",
      "Validation Error for Fold 4: 2.3018\n",
      "Fold 5\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.1557, Accuracy: 0.9506\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0616, Accuracy: 0.9814\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0548, Accuracy: 0.9837\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0477, Accuracy: 0.9858\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0459, Accuracy: 0.9867\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0426, Accuracy: 0.9873\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0401, Accuracy: 0.9889\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0429, Accuracy: 0.9890\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0368, Accuracy: 0.9902\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0333, Accuracy: 0.9909\n",
      "Validation Error for Fold 5: 0.0715\n",
      "Model 16, Kernel 3, LR 0.01, Batch 64, Cross-Validation Error: 0.5303, Training Accuracy: 0.8136\n",
      "Training model with num_filters=16, kernel_size=3, learning_rate=0.01, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.1710, Accuracy: 0.9455\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0560, Accuracy: 0.9829\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0405, Accuracy: 0.9872\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0328, Accuracy: 0.9898\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0313, Accuracy: 0.9905\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0265, Accuracy: 0.9915\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0271, Accuracy: 0.9922\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0252, Accuracy: 0.9923\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0267, Accuracy: 0.9923\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0259, Accuracy: 0.9929\n",
      "Validation Error for Fold 1: 0.0746\n",
      "Fold 2\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.3218, Accuracy: 0.8961\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1033, Accuracy: 0.9669\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0838, Accuracy: 0.9734\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0716, Accuracy: 0.9771\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0681, Accuracy: 0.9782\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0623, Accuracy: 0.9795\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0601, Accuracy: 0.9805\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0583, Accuracy: 0.9819\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0543, Accuracy: 0.9820\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0551, Accuracy: 0.9827\n",
      "Validation Error for Fold 2: 0.0835\n",
      "Fold 3\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2054, Accuracy: 0.9348\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0663, Accuracy: 0.9799\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0518, Accuracy: 0.9837\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0434, Accuracy: 0.9865\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0386, Accuracy: 0.9873\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0355, Accuracy: 0.9889\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0348, Accuracy: 0.9884\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0286, Accuracy: 0.9908\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0305, Accuracy: 0.9904\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0264, Accuracy: 0.9918\n",
      "Validation Error for Fold 3: 0.0707\n",
      "Fold 4\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2878, Accuracy: 0.9084\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1083, Accuracy: 0.9663\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0861, Accuracy: 0.9732\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0759, Accuracy: 0.9763\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0724, Accuracy: 0.9768\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0641, Accuracy: 0.9790\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0618, Accuracy: 0.9799\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0590, Accuracy: 0.9811\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0581, Accuracy: 0.9809\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0579, Accuracy: 0.9814\n",
      "Validation Error for Fold 4: 0.0943\n",
      "Fold 5\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2161, Accuracy: 0.9307\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0660, Accuracy: 0.9795\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0487, Accuracy: 0.9845\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0438, Accuracy: 0.9858\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0352, Accuracy: 0.9886\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0319, Accuracy: 0.9895\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0319, Accuracy: 0.9899\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0291, Accuracy: 0.9911\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0265, Accuracy: 0.9915\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0278, Accuracy: 0.9911\n",
      "Validation Error for Fold 5: 0.0860\n",
      "Model 16, Kernel 3, LR 0.01, Batch 128, Cross-Validation Error: 0.0818, Training Accuracy: 0.9880\n",
      "Training model with num_filters=16, kernel_size=3, learning_rate=0.001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2600, Accuracy: 0.9238\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0741, Accuracy: 0.9767\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0526, Accuracy: 0.9836\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0394, Accuracy: 0.9872\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0308, Accuracy: 0.9902\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0255, Accuracy: 0.9916\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0195, Accuracy: 0.9934\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0162, Accuracy: 0.9948\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0133, Accuracy: 0.9955\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0121, Accuracy: 0.9962\n",
      "Validation Error for Fold 1: 0.0442\n",
      "Fold 2\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2623, Accuracy: 0.9206\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0713, Accuracy: 0.9778\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0499, Accuracy: 0.9845\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0362, Accuracy: 0.9885\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0277, Accuracy: 0.9915\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0223, Accuracy: 0.9927\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0177, Accuracy: 0.9945\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0140, Accuracy: 0.9954\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0128, Accuracy: 0.9960\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0110, Accuracy: 0.9964\n",
      "Validation Error for Fold 2: 0.0493\n",
      "Fold 3\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2491, Accuracy: 0.9241\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0689, Accuracy: 0.9786\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0493, Accuracy: 0.9845\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0376, Accuracy: 0.9882\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0281, Accuracy: 0.9911\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0244, Accuracy: 0.9919\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0187, Accuracy: 0.9940\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0148, Accuracy: 0.9953\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0125, Accuracy: 0.9960\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0106, Accuracy: 0.9967\n",
      "Validation Error for Fold 3: 0.0367\n",
      "Fold 4\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2486, Accuracy: 0.9244\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0640, Accuracy: 0.9809\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0450, Accuracy: 0.9860\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0351, Accuracy: 0.9889\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0269, Accuracy: 0.9916\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0215, Accuracy: 0.9933\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0166, Accuracy: 0.9943\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0142, Accuracy: 0.9955\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0119, Accuracy: 0.9961\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0107, Accuracy: 0.9965\n",
      "Validation Error for Fold 4: 0.0481\n",
      "Fold 5\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2517, Accuracy: 0.9237\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0685, Accuracy: 0.9785\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0470, Accuracy: 0.9851\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0358, Accuracy: 0.9889\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0281, Accuracy: 0.9910\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0225, Accuracy: 0.9930\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0183, Accuracy: 0.9937\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0144, Accuracy: 0.9951\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0125, Accuracy: 0.9960\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0106, Accuracy: 0.9962\n",
      "Validation Error for Fold 5: 0.0544\n",
      "Model 16, Kernel 3, LR 0.001, Batch 64, Cross-Validation Error: 0.0465, Training Accuracy: 0.9964\n",
      "Training model with num_filters=16, kernel_size=3, learning_rate=0.001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3712, Accuracy: 0.8913\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0801, Accuracy: 0.9761\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0569, Accuracy: 0.9819\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0437, Accuracy: 0.9865\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0345, Accuracy: 0.9892\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0286, Accuracy: 0.9915\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0249, Accuracy: 0.9919\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0211, Accuracy: 0.9929\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0164, Accuracy: 0.9952\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0129, Accuracy: 0.9959\n",
      "Validation Error for Fold 1: 0.0404\n",
      "Fold 2\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3512, Accuracy: 0.8952\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0827, Accuracy: 0.9756\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0563, Accuracy: 0.9832\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0435, Accuracy: 0.9860\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0353, Accuracy: 0.9888\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0294, Accuracy: 0.9902\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0229, Accuracy: 0.9928\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0196, Accuracy: 0.9936\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0167, Accuracy: 0.9947\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0129, Accuracy: 0.9961\n",
      "Validation Error for Fold 2: 0.0476\n",
      "Fold 3\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3380, Accuracy: 0.9001\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0815, Accuracy: 0.9754\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0553, Accuracy: 0.9832\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0431, Accuracy: 0.9868\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0336, Accuracy: 0.9899\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0311, Accuracy: 0.9904\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0247, Accuracy: 0.9920\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0199, Accuracy: 0.9940\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0169, Accuracy: 0.9944\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0134, Accuracy: 0.9959\n",
      "Validation Error for Fold 3: 0.0394\n",
      "Fold 4\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3778, Accuracy: 0.8903\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0973, Accuracy: 0.9703\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0668, Accuracy: 0.9793\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0533, Accuracy: 0.9836\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0431, Accuracy: 0.9866\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0357, Accuracy: 0.9888\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0308, Accuracy: 0.9903\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0262, Accuracy: 0.9915\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0238, Accuracy: 0.9918\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0198, Accuracy: 0.9936\n",
      "Validation Error for Fold 4: 0.0383\n",
      "Fold 5\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3378, Accuracy: 0.9008\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0802, Accuracy: 0.9759\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0534, Accuracy: 0.9830\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0416, Accuracy: 0.9875\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0337, Accuracy: 0.9896\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0273, Accuracy: 0.9912\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0236, Accuracy: 0.9921\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0194, Accuracy: 0.9934\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0162, Accuracy: 0.9944\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0129, Accuracy: 0.9961\n",
      "Validation Error for Fold 5: 0.0420\n",
      "Model 16, Kernel 3, LR 0.001, Batch 128, Cross-Validation Error: 0.0415, Training Accuracy: 0.9955\n",
      "Training model with num_filters=16, kernel_size=3, learning_rate=0.0001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.8163, Accuracy: 0.7838\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.2709, Accuracy: 0.9219\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1980, Accuracy: 0.9410\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.1549, Accuracy: 0.9535\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.1284, Accuracy: 0.9615\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.1097, Accuracy: 0.9670\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0947, Accuracy: 0.9716\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0842, Accuracy: 0.9746\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0748, Accuracy: 0.9780\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0674, Accuracy: 0.9802\n",
      "Validation Error for Fold 1: 0.0747\n",
      "Fold 2\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.8353, Accuracy: 0.7854\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.2443, Accuracy: 0.9283\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1697, Accuracy: 0.9496\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.1310, Accuracy: 0.9607\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.1069, Accuracy: 0.9679\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0918, Accuracy: 0.9725\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0804, Accuracy: 0.9762\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0714, Accuracy: 0.9780\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0647, Accuracy: 0.9807\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0597, Accuracy: 0.9824\n",
      "Validation Error for Fold 2: 0.0687\n",
      "Fold 3\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.7724, Accuracy: 0.8133\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.2450, Accuracy: 0.9278\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1762, Accuracy: 0.9476\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.1375, Accuracy: 0.9597\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.1141, Accuracy: 0.9664\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0977, Accuracy: 0.9708\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0859, Accuracy: 0.9749\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0779, Accuracy: 0.9772\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0703, Accuracy: 0.9792\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0643, Accuracy: 0.9811\n",
      "Validation Error for Fold 3: 0.0748\n",
      "Fold 4\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.8468, Accuracy: 0.7914\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.2741, Accuracy: 0.9201\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1959, Accuracy: 0.9418\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.1506, Accuracy: 0.9556\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.1214, Accuracy: 0.9644\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.1022, Accuracy: 0.9697\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0891, Accuracy: 0.9738\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0804, Accuracy: 0.9761\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0717, Accuracy: 0.9790\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0655, Accuracy: 0.9805\n",
      "Validation Error for Fold 4: 0.0764\n",
      "Fold 5\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.8010, Accuracy: 0.7973\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.2666, Accuracy: 0.9211\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1875, Accuracy: 0.9441\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.1414, Accuracy: 0.9580\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.1137, Accuracy: 0.9663\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0954, Accuracy: 0.9722\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0827, Accuracy: 0.9756\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0747, Accuracy: 0.9778\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0667, Accuracy: 0.9799\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0612, Accuracy: 0.9820\n",
      "Validation Error for Fold 5: 0.0763\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 64, Cross-Validation Error: 0.0742, Training Accuracy: 0.9813\n",
      "Training model with num_filters=16, kernel_size=3, learning_rate=0.0001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.1142, Accuracy: 0.7353\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.3557, Accuracy: 0.8980\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2622, Accuracy: 0.9241\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.2119, Accuracy: 0.9381\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1783, Accuracy: 0.9471\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.1512, Accuracy: 0.9549\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.1335, Accuracy: 0.9596\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.1183, Accuracy: 0.9654\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.1062, Accuracy: 0.9689\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0965, Accuracy: 0.9718\n",
      "Validation Error for Fold 1: 0.1020\n",
      "Fold 2\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.1103, Accuracy: 0.7237\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.3493, Accuracy: 0.8972\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2602, Accuracy: 0.9226\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.2128, Accuracy: 0.9366\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1757, Accuracy: 0.9477\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.1467, Accuracy: 0.9561\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.1237, Accuracy: 0.9635\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.1065, Accuracy: 0.9686\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0942, Accuracy: 0.9722\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0844, Accuracy: 0.9746\n",
      "Validation Error for Fold 2: 0.0848\n",
      "Fold 3\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.0337, Accuracy: 0.7467\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.3185, Accuracy: 0.9087\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2391, Accuracy: 0.9298\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.1942, Accuracy: 0.9426\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1620, Accuracy: 0.9524\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.1369, Accuracy: 0.9591\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.1189, Accuracy: 0.9643\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.1048, Accuracy: 0.9688\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0939, Accuracy: 0.9725\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0852, Accuracy: 0.9745\n",
      "Validation Error for Fold 3: 0.0849\n",
      "Fold 4\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.1478, Accuracy: 0.7167\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.3503, Accuracy: 0.8986\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2545, Accuracy: 0.9254\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.2055, Accuracy: 0.9389\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1715, Accuracy: 0.9489\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.1452, Accuracy: 0.9570\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.1264, Accuracy: 0.9625\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.1115, Accuracy: 0.9675\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0989, Accuracy: 0.9713\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0898, Accuracy: 0.9740\n",
      "Validation Error for Fold 4: 0.0964\n",
      "Fold 5\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.1221, Accuracy: 0.7344\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.3403, Accuracy: 0.9014\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2577, Accuracy: 0.9228\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.2090, Accuracy: 0.9379\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1737, Accuracy: 0.9484\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.1472, Accuracy: 0.9562\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.1273, Accuracy: 0.9628\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.1116, Accuracy: 0.9669\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0998, Accuracy: 0.9710\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0904, Accuracy: 0.9730\n",
      "Validation Error for Fold 5: 0.0954\n",
      "Model 16, Kernel 3, LR 0.0001, Batch 128, Cross-Validation Error: 0.0927, Training Accuracy: 0.9736\n",
      "Training model with num_filters=16, kernel_size=5, learning_rate=0.01, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2149, Accuracy: 0.9313\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1003, Accuracy: 0.9691\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0896, Accuracy: 0.9728\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0824, Accuracy: 0.9751\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0779, Accuracy: 0.9765\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0789, Accuracy: 0.9766\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0797, Accuracy: 0.9769\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0762, Accuracy: 0.9774\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0766, Accuracy: 0.9782\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0721, Accuracy: 0.9792\n",
      "Validation Error for Fold 1: 0.0950\n",
      "Fold 2\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2609, Accuracy: 0.9131\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0943, Accuracy: 0.9719\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0796, Accuracy: 0.9757\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0815, Accuracy: 0.9758\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0754, Accuracy: 0.9791\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0694, Accuracy: 0.9808\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0758, Accuracy: 0.9780\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0721, Accuracy: 0.9791\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0656, Accuracy: 0.9818\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0695, Accuracy: 0.9804\n",
      "Validation Error for Fold 2: 0.0795\n",
      "Fold 3\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.1840, Accuracy: 0.9437\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0778, Accuracy: 0.9768\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0679, Accuracy: 0.9796\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0679, Accuracy: 0.9799\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0677, Accuracy: 0.9810\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0594, Accuracy: 0.9838\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0566, Accuracy: 0.9847\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0606, Accuracy: 0.9830\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0568, Accuracy: 0.9847\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0611, Accuracy: 0.9842\n",
      "Validation Error for Fold 3: 0.1020\n",
      "Fold 4\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.1743, Accuracy: 0.9469\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0873, Accuracy: 0.9742\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0738, Accuracy: 0.9787\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0666, Accuracy: 0.9808\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0639, Accuracy: 0.9815\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0605, Accuracy: 0.9837\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0654, Accuracy: 0.9822\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0600, Accuracy: 0.9839\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0615, Accuracy: 0.9842\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0504, Accuracy: 0.9869\n",
      "Validation Error for Fold 4: 0.0773\n",
      "Fold 5\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.1830, Accuracy: 0.9425\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0809, Accuracy: 0.9751\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0738, Accuracy: 0.9783\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0697, Accuracy: 0.9801\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0662, Accuracy: 0.9809\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0701, Accuracy: 0.9808\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0702, Accuracy: 0.9810\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0601, Accuracy: 0.9838\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0611, Accuracy: 0.9837\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0626, Accuracy: 0.9829\n",
      "Validation Error for Fold 5: 0.1318\n",
      "Model 16, Kernel 5, LR 0.01, Batch 64, Cross-Validation Error: 0.0971, Training Accuracy: 0.9827\n",
      "Training model with num_filters=16, kernel_size=5, learning_rate=0.01, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.1721, Accuracy: 0.9471\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0587, Accuracy: 0.9824\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0477, Accuracy: 0.9860\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0437, Accuracy: 0.9870\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0389, Accuracy: 0.9882\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0349, Accuracy: 0.9900\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0409, Accuracy: 0.9877\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0315, Accuracy: 0.9911\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0344, Accuracy: 0.9905\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0339, Accuracy: 0.9909\n",
      "Validation Error for Fold 1: 0.0845\n",
      "Fold 2\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2152, Accuracy: 0.9317\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0708, Accuracy: 0.9779\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0550, Accuracy: 0.9829\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0521, Accuracy: 0.9847\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0474, Accuracy: 0.9850\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0468, Accuracy: 0.9862\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0441, Accuracy: 0.9868\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0469, Accuracy: 0.9862\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0469, Accuracy: 0.9864\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0401, Accuracy: 0.9886\n",
      "Validation Error for Fold 2: 0.0864\n",
      "Fold 3\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.1823, Accuracy: 0.9425\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0599, Accuracy: 0.9815\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0525, Accuracy: 0.9838\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0456, Accuracy: 0.9859\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0442, Accuracy: 0.9867\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0447, Accuracy: 0.9869\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0398, Accuracy: 0.9878\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0369, Accuracy: 0.9896\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0398, Accuracy: 0.9887\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0359, Accuracy: 0.9898\n",
      "Validation Error for Fold 3: 0.0749\n",
      "Fold 4\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [1/10], Loss: 2.3039, Accuracy: 0.1102\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [2/10], Loss: 2.3020, Accuracy: 0.1115\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [3/10], Loss: 2.3021, Accuracy: 0.1112\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [4/10], Loss: 2.3020, Accuracy: 0.1115\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [5/10], Loss: 2.3017, Accuracy: 0.1123\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [6/10], Loss: 2.3019, Accuracy: 0.1115\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [7/10], Loss: 2.3019, Accuracy: 0.1118\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [8/10], Loss: 2.3019, Accuracy: 0.1124\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [9/10], Loss: 2.3020, Accuracy: 0.1112\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [10/10], Loss: 2.3019, Accuracy: 0.1125\n",
      "Validation Error for Fold 4: 2.3018\n",
      "Fold 5\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.1721, Accuracy: 0.9451\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0578, Accuracy: 0.9825\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0448, Accuracy: 0.9865\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0424, Accuracy: 0.9872\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0483, Accuracy: 0.9860\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0391, Accuracy: 0.9887\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0354, Accuracy: 0.9898\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0367, Accuracy: 0.9894\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0420, Accuracy: 0.9892\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0311, Accuracy: 0.9918\n",
      "Validation Error for Fold 5: 0.0980\n",
      "Model 16, Kernel 5, LR 0.01, Batch 128, Cross-Validation Error: 0.5291, Training Accuracy: 0.8147\n",
      "Training model with num_filters=16, kernel_size=5, learning_rate=0.001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2340, Accuracy: 0.9286\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0651, Accuracy: 0.9798\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0440, Accuracy: 0.9864\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0337, Accuracy: 0.9893\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0275, Accuracy: 0.9908\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0199, Accuracy: 0.9940\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0168, Accuracy: 0.9943\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0140, Accuracy: 0.9953\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0117, Accuracy: 0.9958\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0099, Accuracy: 0.9966\n",
      "Validation Error for Fold 1: 0.0512\n",
      "Fold 2\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2305, Accuracy: 0.9298\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0573, Accuracy: 0.9821\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0412, Accuracy: 0.9873\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0301, Accuracy: 0.9907\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0248, Accuracy: 0.9924\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0191, Accuracy: 0.9939\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0153, Accuracy: 0.9951\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0137, Accuracy: 0.9955\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0122, Accuracy: 0.9958\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0098, Accuracy: 0.9966\n",
      "Validation Error for Fold 2: 0.0390\n",
      "Fold 3\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2202, Accuracy: 0.9333\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0644, Accuracy: 0.9802\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0440, Accuracy: 0.9869\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0335, Accuracy: 0.9894\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0279, Accuracy: 0.9909\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0220, Accuracy: 0.9932\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0166, Accuracy: 0.9946\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0184, Accuracy: 0.9940\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0121, Accuracy: 0.9961\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0099, Accuracy: 0.9965\n",
      "Validation Error for Fold 3: 0.0475\n",
      "Fold 4\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2125, Accuracy: 0.9370\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0597, Accuracy: 0.9819\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0416, Accuracy: 0.9870\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0309, Accuracy: 0.9907\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0256, Accuracy: 0.9920\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0197, Accuracy: 0.9939\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0166, Accuracy: 0.9943\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0131, Accuracy: 0.9958\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0124, Accuracy: 0.9954\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0093, Accuracy: 0.9969\n",
      "Validation Error for Fold 4: 0.0345\n",
      "Fold 5\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2162, Accuracy: 0.9341\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0627, Accuracy: 0.9801\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0431, Accuracy: 0.9865\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0320, Accuracy: 0.9899\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0242, Accuracy: 0.9928\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0205, Accuracy: 0.9931\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0165, Accuracy: 0.9944\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0138, Accuracy: 0.9953\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0114, Accuracy: 0.9963\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0103, Accuracy: 0.9966\n",
      "Validation Error for Fold 5: 0.0442\n",
      "Model 16, Kernel 5, LR 0.001, Batch 64, Cross-Validation Error: 0.0433, Training Accuracy: 0.9967\n",
      "Training model with num_filters=16, kernel_size=5, learning_rate=0.001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3150, Accuracy: 0.9102\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0798, Accuracy: 0.9756\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0542, Accuracy: 0.9835\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0404, Accuracy: 0.9872\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0322, Accuracy: 0.9896\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0263, Accuracy: 0.9919\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0231, Accuracy: 0.9927\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0173, Accuracy: 0.9942\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0159, Accuracy: 0.9948\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0132, Accuracy: 0.9957\n",
      "Validation Error for Fold 1: 0.0410\n",
      "Fold 2\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2892, Accuracy: 0.9176\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0776, Accuracy: 0.9760\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0547, Accuracy: 0.9829\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0409, Accuracy: 0.9873\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0329, Accuracy: 0.9896\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0268, Accuracy: 0.9917\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0222, Accuracy: 0.9927\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0183, Accuracy: 0.9941\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0154, Accuracy: 0.9950\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0130, Accuracy: 0.9957\n",
      "Validation Error for Fold 2: 0.0460\n",
      "Fold 3\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3356, Accuracy: 0.9019\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0807, Accuracy: 0.9750\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0541, Accuracy: 0.9836\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0429, Accuracy: 0.9871\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0341, Accuracy: 0.9894\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0284, Accuracy: 0.9906\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0222, Accuracy: 0.9928\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0208, Accuracy: 0.9934\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0152, Accuracy: 0.9954\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0150, Accuracy: 0.9954\n",
      "Validation Error for Fold 3: 0.0403\n",
      "Fold 4\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3278, Accuracy: 0.9040\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0814, Accuracy: 0.9756\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0568, Accuracy: 0.9827\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0451, Accuracy: 0.9852\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0356, Accuracy: 0.9885\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0309, Accuracy: 0.9905\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0256, Accuracy: 0.9919\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0201, Accuracy: 0.9940\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0180, Accuracy: 0.9943\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0162, Accuracy: 0.9947\n",
      "Validation Error for Fold 4: 0.0364\n",
      "Fold 5\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.3029, Accuracy: 0.9116\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0810, Accuracy: 0.9744\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0547, Accuracy: 0.9833\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0424, Accuracy: 0.9870\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0340, Accuracy: 0.9889\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0280, Accuracy: 0.9915\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0235, Accuracy: 0.9925\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0202, Accuracy: 0.9936\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0161, Accuracy: 0.9950\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0137, Accuracy: 0.9959\n",
      "Validation Error for Fold 5: 0.0438\n",
      "Model 16, Kernel 5, LR 0.001, Batch 128, Cross-Validation Error: 0.0415, Training Accuracy: 0.9955\n",
      "Training model with num_filters=16, kernel_size=5, learning_rate=0.0001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.6818, Accuracy: 0.8249\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.2151, Accuracy: 0.9380\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1512, Accuracy: 0.9559\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.1172, Accuracy: 0.9646\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0967, Accuracy: 0.9710\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0837, Accuracy: 0.9744\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0739, Accuracy: 0.9777\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0657, Accuracy: 0.9801\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0601, Accuracy: 0.9822\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0548, Accuracy: 0.9833\n",
      "Validation Error for Fold 1: 0.0613\n",
      "Fold 2\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.7094, Accuracy: 0.8180\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.2087, Accuracy: 0.9388\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1483, Accuracy: 0.9569\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.1166, Accuracy: 0.9655\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0976, Accuracy: 0.9711\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0855, Accuracy: 0.9749\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0759, Accuracy: 0.9774\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0687, Accuracy: 0.9792\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0630, Accuracy: 0.9810\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0570, Accuracy: 0.9828\n",
      "Validation Error for Fold 2: 0.0599\n",
      "Fold 3\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.7408, Accuracy: 0.8029\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.2174, Accuracy: 0.9371\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1514, Accuracy: 0.9555\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.1169, Accuracy: 0.9659\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0956, Accuracy: 0.9725\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0837, Accuracy: 0.9747\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0734, Accuracy: 0.9776\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0667, Accuracy: 0.9796\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0604, Accuracy: 0.9817\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0560, Accuracy: 0.9828\n",
      "Validation Error for Fold 3: 0.0666\n",
      "Fold 4\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.6831, Accuracy: 0.8204\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.2191, Accuracy: 0.9364\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1501, Accuracy: 0.9567\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.1155, Accuracy: 0.9664\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0962, Accuracy: 0.9720\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0821, Accuracy: 0.9759\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0731, Accuracy: 0.9789\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0651, Accuracy: 0.9804\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0590, Accuracy: 0.9825\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0539, Accuracy: 0.9843\n",
      "Validation Error for Fold 4: 0.0676\n",
      "Fold 5\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.6888, Accuracy: 0.8300\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.2066, Accuracy: 0.9403\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1444, Accuracy: 0.9578\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.1130, Accuracy: 0.9671\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0944, Accuracy: 0.9720\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0812, Accuracy: 0.9756\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0714, Accuracy: 0.9783\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0643, Accuracy: 0.9810\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0584, Accuracy: 0.9828\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0538, Accuracy: 0.9834\n",
      "Validation Error for Fold 5: 0.0658\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 64, Cross-Validation Error: 0.0642, Training Accuracy: 0.9833\n",
      "Training model with num_filters=16, kernel_size=5, learning_rate=0.0001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.9584, Accuracy: 0.7897\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.2726, Accuracy: 0.9204\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.1962, Accuracy: 0.9431\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.1531, Accuracy: 0.9551\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1252, Accuracy: 0.9633\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.1077, Accuracy: 0.9683\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0938, Accuracy: 0.9725\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0845, Accuracy: 0.9745\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0779, Accuracy: 0.9761\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0706, Accuracy: 0.9788\n",
      "Validation Error for Fold 1: 0.0722\n",
      "Fold 2\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.0335, Accuracy: 0.7400\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.2866, Accuracy: 0.9164\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2028, Accuracy: 0.9401\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.1561, Accuracy: 0.9542\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1275, Accuracy: 0.9627\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.1086, Accuracy: 0.9684\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0965, Accuracy: 0.9721\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0867, Accuracy: 0.9741\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0785, Accuracy: 0.9768\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0720, Accuracy: 0.9788\n",
      "Validation Error for Fold 2: 0.0738\n",
      "Fold 3\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.9804, Accuracy: 0.7649\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.2877, Accuracy: 0.9175\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2035, Accuracy: 0.9412\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.1572, Accuracy: 0.9540\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1281, Accuracy: 0.9628\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.1091, Accuracy: 0.9674\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0950, Accuracy: 0.9723\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0844, Accuracy: 0.9756\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0764, Accuracy: 0.9774\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0697, Accuracy: 0.9798\n",
      "Validation Error for Fold 3: 0.0693\n",
      "Fold 4\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [1/10], Loss: 1.0047, Accuracy: 0.7774\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.2783, Accuracy: 0.9206\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.1948, Accuracy: 0.9433\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.1514, Accuracy: 0.9563\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1238, Accuracy: 0.9634\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.1069, Accuracy: 0.9684\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0937, Accuracy: 0.9723\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0844, Accuracy: 0.9743\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0767, Accuracy: 0.9773\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0701, Accuracy: 0.9792\n",
      "Validation Error for Fold 4: 0.0754\n",
      "Fold 5\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.9584, Accuracy: 0.7643\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.2870, Accuracy: 0.9173\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2071, Accuracy: 0.9393\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.1626, Accuracy: 0.9530\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1340, Accuracy: 0.9608\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.1150, Accuracy: 0.9666\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.1008, Accuracy: 0.9702\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0900, Accuracy: 0.9732\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0823, Accuracy: 0.9757\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0753, Accuracy: 0.9776\n",
      "Validation Error for Fold 5: 0.0880\n",
      "Model 16, Kernel 5, LR 0.0001, Batch 128, Cross-Validation Error: 0.0757, Training Accuracy: 0.9788\n",
      "Training model with num_filters=32, kernel_size=3, learning_rate=0.01, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.3015, Accuracy: 0.9025\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1115, Accuracy: 0.9660\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0953, Accuracy: 0.9705\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0861, Accuracy: 0.9734\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0831, Accuracy: 0.9735\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0761, Accuracy: 0.9772\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0767, Accuracy: 0.9759\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0754, Accuracy: 0.9770\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0706, Accuracy: 0.9779\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0689, Accuracy: 0.9787\n",
      "Validation Error for Fold 1: 0.1090\n",
      "Fold 2\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2143, Accuracy: 0.9316\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0921, Accuracy: 0.9712\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0761, Accuracy: 0.9775\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0707, Accuracy: 0.9778\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0661, Accuracy: 0.9801\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0626, Accuracy: 0.9806\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0585, Accuracy: 0.9819\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0549, Accuracy: 0.9842\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0583, Accuracy: 0.9824\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0499, Accuracy: 0.9849\n",
      "Validation Error for Fold 2: 0.0788\n",
      "Fold 3\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2077, Accuracy: 0.9356\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0901, Accuracy: 0.9719\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0794, Accuracy: 0.9760\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0721, Accuracy: 0.9780\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0660, Accuracy: 0.9799\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0639, Accuracy: 0.9811\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0633, Accuracy: 0.9809\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0617, Accuracy: 0.9819\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0580, Accuracy: 0.9830\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0629, Accuracy: 0.9811\n",
      "Validation Error for Fold 3: 0.0878\n",
      "Fold 4\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.3540, Accuracy: 0.8869\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1555, Accuracy: 0.9506\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1307, Accuracy: 0.9583\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1202, Accuracy: 0.9625\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1159, Accuracy: 0.9627\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.1073, Accuracy: 0.9666\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.1088, Accuracy: 0.9653\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0997, Accuracy: 0.9685\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.1017, Accuracy: 0.9674\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.1032, Accuracy: 0.9680\n",
      "Validation Error for Fold 4: 0.1200\n",
      "Fold 5\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [1/10], Loss: 2.3074, Accuracy: 0.1117\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [2/10], Loss: 2.3021, Accuracy: 0.1100\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [3/10], Loss: 2.3023, Accuracy: 0.1110\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [4/10], Loss: 2.3024, Accuracy: 0.1103\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [5/10], Loss: 2.3023, Accuracy: 0.1109\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [6/10], Loss: 2.3020, Accuracy: 0.1124\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [7/10], Loss: 2.3021, Accuracy: 0.1099\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [8/10], Loss: 2.3023, Accuracy: 0.1104\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [9/10], Loss: 2.3021, Accuracy: 0.1107\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Epoch [10/10], Loss: 2.3020, Accuracy: 0.1105\n",
      "Validation Error for Fold 5: 2.3023\n",
      "Model 32, Kernel 3, LR 0.01, Batch 64, Cross-Validation Error: 0.5396, Training Accuracy: 0.8046\n",
      "Training model with num_filters=32, kernel_size=3, learning_rate=0.01, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.4418, Accuracy: 0.8591\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1818, Accuracy: 0.9429\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.1445, Accuracy: 0.9548\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.1280, Accuracy: 0.9591\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.1177, Accuracy: 0.9619\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.1065, Accuracy: 0.9658\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.1052, Accuracy: 0.9665\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0931, Accuracy: 0.9699\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0942, Accuracy: 0.9685\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0916, Accuracy: 0.9714\n",
      "Validation Error for Fold 1: 0.1138\n",
      "Fold 2\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [1/10], Loss: 2.3128, Accuracy: 0.1108\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [2/10], Loss: 2.3018, Accuracy: 0.1101\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [3/10], Loss: 2.3019, Accuracy: 0.1102\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [4/10], Loss: 2.3018, Accuracy: 0.1114\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [5/10], Loss: 2.3018, Accuracy: 0.1113\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [6/10], Loss: 2.3018, Accuracy: 0.1115\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [7/10], Loss: 2.3020, Accuracy: 0.1107\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [8/10], Loss: 2.3020, Accuracy: 0.1107\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [9/10], Loss: 2.3019, Accuracy: 0.1110\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [10/10], Loss: 2.3018, Accuracy: 0.1109\n",
      "Validation Error for Fold 2: 2.3018\n",
      "Fold 3\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.3309, Accuracy: 0.8933\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.1019, Accuracy: 0.9685\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0849, Accuracy: 0.9735\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0699, Accuracy: 0.9774\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0624, Accuracy: 0.9803\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0569, Accuracy: 0.9821\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0549, Accuracy: 0.9834\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0537, Accuracy: 0.9827\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0516, Accuracy: 0.9841\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0505, Accuracy: 0.9844\n",
      "Validation Error for Fold 3: 0.0789\n",
      "Fold 4\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [1/10], Loss: 2.3087, Accuracy: 0.1101\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [2/10], Loss: 2.3018, Accuracy: 0.1114\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [3/10], Loss: 2.3020, Accuracy: 0.1116\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [4/10], Loss: 2.3018, Accuracy: 0.1124\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [5/10], Loss: 2.3020, Accuracy: 0.1113\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [6/10], Loss: 2.3018, Accuracy: 0.1107\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [7/10], Loss: 2.3018, Accuracy: 0.1117\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [8/10], Loss: 2.3020, Accuracy: 0.1099\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [9/10], Loss: 2.3018, Accuracy: 0.1116\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [10/10], Loss: 2.3018, Accuracy: 0.1110\n",
      "Validation Error for Fold 4: 2.3018\n",
      "Fold 5\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2371, Accuracy: 0.9233\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0778, Accuracy: 0.9755\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0613, Accuracy: 0.9802\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0549, Accuracy: 0.9831\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0527, Accuracy: 0.9837\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0434, Accuracy: 0.9866\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0429, Accuracy: 0.9856\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0412, Accuracy: 0.9874\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0388, Accuracy: 0.9873\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0403, Accuracy: 0.9870\n",
      "Validation Error for Fold 5: 0.0662\n",
      "Model 32, Kernel 3, LR 0.01, Batch 128, Cross-Validation Error: 0.9725, Training Accuracy: 0.6329\n",
      "Training model with num_filters=32, kernel_size=3, learning_rate=0.001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2056, Accuracy: 0.9366\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0543, Accuracy: 0.9838\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0370, Accuracy: 0.9886\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0271, Accuracy: 0.9914\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0214, Accuracy: 0.9929\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0148, Accuracy: 0.9950\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0126, Accuracy: 0.9960\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0115, Accuracy: 0.9961\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0089, Accuracy: 0.9970\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0090, Accuracy: 0.9969\n",
      "Validation Error for Fold 1: 0.0565\n",
      "Fold 2\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2030, Accuracy: 0.9366\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0540, Accuracy: 0.9837\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0365, Accuracy: 0.9886\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0285, Accuracy: 0.9907\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0201, Accuracy: 0.9938\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0157, Accuracy: 0.9951\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0148, Accuracy: 0.9950\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0119, Accuracy: 0.9960\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0092, Accuracy: 0.9968\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0067, Accuracy: 0.9979\n",
      "Validation Error for Fold 2: 0.0420\n",
      "Fold 3\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2008, Accuracy: 0.9377\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0556, Accuracy: 0.9827\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0367, Accuracy: 0.9887\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0279, Accuracy: 0.9915\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0221, Accuracy: 0.9930\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0171, Accuracy: 0.9942\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0141, Accuracy: 0.9954\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0110, Accuracy: 0.9964\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0097, Accuracy: 0.9969\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0067, Accuracy: 0.9978\n",
      "Validation Error for Fold 3: 0.0523\n",
      "Fold 4\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2014, Accuracy: 0.9391\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0569, Accuracy: 0.9831\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0390, Accuracy: 0.9883\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0300, Accuracy: 0.9910\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0226, Accuracy: 0.9928\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0168, Accuracy: 0.9946\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0149, Accuracy: 0.9954\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0125, Accuracy: 0.9959\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0091, Accuracy: 0.9970\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0091, Accuracy: 0.9970\n",
      "Validation Error for Fold 4: 0.0437\n",
      "Fold 5\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.2038, Accuracy: 0.9389\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0555, Accuracy: 0.9825\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0385, Accuracy: 0.9880\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0276, Accuracy: 0.9915\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0213, Accuracy: 0.9929\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0170, Accuracy: 0.9944\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0130, Accuracy: 0.9956\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0109, Accuracy: 0.9964\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0076, Accuracy: 0.9975\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0089, Accuracy: 0.9971\n",
      "Validation Error for Fold 5: 0.0471\n",
      "Model 32, Kernel 3, LR 0.001, Batch 64, Cross-Validation Error: 0.0483, Training Accuracy: 0.9973\n",
      "Training model with num_filters=32, kernel_size=3, learning_rate=0.001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2561, Accuracy: 0.9229\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0627, Accuracy: 0.9811\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0461, Accuracy: 0.9855\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0329, Accuracy: 0.9897\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0245, Accuracy: 0.9925\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0217, Accuracy: 0.9929\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0160, Accuracy: 0.9944\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0140, Accuracy: 0.9955\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0114, Accuracy: 0.9961\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0111, Accuracy: 0.9962\n",
      "Validation Error for Fold 1: 0.0476\n",
      "Fold 2\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2680, Accuracy: 0.9196\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0677, Accuracy: 0.9796\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0457, Accuracy: 0.9864\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0351, Accuracy: 0.9892\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0272, Accuracy: 0.9912\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0208, Accuracy: 0.9938\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0185, Accuracy: 0.9938\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0144, Accuracy: 0.9956\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0118, Accuracy: 0.9964\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0099, Accuracy: 0.9967\n",
      "Validation Error for Fold 2: 0.0407\n",
      "Fold 3\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2907, Accuracy: 0.9089\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0685, Accuracy: 0.9788\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0477, Accuracy: 0.9857\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0346, Accuracy: 0.9891\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0280, Accuracy: 0.9917\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0226, Accuracy: 0.9927\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0170, Accuracy: 0.9946\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0141, Accuracy: 0.9952\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0111, Accuracy: 0.9964\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0102, Accuracy: 0.9969\n",
      "Validation Error for Fold 3: 0.0459\n",
      "Fold 4\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2872, Accuracy: 0.9136\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0683, Accuracy: 0.9792\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0475, Accuracy: 0.9856\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0368, Accuracy: 0.9891\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0305, Accuracy: 0.9906\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0242, Accuracy: 0.9927\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0196, Accuracy: 0.9936\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0161, Accuracy: 0.9950\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0124, Accuracy: 0.9963\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0097, Accuracy: 0.9968\n",
      "Validation Error for Fold 4: 0.0432\n",
      "Fold 5\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2570, Accuracy: 0.9227\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0640, Accuracy: 0.9798\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0448, Accuracy: 0.9861\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0326, Accuracy: 0.9900\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0264, Accuracy: 0.9919\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0194, Accuracy: 0.9940\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0167, Accuracy: 0.9946\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0133, Accuracy: 0.9958\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0102, Accuracy: 0.9966\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0099, Accuracy: 0.9966\n",
      "Validation Error for Fold 5: 0.0505\n",
      "Model 32, Kernel 3, LR 0.001, Batch 128, Cross-Validation Error: 0.0456, Training Accuracy: 0.9967\n",
      "Training model with num_filters=32, kernel_size=3, learning_rate=0.0001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.6279, Accuracy: 0.8412\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1887, Accuracy: 0.9449\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1235, Accuracy: 0.9641\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0929, Accuracy: 0.9728\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0757, Accuracy: 0.9771\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0644, Accuracy: 0.9815\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0562, Accuracy: 0.9838\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0494, Accuracy: 0.9858\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0447, Accuracy: 0.9874\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0403, Accuracy: 0.9880\n",
      "Validation Error for Fold 1: 0.0595\n",
      "Fold 2\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.6347, Accuracy: 0.8319\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.2009, Accuracy: 0.9401\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1302, Accuracy: 0.9613\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0967, Accuracy: 0.9708\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0784, Accuracy: 0.9764\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0677, Accuracy: 0.9801\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0586, Accuracy: 0.9826\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0526, Accuracy: 0.9840\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0479, Accuracy: 0.9854\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0432, Accuracy: 0.9874\n",
      "Validation Error for Fold 2: 0.0491\n",
      "Fold 3\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.6589, Accuracy: 0.8247\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1983, Accuracy: 0.9419\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1310, Accuracy: 0.9616\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0981, Accuracy: 0.9714\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0791, Accuracy: 0.9772\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0670, Accuracy: 0.9800\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0586, Accuracy: 0.9825\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0524, Accuracy: 0.9844\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0467, Accuracy: 0.9861\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0424, Accuracy: 0.9872\n",
      "Validation Error for Fold 3: 0.0492\n",
      "Fold 4\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.6073, Accuracy: 0.8419\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1886, Accuracy: 0.9447\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1229, Accuracy: 0.9632\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0924, Accuracy: 0.9721\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0747, Accuracy: 0.9777\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0641, Accuracy: 0.9808\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0558, Accuracy: 0.9840\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0495, Accuracy: 0.9856\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0447, Accuracy: 0.9866\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0403, Accuracy: 0.9877\n",
      "Validation Error for Fold 4: 0.0470\n",
      "Fold 5\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.5844, Accuracy: 0.8489\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1834, Accuracy: 0.9461\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1222, Accuracy: 0.9651\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0922, Accuracy: 0.9731\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0760, Accuracy: 0.9780\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0650, Accuracy: 0.9813\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0567, Accuracy: 0.9830\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0501, Accuracy: 0.9852\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0451, Accuracy: 0.9870\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0421, Accuracy: 0.9875\n",
      "Validation Error for Fold 5: 0.0537\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 64, Cross-Validation Error: 0.0517, Training Accuracy: 0.9876\n",
      "Training model with num_filters=32, kernel_size=3, learning_rate=0.0001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.8108, Accuracy: 0.7988\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.2514, Accuracy: 0.9268\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.1776, Accuracy: 0.9481\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.1357, Accuracy: 0.9603\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1090, Accuracy: 0.9679\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0922, Accuracy: 0.9730\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0802, Accuracy: 0.9764\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0718, Accuracy: 0.9788\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0642, Accuracy: 0.9812\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0593, Accuracy: 0.9825\n",
      "Validation Error for Fold 1: 0.0660\n",
      "Fold 2\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.8327, Accuracy: 0.8034\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.2468, Accuracy: 0.9297\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.1700, Accuracy: 0.9512\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.1277, Accuracy: 0.9629\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1035, Accuracy: 0.9702\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0874, Accuracy: 0.9744\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0753, Accuracy: 0.9783\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0677, Accuracy: 0.9801\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0609, Accuracy: 0.9820\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0555, Accuracy: 0.9837\n",
      "Validation Error for Fold 2: 0.0595\n",
      "Fold 3\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.9336, Accuracy: 0.7641\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.3011, Accuracy: 0.9116\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.2216, Accuracy: 0.9346\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.1685, Accuracy: 0.9501\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1325, Accuracy: 0.9613\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.1079, Accuracy: 0.9683\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0908, Accuracy: 0.9738\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0787, Accuracy: 0.9764\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0694, Accuracy: 0.9799\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0624, Accuracy: 0.9818\n",
      "Validation Error for Fold 3: 0.0670\n",
      "Fold 4\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.8090, Accuracy: 0.8101\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.2311, Accuracy: 0.9325\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.1540, Accuracy: 0.9546\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.1157, Accuracy: 0.9660\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.0943, Accuracy: 0.9724\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0807, Accuracy: 0.9762\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0706, Accuracy: 0.9794\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0631, Accuracy: 0.9818\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0583, Accuracy: 0.9823\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0531, Accuracy: 0.9844\n",
      "Validation Error for Fold 4: 0.0611\n",
      "Fold 5\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.8433, Accuracy: 0.7860\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.2530, Accuracy: 0.9250\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.1754, Accuracy: 0.9474\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.1327, Accuracy: 0.9610\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.1063, Accuracy: 0.9681\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0902, Accuracy: 0.9737\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0783, Accuracy: 0.9769\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0695, Accuracy: 0.9799\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0628, Accuracy: 0.9819\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0574, Accuracy: 0.9830\n",
      "Validation Error for Fold 5: 0.0685\n",
      "Model 32, Kernel 3, LR 0.0001, Batch 128, Cross-Validation Error: 0.0644, Training Accuracy: 0.9831\n",
      "Training model with num_filters=32, kernel_size=5, learning_rate=0.01, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2566, Accuracy: 0.9186\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0798, Accuracy: 0.9765\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0726, Accuracy: 0.9786\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0753, Accuracy: 0.9792\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0634, Accuracy: 0.9822\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0627, Accuracy: 0.9824\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0687, Accuracy: 0.9825\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0696, Accuracy: 0.9816\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0612, Accuracy: 0.9840\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0643, Accuracy: 0.9840\n",
      "Validation Error for Fold 1: 0.1072\n",
      "Fold 2\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2354, Accuracy: 0.9289\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1127, Accuracy: 0.9656\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0969, Accuracy: 0.9712\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0918, Accuracy: 0.9724\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0880, Accuracy: 0.9736\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0875, Accuracy: 0.9746\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0793, Accuracy: 0.9775\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0808, Accuracy: 0.9778\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0798, Accuracy: 0.9772\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0751, Accuracy: 0.9791\n",
      "Validation Error for Fold 2: 0.1004\n",
      "Fold 3\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2248, Accuracy: 0.9286\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0931, Accuracy: 0.9723\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0811, Accuracy: 0.9768\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0758, Accuracy: 0.9781\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0792, Accuracy: 0.9772\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0728, Accuracy: 0.9798\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0687, Accuracy: 0.9809\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0713, Accuracy: 0.9792\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0746, Accuracy: 0.9795\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0650, Accuracy: 0.9820\n",
      "Validation Error for Fold 3: 0.1026\n",
      "Fold 4\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2122, Accuracy: 0.9352\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0939, Accuracy: 0.9722\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0835, Accuracy: 0.9757\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0787, Accuracy: 0.9774\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0786, Accuracy: 0.9778\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0683, Accuracy: 0.9809\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0712, Accuracy: 0.9805\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0640, Accuracy: 0.9826\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0749, Accuracy: 0.9802\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0577, Accuracy: 0.9835\n",
      "Validation Error for Fold 4: 0.1062\n",
      "Fold 5\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2436, Accuracy: 0.9219\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0921, Accuracy: 0.9728\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0859, Accuracy: 0.9746\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0807, Accuracy: 0.9764\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0778, Accuracy: 0.9783\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0762, Accuracy: 0.9785\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0719, Accuracy: 0.9796\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0678, Accuracy: 0.9808\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0655, Accuracy: 0.9819\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0636, Accuracy: 0.9823\n",
      "Validation Error for Fold 5: 0.1429\n",
      "Model 32, Kernel 5, LR 0.01, Batch 64, Cross-Validation Error: 0.1119, Training Accuracy: 0.9822\n",
      "Training model with num_filters=32, kernel_size=5, learning_rate=0.01, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2038, Accuracy: 0.9382\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0656, Accuracy: 0.9798\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0525, Accuracy: 0.9838\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0485, Accuracy: 0.9852\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0446, Accuracy: 0.9862\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0458, Accuracy: 0.9862\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0423, Accuracy: 0.9872\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0475, Accuracy: 0.9866\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0392, Accuracy: 0.9885\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0387, Accuracy: 0.9885\n",
      "Validation Error for Fold 1: 0.0746\n",
      "Fold 2\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2112, Accuracy: 0.9316\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0652, Accuracy: 0.9800\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0501, Accuracy: 0.9845\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0490, Accuracy: 0.9850\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0434, Accuracy: 0.9872\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0437, Accuracy: 0.9867\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0405, Accuracy: 0.9878\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0378, Accuracy: 0.9890\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0402, Accuracy: 0.9886\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0403, Accuracy: 0.9888\n",
      "Validation Error for Fold 2: 0.0908\n",
      "Fold 3\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2984, Accuracy: 0.9035\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0812, Accuracy: 0.9748\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0694, Accuracy: 0.9785\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0601, Accuracy: 0.9815\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0601, Accuracy: 0.9814\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0551, Accuracy: 0.9828\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0587, Accuracy: 0.9819\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0494, Accuracy: 0.9853\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0522, Accuracy: 0.9840\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0449, Accuracy: 0.9866\n",
      "Validation Error for Fold 3: 0.0925\n",
      "Fold 4\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2180, Accuracy: 0.9333\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0657, Accuracy: 0.9808\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0532, Accuracy: 0.9836\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0484, Accuracy: 0.9855\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0453, Accuracy: 0.9864\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0409, Accuracy: 0.9880\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0419, Accuracy: 0.9874\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0421, Accuracy: 0.9881\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0401, Accuracy: 0.9880\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0372, Accuracy: 0.9896\n",
      "Validation Error for Fold 4: 0.0758\n",
      "Fold 5\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2669, Accuracy: 0.9178\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0721, Accuracy: 0.9776\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0633, Accuracy: 0.9799\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0547, Accuracy: 0.9831\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0465, Accuracy: 0.9857\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0506, Accuracy: 0.9850\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0505, Accuracy: 0.9854\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0455, Accuracy: 0.9864\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0467, Accuracy: 0.9860\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0525, Accuracy: 0.9854\n",
      "Validation Error for Fold 5: 0.0841\n",
      "Model 32, Kernel 5, LR 0.01, Batch 128, Cross-Validation Error: 0.0835, Training Accuracy: 0.9878\n",
      "Training model with num_filters=32, kernel_size=5, learning_rate=0.001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.1837, Accuracy: 0.9444\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0502, Accuracy: 0.9842\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0336, Accuracy: 0.9896\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0251, Accuracy: 0.9920\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0197, Accuracy: 0.9934\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0159, Accuracy: 0.9947\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0115, Accuracy: 0.9964\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0107, Accuracy: 0.9965\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0088, Accuracy: 0.9970\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0087, Accuracy: 0.9974\n",
      "Validation Error for Fold 1: 0.0437\n",
      "Fold 2\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.1800, Accuracy: 0.9460\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0491, Accuracy: 0.9839\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0330, Accuracy: 0.9893\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0237, Accuracy: 0.9924\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0176, Accuracy: 0.9943\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0136, Accuracy: 0.9958\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0126, Accuracy: 0.9960\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0104, Accuracy: 0.9966\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0089, Accuracy: 0.9969\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0083, Accuracy: 0.9970\n",
      "Validation Error for Fold 2: 0.0397\n",
      "Fold 3\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.1896, Accuracy: 0.9416\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0513, Accuracy: 0.9840\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0334, Accuracy: 0.9895\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0244, Accuracy: 0.9925\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0180, Accuracy: 0.9945\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0158, Accuracy: 0.9948\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0133, Accuracy: 0.9954\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0098, Accuracy: 0.9970\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0080, Accuracy: 0.9974\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0078, Accuracy: 0.9975\n",
      "Validation Error for Fold 3: 0.0432\n",
      "Fold 4\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.1900, Accuracy: 0.9421\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0525, Accuracy: 0.9842\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0359, Accuracy: 0.9895\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0264, Accuracy: 0.9914\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0219, Accuracy: 0.9929\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0165, Accuracy: 0.9946\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0132, Accuracy: 0.9956\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0110, Accuracy: 0.9967\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0104, Accuracy: 0.9968\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0077, Accuracy: 0.9972\n",
      "Validation Error for Fold 4: 0.0367\n",
      "Fold 5\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.1840, Accuracy: 0.9431\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0523, Accuracy: 0.9837\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0334, Accuracy: 0.9896\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0258, Accuracy: 0.9921\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0210, Accuracy: 0.9931\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0183, Accuracy: 0.9939\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0128, Accuracy: 0.9961\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0097, Accuracy: 0.9971\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0091, Accuracy: 0.9967\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0095, Accuracy: 0.9969\n",
      "Validation Error for Fold 5: 0.0455\n",
      "Model 32, Kernel 5, LR 0.001, Batch 64, Cross-Validation Error: 0.0417, Training Accuracy: 0.9972\n",
      "Training model with num_filters=32, kernel_size=5, learning_rate=0.001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2337, Accuracy: 0.9300\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0590, Accuracy: 0.9820\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0392, Accuracy: 0.9878\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0284, Accuracy: 0.9912\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0242, Accuracy: 0.9923\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0170, Accuracy: 0.9942\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0129, Accuracy: 0.9958\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0120, Accuracy: 0.9962\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0100, Accuracy: 0.9967\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0085, Accuracy: 0.9972\n",
      "Validation Error for Fold 1: 0.0389\n",
      "Fold 2\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2542, Accuracy: 0.9244\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0629, Accuracy: 0.9802\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0429, Accuracy: 0.9867\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0330, Accuracy: 0.9896\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0251, Accuracy: 0.9917\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0196, Accuracy: 0.9938\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0168, Accuracy: 0.9945\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0139, Accuracy: 0.9955\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0120, Accuracy: 0.9962\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0088, Accuracy: 0.9972\n",
      "Validation Error for Fold 2: 0.0412\n",
      "Fold 3\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2362, Accuracy: 0.9295\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0613, Accuracy: 0.9813\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0398, Accuracy: 0.9881\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0301, Accuracy: 0.9908\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0229, Accuracy: 0.9930\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0165, Accuracy: 0.9949\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0156, Accuracy: 0.9950\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0117, Accuracy: 0.9964\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0104, Accuracy: 0.9967\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0090, Accuracy: 0.9972\n",
      "Validation Error for Fold 3: 0.0453\n",
      "Fold 4\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2363, Accuracy: 0.9304\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0596, Accuracy: 0.9822\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0433, Accuracy: 0.9869\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0296, Accuracy: 0.9906\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0245, Accuracy: 0.9925\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0192, Accuracy: 0.9941\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0148, Accuracy: 0.9954\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0138, Accuracy: 0.9955\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0114, Accuracy: 0.9964\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0089, Accuracy: 0.9972\n",
      "Validation Error for Fold 4: 0.0330\n",
      "Fold 5\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2368, Accuracy: 0.9303\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0572, Accuracy: 0.9826\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0392, Accuracy: 0.9881\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0294, Accuracy: 0.9910\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0218, Accuracy: 0.9930\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0196, Accuracy: 0.9940\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0150, Accuracy: 0.9953\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0123, Accuracy: 0.9959\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0099, Accuracy: 0.9970\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0076, Accuracy: 0.9975\n",
      "Validation Error for Fold 5: 0.0429\n",
      "Model 32, Kernel 5, LR 0.001, Batch 128, Cross-Validation Error: 0.0403, Training Accuracy: 0.9973\n",
      "Training model with num_filters=32, kernel_size=5, learning_rate=0.0001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.5295, Accuracy: 0.8584\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1539, Accuracy: 0.9554\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1021, Accuracy: 0.9693\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0799, Accuracy: 0.9762\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0662, Accuracy: 0.9804\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0574, Accuracy: 0.9828\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0500, Accuracy: 0.9850\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0454, Accuracy: 0.9863\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0407, Accuracy: 0.9877\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0365, Accuracy: 0.9886\n",
      "Validation Error for Fold 1: 0.0487\n",
      "Fold 2\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.5391, Accuracy: 0.8659\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1529, Accuracy: 0.9553\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1015, Accuracy: 0.9705\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0785, Accuracy: 0.9765\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0647, Accuracy: 0.9801\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0550, Accuracy: 0.9835\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0484, Accuracy: 0.9856\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0434, Accuracy: 0.9871\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0380, Accuracy: 0.9885\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0348, Accuracy: 0.9895\n",
      "Validation Error for Fold 2: 0.0438\n",
      "Fold 3\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.5162, Accuracy: 0.8699\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1429, Accuracy: 0.9584\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.0960, Accuracy: 0.9715\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0762, Accuracy: 0.9773\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0631, Accuracy: 0.9812\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0546, Accuracy: 0.9837\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0480, Accuracy: 0.9853\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0427, Accuracy: 0.9871\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0387, Accuracy: 0.9883\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0351, Accuracy: 0.9896\n",
      "Validation Error for Fold 3: 0.0454\n",
      "Fold 4\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.5307, Accuracy: 0.8584\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1533, Accuracy: 0.9554\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.1017, Accuracy: 0.9704\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0779, Accuracy: 0.9768\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0652, Accuracy: 0.9806\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0556, Accuracy: 0.9838\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0487, Accuracy: 0.9855\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0440, Accuracy: 0.9867\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0388, Accuracy: 0.9885\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0352, Accuracy: 0.9898\n",
      "Validation Error for Fold 4: 0.0448\n",
      "Fold 5\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.5509, Accuracy: 0.8552\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1446, Accuracy: 0.9578\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.0984, Accuracy: 0.9709\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0783, Accuracy: 0.9766\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0659, Accuracy: 0.9802\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0573, Accuracy: 0.9825\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0501, Accuracy: 0.9847\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0450, Accuracy: 0.9864\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0407, Accuracy: 0.9878\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0369, Accuracy: 0.9892\n",
      "Validation Error for Fold 5: 0.0615\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 64, Cross-Validation Error: 0.0488, Training Accuracy: 0.9893\n",
      "Training model with num_filters=32, kernel_size=5, learning_rate=0.0001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.7049, Accuracy: 0.8337\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.1970, Accuracy: 0.9427\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.1327, Accuracy: 0.9611\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.1024, Accuracy: 0.9694\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.0839, Accuracy: 0.9753\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0729, Accuracy: 0.9784\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0650, Accuracy: 0.9809\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0592, Accuracy: 0.9818\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0529, Accuracy: 0.9845\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0482, Accuracy: 0.9853\n",
      "Validation Error for Fold 1: 0.0570\n",
      "Fold 2\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.7647, Accuracy: 0.8105\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.2214, Accuracy: 0.9354\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.1475, Accuracy: 0.9568\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.1114, Accuracy: 0.9670\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.0900, Accuracy: 0.9734\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0776, Accuracy: 0.9771\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0675, Accuracy: 0.9799\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0602, Accuracy: 0.9816\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0536, Accuracy: 0.9838\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0499, Accuracy: 0.9849\n",
      "Validation Error for Fold 2: 0.0530\n",
      "Fold 3\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.7565, Accuracy: 0.8164\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.2143, Accuracy: 0.9375\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.1438, Accuracy: 0.9583\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.1104, Accuracy: 0.9681\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.0914, Accuracy: 0.9731\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0781, Accuracy: 0.9770\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0697, Accuracy: 0.9792\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0622, Accuracy: 0.9821\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0578, Accuracy: 0.9835\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0528, Accuracy: 0.9840\n",
      "Validation Error for Fold 3: 0.0547\n",
      "Fold 4\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.7155, Accuracy: 0.8288\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.2079, Accuracy: 0.9388\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.1428, Accuracy: 0.9575\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.1096, Accuracy: 0.9681\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.0903, Accuracy: 0.9739\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0772, Accuracy: 0.9775\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0687, Accuracy: 0.9796\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0608, Accuracy: 0.9824\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0561, Accuracy: 0.9833\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0510, Accuracy: 0.9846\n",
      "Validation Error for Fold 4: 0.0537\n",
      "Fold 5\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.7418, Accuracy: 0.8125\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.2161, Accuracy: 0.9376\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.1440, Accuracy: 0.9586\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.1087, Accuracy: 0.9681\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.0894, Accuracy: 0.9736\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0760, Accuracy: 0.9776\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0657, Accuracy: 0.9803\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0599, Accuracy: 0.9820\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0536, Accuracy: 0.9841\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0495, Accuracy: 0.9849\n",
      "Validation Error for Fold 5: 0.0606\n",
      "Model 32, Kernel 5, LR 0.0001, Batch 128, Cross-Validation Error: 0.0558, Training Accuracy: 0.9848\n",
      "Training model with num_filters=64, kernel_size=3, learning_rate=0.01, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2632, Accuracy: 0.9231\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0837, Accuracy: 0.9742\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0736, Accuracy: 0.9774\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0632, Accuracy: 0.9807\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0623, Accuracy: 0.9810\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0587, Accuracy: 0.9825\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0536, Accuracy: 0.9840\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0532, Accuracy: 0.9844\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0533, Accuracy: 0.9849\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0491, Accuracy: 0.9859\n",
      "Validation Error for Fold 1: 0.0980\n",
      "Fold 2\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2547, Accuracy: 0.9232\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0901, Accuracy: 0.9728\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0769, Accuracy: 0.9759\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0694, Accuracy: 0.9785\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0687, Accuracy: 0.9790\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0618, Accuracy: 0.9816\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0569, Accuracy: 0.9828\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0594, Accuracy: 0.9816\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0530, Accuracy: 0.9839\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0556, Accuracy: 0.9835\n",
      "Validation Error for Fold 2: 0.0837\n",
      "Fold 3\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2075, Accuracy: 0.9380\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0883, Accuracy: 0.9735\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0758, Accuracy: 0.9766\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0656, Accuracy: 0.9798\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0639, Accuracy: 0.9804\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0607, Accuracy: 0.9819\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0612, Accuracy: 0.9818\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0547, Accuracy: 0.9836\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0527, Accuracy: 0.9845\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0531, Accuracy: 0.9842\n",
      "Validation Error for Fold 3: 0.0949\n",
      "Fold 4\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2473, Accuracy: 0.9250\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1006, Accuracy: 0.9691\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0853, Accuracy: 0.9738\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0780, Accuracy: 0.9760\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0767, Accuracy: 0.9761\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0720, Accuracy: 0.9783\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0718, Accuracy: 0.9788\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0670, Accuracy: 0.9794\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0634, Accuracy: 0.9801\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0641, Accuracy: 0.9809\n",
      "Validation Error for Fold 4: 0.0987\n",
      "Fold 5\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.3383, Accuracy: 0.8991\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1708, Accuracy: 0.9450\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1436, Accuracy: 0.9543\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.1338, Accuracy: 0.9577\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.1231, Accuracy: 0.9607\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.1141, Accuracy: 0.9631\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.1108, Accuracy: 0.9651\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.1090, Accuracy: 0.9660\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0967, Accuracy: 0.9698\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0892, Accuracy: 0.9723\n",
      "Validation Error for Fold 5: 0.1094\n",
      "Model 64, Kernel 3, LR 0.01, Batch 64, Cross-Validation Error: 0.0969, Training Accuracy: 0.9814\n",
      "Training model with num_filters=64, kernel_size=3, learning_rate=0.01, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2969, Accuracy: 0.9085\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0760, Accuracy: 0.9762\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0632, Accuracy: 0.9804\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0572, Accuracy: 0.9818\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0498, Accuracy: 0.9838\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0453, Accuracy: 0.9855\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0425, Accuracy: 0.9865\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0392, Accuracy: 0.9873\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0341, Accuracy: 0.9891\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0381, Accuracy: 0.9882\n",
      "Validation Error for Fold 1: 0.0928\n",
      "Fold 2\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2961, Accuracy: 0.9114\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0855, Accuracy: 0.9739\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0691, Accuracy: 0.9783\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0567, Accuracy: 0.9818\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0553, Accuracy: 0.9829\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0500, Accuracy: 0.9846\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0436, Accuracy: 0.9863\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0488, Accuracy: 0.9846\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0452, Accuracy: 0.9858\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0439, Accuracy: 0.9867\n",
      "Validation Error for Fold 2: 0.0780\n",
      "Fold 3\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2984, Accuracy: 0.9119\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0944, Accuracy: 0.9702\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0790, Accuracy: 0.9749\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0717, Accuracy: 0.9769\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0663, Accuracy: 0.9789\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0605, Accuracy: 0.9801\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0559, Accuracy: 0.9824\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0521, Accuracy: 0.9841\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0498, Accuracy: 0.9840\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0460, Accuracy: 0.9856\n",
      "Validation Error for Fold 3: 0.0746\n",
      "Fold 4\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.3241, Accuracy: 0.9040\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0997, Accuracy: 0.9688\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0805, Accuracy: 0.9752\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0763, Accuracy: 0.9757\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0608, Accuracy: 0.9803\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0614, Accuracy: 0.9806\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0581, Accuracy: 0.9817\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0559, Accuracy: 0.9820\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0485, Accuracy: 0.9848\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0509, Accuracy: 0.9844\n",
      "Validation Error for Fold 4: 0.0799\n",
      "Fold 5\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.3646, Accuracy: 0.8823\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0981, Accuracy: 0.9690\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0781, Accuracy: 0.9759\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0706, Accuracy: 0.9775\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0617, Accuracy: 0.9809\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0655, Accuracy: 0.9787\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0596, Accuracy: 0.9804\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0560, Accuracy: 0.9823\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0493, Accuracy: 0.9846\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0526, Accuracy: 0.9833\n",
      "Validation Error for Fold 5: 0.0821\n",
      "Model 64, Kernel 3, LR 0.01, Batch 128, Cross-Validation Error: 0.0815, Training Accuracy: 0.9856\n",
      "Training model with num_filters=64, kernel_size=3, learning_rate=0.001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.1776, Accuracy: 0.9457\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0507, Accuracy: 0.9841\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0344, Accuracy: 0.9893\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0251, Accuracy: 0.9923\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0176, Accuracy: 0.9941\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0155, Accuracy: 0.9950\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0113, Accuracy: 0.9962\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0105, Accuracy: 0.9962\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0071, Accuracy: 0.9976\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0082, Accuracy: 0.9973\n",
      "Validation Error for Fold 1: 0.0489\n",
      "Fold 2\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.1706, Accuracy: 0.9472\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0474, Accuracy: 0.9849\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0314, Accuracy: 0.9904\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0232, Accuracy: 0.9921\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0161, Accuracy: 0.9950\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0142, Accuracy: 0.9951\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0097, Accuracy: 0.9968\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0089, Accuracy: 0.9971\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0068, Accuracy: 0.9978\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0076, Accuracy: 0.9975\n",
      "Validation Error for Fold 2: 0.0360\n",
      "Fold 3\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.1671, Accuracy: 0.9499\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0479, Accuracy: 0.9847\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0319, Accuracy: 0.9899\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0239, Accuracy: 0.9924\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0175, Accuracy: 0.9942\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0143, Accuracy: 0.9951\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0126, Accuracy: 0.9959\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0085, Accuracy: 0.9974\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0073, Accuracy: 0.9977\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0078, Accuracy: 0.9973\n",
      "Validation Error for Fold 3: 0.0467\n",
      "Fold 4\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.1707, Accuracy: 0.9460\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0474, Accuracy: 0.9852\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0340, Accuracy: 0.9894\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0228, Accuracy: 0.9929\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0171, Accuracy: 0.9945\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0140, Accuracy: 0.9956\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0118, Accuracy: 0.9962\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0092, Accuracy: 0.9968\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0068, Accuracy: 0.9977\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0084, Accuracy: 0.9972\n",
      "Validation Error for Fold 4: 0.0439\n",
      "Fold 5\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.1683, Accuracy: 0.9483\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0502, Accuracy: 0.9846\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0337, Accuracy: 0.9897\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0242, Accuracy: 0.9923\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0179, Accuracy: 0.9941\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0146, Accuracy: 0.9952\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0131, Accuracy: 0.9954\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0099, Accuracy: 0.9963\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0083, Accuracy: 0.9971\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0074, Accuracy: 0.9975\n",
      "Validation Error for Fold 5: 0.0447\n",
      "Model 64, Kernel 3, LR 0.001, Batch 64, Cross-Validation Error: 0.0440, Training Accuracy: 0.9974\n",
      "Training model with num_filters=64, kernel_size=3, learning_rate=0.001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2046, Accuracy: 0.9384\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0489, Accuracy: 0.9851\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0337, Accuracy: 0.9895\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0249, Accuracy: 0.9921\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0194, Accuracy: 0.9938\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0135, Accuracy: 0.9956\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0113, Accuracy: 0.9962\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0087, Accuracy: 0.9971\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0083, Accuracy: 0.9971\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0071, Accuracy: 0.9978\n",
      "Validation Error for Fold 1: 0.0395\n",
      "Fold 2\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2034, Accuracy: 0.9383\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0531, Accuracy: 0.9835\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0384, Accuracy: 0.9881\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0277, Accuracy: 0.9908\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0207, Accuracy: 0.9935\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0158, Accuracy: 0.9951\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0130, Accuracy: 0.9956\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0098, Accuracy: 0.9971\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0075, Accuracy: 0.9976\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0076, Accuracy: 0.9975\n",
      "Validation Error for Fold 2: 0.0410\n",
      "Fold 3\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2248, Accuracy: 0.9327\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0554, Accuracy: 0.9829\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0372, Accuracy: 0.9887\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0277, Accuracy: 0.9916\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0216, Accuracy: 0.9933\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0179, Accuracy: 0.9941\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0142, Accuracy: 0.9954\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0112, Accuracy: 0.9963\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0093, Accuracy: 0.9970\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0067, Accuracy: 0.9977\n",
      "Validation Error for Fold 3: 0.0501\n",
      "Fold 4\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2053, Accuracy: 0.9368\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0493, Accuracy: 0.9849\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0348, Accuracy: 0.9899\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0272, Accuracy: 0.9915\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0198, Accuracy: 0.9937\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0155, Accuracy: 0.9951\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0118, Accuracy: 0.9964\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0094, Accuracy: 0.9968\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0075, Accuracy: 0.9976\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0074, Accuracy: 0.9971\n",
      "Validation Error for Fold 4: 0.0407\n",
      "Fold 5\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2158, Accuracy: 0.9351\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0539, Accuracy: 0.9830\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0358, Accuracy: 0.9886\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0258, Accuracy: 0.9917\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0203, Accuracy: 0.9934\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0154, Accuracy: 0.9952\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0126, Accuracy: 0.9962\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0101, Accuracy: 0.9967\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0102, Accuracy: 0.9964\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0079, Accuracy: 0.9971\n",
      "Validation Error for Fold 5: 0.0401\n",
      "Model 64, Kernel 3, LR 0.001, Batch 128, Cross-Validation Error: 0.0423, Training Accuracy: 0.9974\n",
      "Training model with num_filters=64, kernel_size=3, learning_rate=0.0001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.4530, Accuracy: 0.8790\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1296, Accuracy: 0.9619\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.0851, Accuracy: 0.9746\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0655, Accuracy: 0.9803\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0529, Accuracy: 0.9840\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0467, Accuracy: 0.9860\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0401, Accuracy: 0.9882\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0354, Accuracy: 0.9891\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0311, Accuracy: 0.9904\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0277, Accuracy: 0.9918\n",
      "Validation Error for Fold 1: 0.0472\n",
      "Fold 2\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.4563, Accuracy: 0.8747\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1345, Accuracy: 0.9601\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.0870, Accuracy: 0.9745\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0684, Accuracy: 0.9792\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0559, Accuracy: 0.9829\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0484, Accuracy: 0.9854\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0415, Accuracy: 0.9877\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0371, Accuracy: 0.9889\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0329, Accuracy: 0.9903\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0288, Accuracy: 0.9910\n",
      "Validation Error for Fold 2: 0.0431\n",
      "Fold 3\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.4595, Accuracy: 0.8798\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1276, Accuracy: 0.9621\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.0834, Accuracy: 0.9754\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0649, Accuracy: 0.9804\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0555, Accuracy: 0.9832\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0483, Accuracy: 0.9855\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0426, Accuracy: 0.9875\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0374, Accuracy: 0.9889\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0335, Accuracy: 0.9901\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0298, Accuracy: 0.9909\n",
      "Validation Error for Fold 3: 0.0439\n",
      "Fold 4\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.4695, Accuracy: 0.8728\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1300, Accuracy: 0.9614\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.0837, Accuracy: 0.9755\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0650, Accuracy: 0.9810\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0536, Accuracy: 0.9841\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0454, Accuracy: 0.9867\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0400, Accuracy: 0.9880\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0356, Accuracy: 0.9892\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0324, Accuracy: 0.9904\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0284, Accuracy: 0.9914\n",
      "Validation Error for Fold 4: 0.0389\n",
      "Fold 5\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.4545, Accuracy: 0.8749\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1227, Accuracy: 0.9652\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.0811, Accuracy: 0.9762\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0626, Accuracy: 0.9812\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0529, Accuracy: 0.9842\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0454, Accuracy: 0.9861\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0397, Accuracy: 0.9882\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0350, Accuracy: 0.9894\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0315, Accuracy: 0.9901\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0270, Accuracy: 0.9922\n",
      "Validation Error for Fold 5: 0.0443\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 64, Cross-Validation Error: 0.0435, Training Accuracy: 0.9914\n",
      "Training model with num_filters=64, kernel_size=3, learning_rate=0.0001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.6451, Accuracy: 0.8259\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.1999, Accuracy: 0.9414\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.1301, Accuracy: 0.9618\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.0957, Accuracy: 0.9716\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.0774, Accuracy: 0.9775\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0649, Accuracy: 0.9808\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0561, Accuracy: 0.9836\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0504, Accuracy: 0.9849\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0453, Accuracy: 0.9864\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0414, Accuracy: 0.9878\n",
      "Validation Error for Fold 1: 0.0541\n",
      "Fold 2\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.6989, Accuracy: 0.8199\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.1987, Accuracy: 0.9423\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.1286, Accuracy: 0.9620\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.0965, Accuracy: 0.9713\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.0788, Accuracy: 0.9767\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0670, Accuracy: 0.9802\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0588, Accuracy: 0.9827\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0523, Accuracy: 0.9846\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0470, Accuracy: 0.9866\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0431, Accuracy: 0.9876\n",
      "Validation Error for Fold 2: 0.0509\n",
      "Fold 3\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.6113, Accuracy: 0.8396\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.1956, Accuracy: 0.9426\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.1264, Accuracy: 0.9631\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.0923, Accuracy: 0.9730\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.0745, Accuracy: 0.9777\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0624, Accuracy: 0.9820\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0541, Accuracy: 0.9842\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0491, Accuracy: 0.9853\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0443, Accuracy: 0.9874\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0398, Accuracy: 0.9885\n",
      "Validation Error for Fold 3: 0.0483\n",
      "Fold 4\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.6219, Accuracy: 0.8396\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.1880, Accuracy: 0.9445\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.1219, Accuracy: 0.9639\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.0918, Accuracy: 0.9736\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.0747, Accuracy: 0.9787\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0634, Accuracy: 0.9816\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0557, Accuracy: 0.9830\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0512, Accuracy: 0.9851\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0449, Accuracy: 0.9873\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0415, Accuracy: 0.9878\n",
      "Validation Error for Fold 4: 0.0480\n",
      "Fold 5\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.6477, Accuracy: 0.8322\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.1901, Accuracy: 0.9442\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.1203, Accuracy: 0.9647\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.0898, Accuracy: 0.9738\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.0723, Accuracy: 0.9787\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0616, Accuracy: 0.9816\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0544, Accuracy: 0.9839\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0473, Accuracy: 0.9857\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0435, Accuracy: 0.9872\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0392, Accuracy: 0.9882\n",
      "Validation Error for Fold 5: 0.0528\n",
      "Model 64, Kernel 3, LR 0.0001, Batch 128, Cross-Validation Error: 0.0508, Training Accuracy: 0.9880\n",
      "Training model with num_filters=64, kernel_size=5, learning_rate=0.01, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.3922, Accuracy: 0.8890\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1289, Accuracy: 0.9621\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.1041, Accuracy: 0.9686\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0975, Accuracy: 0.9708\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0925, Accuracy: 0.9722\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0859, Accuracy: 0.9746\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0852, Accuracy: 0.9751\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0868, Accuracy: 0.9746\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0840, Accuracy: 0.9762\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0847, Accuracy: 0.9762\n",
      "Validation Error for Fold 1: 0.1043\n",
      "Fold 2\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.3763, Accuracy: 0.8746\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1104, Accuracy: 0.9671\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0926, Accuracy: 0.9726\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0901, Accuracy: 0.9738\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0841, Accuracy: 0.9764\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0835, Accuracy: 0.9769\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0735, Accuracy: 0.9793\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0800, Accuracy: 0.9784\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0785, Accuracy: 0.9788\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0712, Accuracy: 0.9808\n",
      "Validation Error for Fold 2: 0.1131\n",
      "Fold 3\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2280, Accuracy: 0.9300\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0979, Accuracy: 0.9707\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0885, Accuracy: 0.9734\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0834, Accuracy: 0.9754\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0822, Accuracy: 0.9766\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0833, Accuracy: 0.9764\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0828, Accuracy: 0.9777\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0696, Accuracy: 0.9811\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0774, Accuracy: 0.9788\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0734, Accuracy: 0.9805\n",
      "Validation Error for Fold 3: 0.1062\n",
      "Fold 4\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2047, Accuracy: 0.9388\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.0875, Accuracy: 0.9743\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0839, Accuracy: 0.9752\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0829, Accuracy: 0.9761\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0719, Accuracy: 0.9797\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0745, Accuracy: 0.9792\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0696, Accuracy: 0.9812\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0713, Accuracy: 0.9814\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0618, Accuracy: 0.9832\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0677, Accuracy: 0.9826\n",
      "Validation Error for Fold 4: 0.1586\n",
      "Fold 5\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [1/10], Loss: 0.2940, Accuracy: 0.9211\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [2/10], Loss: 0.1022, Accuracy: 0.9696\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [3/10], Loss: 0.0965, Accuracy: 0.9709\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [4/10], Loss: 0.0938, Accuracy: 0.9725\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [5/10], Loss: 0.0850, Accuracy: 0.9753\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [6/10], Loss: 0.0856, Accuracy: 0.9754\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [7/10], Loss: 0.0834, Accuracy: 0.9768\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [8/10], Loss: 0.0863, Accuracy: 0.9754\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [9/10], Loss: 0.0775, Accuracy: 0.9767\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Epoch [10/10], Loss: 0.0782, Accuracy: 0.9771\n",
      "Validation Error for Fold 5: 0.1098\n",
      "Model 64, Kernel 5, LR 0.01, Batch 64, Cross-Validation Error: 0.1184, Training Accuracy: 0.9794\n",
      "Training model with num_filters=64, kernel_size=5, learning_rate=0.01, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2721, Accuracy: 0.9263\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0651, Accuracy: 0.9795\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0531, Accuracy: 0.9836\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0513, Accuracy: 0.9842\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0462, Accuracy: 0.9856\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0469, Accuracy: 0.9857\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0444, Accuracy: 0.9863\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0453, Accuracy: 0.9868\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0485, Accuracy: 0.9859\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0437, Accuracy: 0.9873\n",
      "Validation Error for Fold 1: 0.0812\n",
      "Fold 2\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [1/10], Loss: 2.3808, Accuracy: 0.1119\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [2/10], Loss: 2.3018, Accuracy: 0.1110\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [3/10], Loss: 2.3020, Accuracy: 0.1106\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [4/10], Loss: 2.3020, Accuracy: 0.1110\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [5/10], Loss: 2.3018, Accuracy: 0.1109\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [6/10], Loss: 2.3019, Accuracy: 0.1115\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [7/10], Loss: 2.3018, Accuracy: 0.1116\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [8/10], Loss: 2.3019, Accuracy: 0.1115\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [9/10], Loss: 2.3018, Accuracy: 0.1117\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [10/10], Loss: 2.3019, Accuracy: 0.1118\n",
      "Validation Error for Fold 2: 2.3018\n",
      "Fold 3\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.3991, Accuracy: 0.8685\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0753, Accuracy: 0.9770\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0609, Accuracy: 0.9810\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0584, Accuracy: 0.9821\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0518, Accuracy: 0.9845\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0508, Accuracy: 0.9839\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0512, Accuracy: 0.9851\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0453, Accuracy: 0.9865\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0489, Accuracy: 0.9858\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0415, Accuracy: 0.9874\n",
      "Validation Error for Fold 3: 0.0926\n",
      "Fold 4\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.3391, Accuracy: 0.9032\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0873, Accuracy: 0.9734\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0749, Accuracy: 0.9766\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0679, Accuracy: 0.9797\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0637, Accuracy: 0.9804\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0651, Accuracy: 0.9803\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0577, Accuracy: 0.9826\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0679, Accuracy: 0.9790\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0604, Accuracy: 0.9822\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0601, Accuracy: 0.9824\n",
      "Validation Error for Fold 4: 0.0950\n",
      "Fold 5\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [1/10], Loss: 0.2767, Accuracy: 0.9133\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [2/10], Loss: 0.0647, Accuracy: 0.9799\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [3/10], Loss: 0.0558, Accuracy: 0.9833\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [4/10], Loss: 0.0497, Accuracy: 0.9852\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [5/10], Loss: 0.0470, Accuracy: 0.9858\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [6/10], Loss: 0.0438, Accuracy: 0.9871\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [7/10], Loss: 0.0460, Accuracy: 0.9869\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [8/10], Loss: 0.0450, Accuracy: 0.9873\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [9/10], Loss: 0.0434, Accuracy: 0.9878\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Epoch [10/10], Loss: 0.0397, Accuracy: 0.9891\n",
      "Validation Error for Fold 5: 0.0793\n",
      "Model 64, Kernel 5, LR 0.01, Batch 128, Cross-Validation Error: 0.5300, Training Accuracy: 0.8116\n",
      "Training model with num_filters=64, kernel_size=5, learning_rate=0.001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.1549, Accuracy: 0.9524\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0429, Accuracy: 0.9870\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0287, Accuracy: 0.9908\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0220, Accuracy: 0.9930\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0151, Accuracy: 0.9951\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0131, Accuracy: 0.9958\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0117, Accuracy: 0.9961\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0084, Accuracy: 0.9972\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0073, Accuracy: 0.9979\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0064, Accuracy: 0.9981\n",
      "Validation Error for Fold 1: 0.0632\n",
      "Fold 2\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.1384, Accuracy: 0.9571\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0409, Accuracy: 0.9868\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0266, Accuracy: 0.9920\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0192, Accuracy: 0.9936\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0143, Accuracy: 0.9953\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0122, Accuracy: 0.9960\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0095, Accuracy: 0.9969\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0073, Accuracy: 0.9979\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0065, Accuracy: 0.9977\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0087, Accuracy: 0.9972\n",
      "Validation Error for Fold 2: 0.0372\n",
      "Fold 3\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.1530, Accuracy: 0.9529\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0431, Accuracy: 0.9864\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0286, Accuracy: 0.9912\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0199, Accuracy: 0.9934\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0161, Accuracy: 0.9950\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0115, Accuracy: 0.9962\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0110, Accuracy: 0.9964\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0085, Accuracy: 0.9972\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0068, Accuracy: 0.9981\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0072, Accuracy: 0.9976\n",
      "Validation Error for Fold 3: 0.0476\n",
      "Fold 4\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.1474, Accuracy: 0.9546\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0437, Accuracy: 0.9866\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0299, Accuracy: 0.9904\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0220, Accuracy: 0.9930\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0157, Accuracy: 0.9952\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0136, Accuracy: 0.9955\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0109, Accuracy: 0.9966\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0095, Accuracy: 0.9969\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0077, Accuracy: 0.9977\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0073, Accuracy: 0.9978\n",
      "Validation Error for Fold 4: 0.0331\n",
      "Fold 5\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [1/10], Loss: 0.1472, Accuracy: 0.9553\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [2/10], Loss: 0.0414, Accuracy: 0.9874\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [3/10], Loss: 0.0291, Accuracy: 0.9908\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [4/10], Loss: 0.0206, Accuracy: 0.9927\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [5/10], Loss: 0.0144, Accuracy: 0.9957\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [6/10], Loss: 0.0112, Accuracy: 0.9965\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [7/10], Loss: 0.0114, Accuracy: 0.9964\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [8/10], Loss: 0.0095, Accuracy: 0.9969\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [9/10], Loss: 0.0069, Accuracy: 0.9978\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Epoch [10/10], Loss: 0.0064, Accuracy: 0.9980\n",
      "Validation Error for Fold 5: 0.0443\n",
      "Model 64, Kernel 5, LR 0.001, Batch 64, Cross-Validation Error: 0.0451, Training Accuracy: 0.9977\n",
      "Training model with num_filters=64, kernel_size=5, learning_rate=0.001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.1857, Accuracy: 0.9413\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0492, Accuracy: 0.9845\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0322, Accuracy: 0.9893\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0231, Accuracy: 0.9926\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0172, Accuracy: 0.9944\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0136, Accuracy: 0.9956\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0121, Accuracy: 0.9960\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0108, Accuracy: 0.9964\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0081, Accuracy: 0.9974\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0074, Accuracy: 0.9975\n",
      "Validation Error for Fold 1: 0.0472\n",
      "Fold 2\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.1860, Accuracy: 0.9448\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0478, Accuracy: 0.9856\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0306, Accuracy: 0.9902\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0223, Accuracy: 0.9933\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0174, Accuracy: 0.9941\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0141, Accuracy: 0.9954\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0097, Accuracy: 0.9968\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0085, Accuracy: 0.9971\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0055, Accuracy: 0.9980\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0068, Accuracy: 0.9976\n",
      "Validation Error for Fold 2: 0.0473\n",
      "Fold 3\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.1979, Accuracy: 0.9379\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0497, Accuracy: 0.9845\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0339, Accuracy: 0.9900\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0255, Accuracy: 0.9918\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0182, Accuracy: 0.9945\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0140, Accuracy: 0.9953\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0109, Accuracy: 0.9965\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0100, Accuracy: 0.9968\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0079, Accuracy: 0.9975\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0078, Accuracy: 0.9971\n",
      "Validation Error for Fold 3: 0.0408\n",
      "Fold 4\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.2065, Accuracy: 0.9351\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0529, Accuracy: 0.9832\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0347, Accuracy: 0.9890\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0245, Accuracy: 0.9924\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0205, Accuracy: 0.9936\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0142, Accuracy: 0.9955\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0116, Accuracy: 0.9964\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0116, Accuracy: 0.9964\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0086, Accuracy: 0.9972\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0081, Accuracy: 0.9973\n",
      "Validation Error for Fold 4: 0.0274\n",
      "Fold 5\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [1/10], Loss: 0.1923, Accuracy: 0.9424\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [2/10], Loss: 0.0500, Accuracy: 0.9849\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [3/10], Loss: 0.0328, Accuracy: 0.9901\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [4/10], Loss: 0.0237, Accuracy: 0.9919\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [5/10], Loss: 0.0189, Accuracy: 0.9939\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [6/10], Loss: 0.0149, Accuracy: 0.9953\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [7/10], Loss: 0.0107, Accuracy: 0.9968\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [8/10], Loss: 0.0093, Accuracy: 0.9973\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [9/10], Loss: 0.0088, Accuracy: 0.9971\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Epoch [10/10], Loss: 0.0079, Accuracy: 0.9974\n",
      "Validation Error for Fold 5: 0.0497\n",
      "Model 64, Kernel 5, LR 0.001, Batch 128, Cross-Validation Error: 0.0425, Training Accuracy: 0.9974\n",
      "Training model with num_filters=64, kernel_size=5, learning_rate=0.0001, batch_size=64, epochs=10\n",
      "Fold 1\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.3945, Accuracy: 0.8940\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1010, Accuracy: 0.9706\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.0672, Accuracy: 0.9800\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0524, Accuracy: 0.9841\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0427, Accuracy: 0.9871\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0376, Accuracy: 0.9889\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0318, Accuracy: 0.9905\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0286, Accuracy: 0.9912\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0238, Accuracy: 0.9929\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0221, Accuracy: 0.9926\n",
      "Validation Error for Fold 1: 0.0387\n",
      "Fold 2\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.4137, Accuracy: 0.8891\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1049, Accuracy: 0.9692\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.0718, Accuracy: 0.9792\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0567, Accuracy: 0.9832\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0465, Accuracy: 0.9856\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0407, Accuracy: 0.9874\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0353, Accuracy: 0.9886\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0308, Accuracy: 0.9906\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0277, Accuracy: 0.9914\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0239, Accuracy: 0.9927\n",
      "Validation Error for Fold 2: 0.0376\n",
      "Fold 3\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.3786, Accuracy: 0.8998\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1072, Accuracy: 0.9683\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.0748, Accuracy: 0.9772\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0597, Accuracy: 0.9819\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0492, Accuracy: 0.9847\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0425, Accuracy: 0.9869\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0364, Accuracy: 0.9887\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0321, Accuracy: 0.9905\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0282, Accuracy: 0.9917\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0239, Accuracy: 0.9925\n",
      "Validation Error for Fold 3: 0.0344\n",
      "Fold 4\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.3852, Accuracy: 0.9000\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1043, Accuracy: 0.9693\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.0735, Accuracy: 0.9781\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0590, Accuracy: 0.9824\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0482, Accuracy: 0.9849\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0413, Accuracy: 0.9877\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0374, Accuracy: 0.9886\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0311, Accuracy: 0.9900\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0275, Accuracy: 0.9915\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0246, Accuracy: 0.9922\n",
      "Validation Error for Fold 4: 0.0335\n",
      "Fold 5\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [1/10], Loss: 0.3834, Accuracy: 0.8985\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [2/10], Loss: 0.1012, Accuracy: 0.9705\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [3/10], Loss: 0.0718, Accuracy: 0.9780\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [4/10], Loss: 0.0561, Accuracy: 0.9829\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [5/10], Loss: 0.0469, Accuracy: 0.9861\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [6/10], Loss: 0.0399, Accuracy: 0.9881\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [7/10], Loss: 0.0340, Accuracy: 0.9895\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [8/10], Loss: 0.0302, Accuracy: 0.9906\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [9/10], Loss: 0.0262, Accuracy: 0.9921\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Epoch [10/10], Loss: 0.0223, Accuracy: 0.9933\n",
      "Validation Error for Fold 5: 0.0439\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 64, Cross-Validation Error: 0.0376, Training Accuracy: 0.9927\n",
      "Training model with num_filters=64, kernel_size=5, learning_rate=0.0001, batch_size=128, epochs=10\n",
      "Fold 1\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.5214, Accuracy: 0.8654\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.1346, Accuracy: 0.9611\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.0912, Accuracy: 0.9733\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.0726, Accuracy: 0.9784\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.0595, Accuracy: 0.9825\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0526, Accuracy: 0.9841\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0450, Accuracy: 0.9865\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0427, Accuracy: 0.9868\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0363, Accuracy: 0.9888\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0334, Accuracy: 0.9896\n",
      "Validation Error for Fold 1: 0.0452\n",
      "Fold 2\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.5501, Accuracy: 0.8607\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.1475, Accuracy: 0.9580\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.0975, Accuracy: 0.9711\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.0752, Accuracy: 0.9785\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.0625, Accuracy: 0.9817\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0533, Accuracy: 0.9847\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0465, Accuracy: 0.9858\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0420, Accuracy: 0.9878\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0364, Accuracy: 0.9890\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0337, Accuracy: 0.9897\n",
      "Validation Error for Fold 2: 0.0414\n",
      "Fold 3\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.5880, Accuracy: 0.8516\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.1511, Accuracy: 0.9559\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.0964, Accuracy: 0.9717\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.0744, Accuracy: 0.9779\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.0629, Accuracy: 0.9811\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0525, Accuracy: 0.9839\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0470, Accuracy: 0.9855\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0413, Accuracy: 0.9880\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0379, Accuracy: 0.9886\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0343, Accuracy: 0.9899\n",
      "Validation Error for Fold 3: 0.0417\n",
      "Fold 4\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.5340, Accuracy: 0.8623\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.1521, Accuracy: 0.9565\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.0988, Accuracy: 0.9709\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.0755, Accuracy: 0.9777\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.0619, Accuracy: 0.9812\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0541, Accuracy: 0.9835\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0468, Accuracy: 0.9860\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0418, Accuracy: 0.9873\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0380, Accuracy: 0.9888\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0341, Accuracy: 0.9897\n",
      "Validation Error for Fold 4: 0.0467\n",
      "Fold 5\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [1/10], Loss: 0.5240, Accuracy: 0.8664\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [2/10], Loss: 0.1404, Accuracy: 0.9586\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [3/10], Loss: 0.0934, Accuracy: 0.9725\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [4/10], Loss: 0.0735, Accuracy: 0.9783\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [5/10], Loss: 0.0615, Accuracy: 0.9810\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [6/10], Loss: 0.0544, Accuracy: 0.9835\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [7/10], Loss: 0.0470, Accuracy: 0.9855\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [8/10], Loss: 0.0419, Accuracy: 0.9872\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [9/10], Loss: 0.0378, Accuracy: 0.9884\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Epoch [10/10], Loss: 0.0345, Accuracy: 0.9893\n",
      "Validation Error for Fold 5: 0.0483\n",
      "Model 64, Kernel 5, LR 0.0001, Batch 128, Cross-Validation Error: 0.0447, Training Accuracy: 0.9896\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Select GPU if available, otherwise fall back to CPU\n",
    "for num_filters in param_grid['num_filters']:\n",
    "    for kernel_size in param_grid['kernel_size']:\n",
    "        for learning_rate in param_grid['learning_rate']:\n",
    "            for batch_size in param_grid['batch_size']:\n",
    "                for epochs in param_grid['epochs']:\n",
    "                    val_loss = train_and_evaluate(num_filters, kernel_size, learning_rate, batch_size, epochs)\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        best_params = {'num_filters': num_filters, 'kernel_size': kernel_size, 'learning_rate': learning_rate, 'batch_size': batch_size, 'epochs': epochs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf3b819-b260-4e1b-a43d-15820b941f30",
   "metadata": {},
   "source": [
    "# Training best models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c8ebb1-096b-4f89-bc9a-01ecfb67f859",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dba1345-217d-4a9e-9883-b918bed7290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset and flatten it for MLP use\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3eb17485-bf9f-4ef5-86ef-9bb3c96f7410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10, Accuracy: 0.9786, F1: 0.9785, Time: 142.81s\n",
      "Epochs: 15, Accuracy: 0.9779, F1: 0.9778, Time: 222.92s\n",
      "Epochs: 20, Accuracy: 0.9804, F1: 0.9803, Time: 310.79s\n",
      "Epochs: 25, Accuracy: 0.9818, F1: 0.9816, Time: 406.76s\n",
      "Epochs: 30, Accuracy: 0.9839, F1: 0.9837, Time: 493.56s\n",
      "Epochs: 35, Accuracy: 0.9827, F1: 0.9826, Time: 596.13s\n",
      "Epochs: 40, Accuracy: 0.9828, F1: 0.9826, Time: 676.80s\n",
      "Epochs: 45, Accuracy: 0.9806, F1: 0.9804, Time: 764.30s\n",
      "Epochs: 50, Accuracy: 0.9848, F1: 0.9847, Time: 840.16s\n",
      "Epochs: 55, Accuracy: 0.9799, F1: 0.9798, Time: 937.02s\n",
      "Epochs: 60, Accuracy: 0.9832, F1: 0.9830, Time: 1044.49s\n",
      "Epochs: 65, Accuracy: 0.9839, F1: 0.9838, Time: 1140.69s\n",
      "Epochs: 70, Accuracy: 0.9802, F1: 0.9800, Time: 1219.49s\n",
      "Epochs: 75, Accuracy: 0.9807, F1: 0.9806, Time: 1290.20s\n",
      "Epochs: 80, Accuracy: 0.9835, F1: 0.9834, Time: 1378.06s\n"
     ]
    }
   ],
   "source": [
    "# Define the range of epoch values to test (from 10 to 80, in steps of 5)\n",
    "epoch_values = range(10, 81, 5)\n",
    "\n",
    "# Dictionary to store evaluation metrics for each epoch count\n",
    "results = {\n",
    "    \"epochs\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": [],\n",
    "    \"training_time\": []\n",
    "}\n",
    "\n",
    "# Loop through each epoch count in the defined range\n",
    "for num_epochs in epoch_values:\n",
    "    # Initialize a new MLP model with the best hyperparameters found earlier\n",
    "    mlp_model = MLP(28*28, mlp_best_params['hidden_sizes'], 10).to(device)\n",
    "\n",
    "    # Define the loss function (cross-entropy for multi-class classification)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Use Adam optimizer with the best learning rate found\n",
    "    optimizer = optim.Adam(mlp_model.parameters(), lr=mlp_best_params['learning_rate'])\n",
    "\n",
    "    # Prepare training and testing DataLoaders with the best batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=mlp_best_params['batch_size'], shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=mlp_best_params['batch_size'], shuffle=False)\n",
    "\n",
    "    # Start timing the training process\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Training loop over the specified number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        mlp_model.train()  # Set model to training mode\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Clear previous gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = mlp_model(images)\n",
    "\n",
    "            # Compute loss and backpropagate\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "    # Calculate total training time for this configuration\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Evaluation phase\n",
    "    mlp_model.eval()  # Set model to evaluation mode\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    # Disable gradient calculation during inference\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = mlp_model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Compute evaluation metrics on the test set\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Store metrics for plotting/analysis\n",
    "    results[\"epochs\"].append(num_epochs)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"recall\"].append(recall)\n",
    "    results[\"f1\"].append(f1)\n",
    "    results[\"training_time\"].append(training_time)\n",
    "\n",
    "    # Print summary of results for this epoch configuration\n",
    "    print(f\"Epochs: {num_epochs}, Accuracy: {accuracy:.4f}, F1: {f1:.4f}, Time: {training_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e03102a0-aa37-40aa-9229-41784b022f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in a dataframe\n",
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2301df87-bd43-493c-bb0b-adb9a0c93090",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d85ea34-6f42-464c-8b3d-94b48845d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset for CNN (Not flattened like MLP)\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dd65367-bfa2-4285-942a-392207428747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10, Accuracy: 0.9926, F1: 0.9925, Time: 537.29s\n",
      "Epochs: 15, Accuracy: 0.9931, F1: 0.9930, Time: 1100.61s\n",
      "Epochs: 20, Accuracy: 0.9916, F1: 0.9915, Time: 1516.94s\n",
      "Epochs: 25, Accuracy: 0.9928, F1: 0.9927, Time: 1852.12s\n",
      "Epochs: 30, Accuracy: 0.9912, F1: 0.9911, Time: 2257.03s\n",
      "Epochs: 35, Accuracy: 0.9928, F1: 0.9927, Time: 2614.85s\n",
      "Epochs: 40, Accuracy: 0.9931, F1: 0.9931, Time: 2914.79s\n",
      "Epochs: 45, Accuracy: 0.9938, F1: 0.9937, Time: 3176.64s\n",
      "Epochs: 50, Accuracy: 0.9907, F1: 0.9906, Time: 3449.73s\n",
      "Epochs: 55, Accuracy: 0.9939, F1: 0.9938, Time: 3790.77s\n",
      "Epochs: 60, Accuracy: 0.9943, F1: 0.9942, Time: 3997.20s\n",
      "Epochs: 65, Accuracy: 0.9934, F1: 0.9933, Time: 4288.19s\n",
      "Epochs: 70, Accuracy: 0.9929, F1: 0.9929, Time: 4537.02s\n",
      "Epochs: 75, Accuracy: 0.9938, F1: 0.9937, Time: 4805.29s\n",
      "Epochs: 80, Accuracy: 0.9932, F1: 0.9931, Time: 5105.30s\n"
     ]
    }
   ],
   "source": [
    "# Define range of epochs to test for performance evaluation\n",
    "epoch_values = range(10, 81, 5)\n",
    "\n",
    "# Dictionary to store CNN results across different epoch values\n",
    "cnn_results = {\n",
    "    \"epochs\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": [],\n",
    "    \"training_time\": []\n",
    "}\n",
    "\n",
    "# Loop over each epoch value in the defined range\n",
    "for num_epochs in epoch_values:\n",
    "    # Initialize CNN model using best hyperparameters from tuning\n",
    "    cnn_model = CNN(best_params['num_filters'], best_params['kernel_size'], 10).to(device)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(cnn_model.parameters(), lr=best_params['learning_rate'])\n",
    "\n",
    "    # Prepare DataLoaders for training and testing\n",
    "    train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=best_params['batch_size'], shuffle=False)\n",
    "\n",
    "    # Record training start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train the model for the given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        cnn_model.train()  # Set model to training mode\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Reset gradients before each step\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = cnn_model(images)\n",
    "\n",
    "            # Compute loss and perform backpropagation\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "    # Calculate total training time for the current epoch configuration\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Evaluate the trained model on the test set\n",
    "    cnn_model.eval()  # Set model to evaluation mode\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    # Perform inference without tracking gradients\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = cnn_model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Calculate classification performance metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Store results for this epoch configuration\n",
    "    cnn_results[\"epochs\"].append(num_epochs)\n",
    "    cnn_results[\"accuracy\"].append(accuracy)\n",
    "    cnn_results[\"precision\"].append(precision)\n",
    "    cnn_results[\"recall\"].append(recall)\n",
    "    cnn_results[\"f1\"].append(f1)\n",
    "    cnn_results[\"training_time\"].append(training_time)\n",
    "\n",
    "    # Output summary of metrics for this training run\n",
    "    print(f\"Epochs: {num_epochs}, Accuracy: {accuracy:.4f}, F1: {f1:.4f}, Time: {training_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03531d9f-e15f-4a6c-b388-181d9bdea484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in a dataframe\n",
    "df_cnn_results = pd.DataFrame(cnn_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8457413-06e6-47fe-9515-f9aa826e4b20",
   "metadata": {},
   "source": [
    "# Exporting Data and Results for Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96c6cfd2-3db2-4d4f-91aa-dd12fb5c7ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mlp_best_params.json\", \"w\") as f:\n",
    "    json.dump(mlp_best_params, f)\n",
    "\n",
    "with open(\"cnn_best_params.json\", \"w\") as f:\n",
    "    json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9671dc4-6ed5-4889-8d19-6615cecd82da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"mlp_results.csv\", index=False)\n",
    "df_cnn_results.to_csv(\"cnn_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df5d24-d6de-4a27-a082-972d692589a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
